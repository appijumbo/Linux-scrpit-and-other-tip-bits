%begin LaTeX Document 
%Automatically generated by Tomboy Exporter 
\documentclass[10pt,a4paper]{article} 

\usepackage{ucs} 
\usepackage[utf8x]{inputenc} 

%The following two lines are for parsing special Icelandic letters 
\usepackage[icelandic]{babel} 
\usepackage[T1]{fontenc} 

%Set margins, delete or comment out the following four lines if you want to use the defaults 
\setlength{\topmargin}{-.5in} 
\setlength{\textheight}{9in} 
\setlength{\oddsidemargin}{.125in} 
\setlength{\textwidth}{6.25in} 

%Needed for formulas and hyperlinking
\usepackage{amsmath} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage[colorlinks, linkcolor=blue]{hyperref} 


%Needed for proper display of underline and strikethrough text 
\usepackage{ulem} 
\normalem 

\begin{document} 
\author{Tomboy Exporter} 
\begingroup 
\hypersetup{linkcolor=black} 
\tableofcontents 
\endgroup 
\newpage 

\hypertarget{\$path}{\section {$PATH}}
https://hackprogramming.com/2-ways-to-permanently-set-path-variable-in-ubuntu/{\Large }{\large \\
It's an environmental variable, so to see its contents\\
\\
\$ echo \$PATH\\
\\
should give something like\\
\\
/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin:/usr/games:/usr/local/games}{\large \\
\\
Can also see this at\\
\\
\$ cat /etc/environment}{\large \\
\\
\\
Exporting PATH variable to /etc/environment}{\large \\
\\
Method 1)\\
To permanently add directory to \$PATH environment variable is by using the following command:\\
\\
e.g. to append '/snap/bin'\\
\\
\# first append the new directory to path\\
\$ PATH = /usr/local/sbin:/usr/local/bin:/snap/bin}{\large \\
\\
\$ source /etc/environment}{\large  \&\& export PATH\\
\\
Method 2)\\
\\
Another way is use the .profile file by adding the export command and then run the source command:\\
\\
\# add this command to `\~/.profile` file\\
\\
\$ export PATH=\$PATH:/snap/bin\\
\# then run the source command\\
\$ source \~/.profile\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
}827
\hypertarget{4_linux_commands_to_find_help_and_examples}{\section {4 Linux commands to find help and examples}}
\textbf{{\large 1) man pages}}\\
\\
\\
example \\
\\
\$ man wget\\
\\
when open type ' / ' to search the pages\\
\\
'n' to go to the next search \\
\\
\\
Also\\
\$ man -k fooBarTopic\\
\\
to search for commands \\
\\
'PageUp'  and 'PageDown' to go up and down a page\\
\\
'Home' to go to top of page\\
\\
'End' to go to bottom of page\\
\\
'q' to quit and get back to the command line\\
\\
\\
\textbf{{\large 2) Info }}\\
\\
\\
A very nicely indexed help, \\
\\
Great for examples !\\
\\
\$ info wget\\
\\
produces the following sections\\
\\
* Overview::                    Features of Wget.\\
* Invoking::                    Wget command-line arguments.\\
* Recursive Download::          Downloading interlinked pages.\\
* Following Links::             The available methods of chasing links.\\
* Time-Stamping::               Mirroring according to time-stamps.\\
* Startup File::                Wget’s initialization file.\\
* Examples::                    Examples of usage.\\
* Various::                     The stuff that doesn’t fit anywhere else.\\
* Appendices::                  Some useful references.\\
* Copying this manual::         You may give out copies of this manual.\\
* Concept Index::               Topics covered by this manual.\\
\\
\\
Simple use the 'arrow up' and 'arrow down' keys to go over the desired menu option and hit 'enter' to select\\
\\
\\
Also 'i' to enter a search index term\\
\\
\\
And don't forget that ' H ' for help on using this 'info' help tool\\
\\
This pops up the menu\\
\\
H           Close this help window.\\
q           Quit Info altogether.\\
h           Invoke the Info tutorial.\\
\\
Up          Move up one line.\\
Down        Move down one line.\\
PgUp        Scroll backward one screenful.\\
PgDn        Scroll forward one screenful.\\
Home        Go to the beginning of this node.\\
End         Go to the end of this node.\\
\\
TAB         Skip to the next hypertext link.\\
RET         Follow the hypertext link under the cursor.\\
\\
Finally 'T' to go to the top of the page\\
\\
------\\
\\
\textbf{{\large 3) --help}}\\
\\
\$ wget --help\\
\\
Very good at giving a simplified listing of the options on a command\\
\\
\\
Can use grep to narrow down too eg.\\
\\
\$ wget --help | grep 'POST'\\
\\
gives\\
\\
--post-data=STRING          use the POST method; send STRING as the data\\
       --post-file=FILE            use the POST method; send contents of FILE\\
\\
\\
Whereas\\
\\
\$ curl --help | grep 'POST'\\
\\
gives\\
\\
 -d, --data <data>   HTTP POST data\\
     --data-ascii <data> HTTP POST ASCII data\\
     --data-binary <data> HTTP POST binary data\\
     --data-raw <data> HTTP POST data, '@' allowed\\
     --data-urlencode <data> HTTP POST data url encoded\\
 -F, --form <name=content> Specify HTTP multipart POST data\\
     --form-string <name=string> Specify HTTP multipart POST data\\
\\
Tip: Best used with less to moderate output also ie  \\
\\
\\
\$ wget --help | less\\
\\
then can use down arrow keys or 'PageUp' and 'PageDown' keys accordingly\\
\\
Again 'q' to quit\\
\\
\\
\textbf{{\large 4) cheat.sh}}\\
\\
Use the website http://cheat.sh  eg.\\
\\
Excellent for quick examples !\\
\\
For example online examples for 'crontab' just\\
\\
cheat.sh/crontab\\
\\
for command line just curl it e.g.\\
\\
\$ curl cheat.sh/crontab\\
\\
\\
1547
\hypertarget{atom_tips}{\section {Atom Tips}}
{\large CTRL + /  		comment out selected block\\
\\
shift + Ctrl + P     	menu\\
\\
Alt     			toggle toolbar\\
\\
 }105
\hypertarget{bash_-_streams,_redirection,_piping_and_xargs_examples}{\section {Bash - Streams, Redirection, Piping and Xargs examples}}
{\Large STIN  0			standard input\\
\\
STOUT 1			standard output\\
\\
STERR 2			standard error\\
\\
}\textbf{{\Large To output to a file >}}{\Large \\
Send output of the ls -1 command to a file called output.txt\\
\$ ls -1 > output.txt        \\
\\
\\
\textbf{To append to the file >>}}{\Large \textbf{Combine files }}{\Large \\
\$ cat file1.txt file2.txt file3.txt > all\_files.txt\\
\\
\\
\textbf{Putting errors into a separate file to easily see them \\
and/or remove them from the console log}}{\Large \\
\\
\$ commandFooBar \textbf{2>}}{\Large  error-log.txt\\
\\
2>  means redirect standard errors\\
\\
\\
\textbf{BUT! IF you want to remove the errors it's DON'T redirect to a text file, \\
but to 'dev null'}}{\Large \\
\\
'dev null' is a 'black hole' bucket ie \\
\$ commandFooBar 2> /dev/null}{\Large \\
\\
errors will just be thrown away now\\
\\
\\
\textbf{To re-direct from one stream to another}}{\Large \\
To get standard error to go to standard output (i.e. console) (hence 'opposite' of /dev/null}{\Large  )\\
\\
\$ commandFooBar 2>\&1 \\
\\
\\
\textbf{PIPING ' | '}}{\Large     output of one command goes to input of another\\
\\
To count how many files in a list\\
\\
\$ ls -1 | wc -l\\
}{\Large -----------------------------------------------------------\\
note:\\
\$ ls -1     'LS ONE' lists on separate lines\\
\$ wc -l  	'WC - L' means count lines\\
-----------------------------------------------------------\\
\\
\textbf{Tee command}}{\Large \\
\\
Split the pipe\\
\$ ls -1 \textbf{| }}{\Large wc -l \textbf{| tee }}{\Large output.txt\\
\\
Now the 'tee' makes the command output go to the 'output.txt' file AND the console (the standard out).\\
\\
\\
--------------------------------------------------------\\
\\
\textbf{Xargs find and Pipes}}{\Large \\
\\
xargs lets you to execute a command on each one of the files that are returned by the 'foobar error' command. \\
\\
\$ foobar-makes-errors | xargs \\
\\
You can execute a command one at a time on each of the 'files' returned\\
\\
\\
\\
\textbf{Piping with xargs -  very simple 'silly' example}}{\Large \\
( find / -name *.conf  --> this part just a demo. It will produce errors and a lot of files found)\\
\\
\\
\$ }{\large find / -name *.conf }\textbf{{\Large | xargs wc -l}}{\Large \\
\\
hence for every .conf file that's found, find out how many lines of text are in that file\\
\\
\textit{NOTE: xargs 'runs' that command!}}{\Large \\
\\
\\
----------------------------------------------------------------------------------------------------------\\
\textbf{\\
xargs - build and execute command lines from standard input}}{\Large \\
\\
\\
simple example, for each number 'n' 1 to 5,  have ''Hello 1 2 3 4 5''\\
\\
Use the 'seq' command. Hence to produce numbers 1 to 5 \\
\$ seq 5\\
\\
Thus our command with xargs becomes\\
\\
\$ seq 5 | xargs echo ''Hello''\\
Hello 1 2 3 4 5 \\
\\
But to run for EACH item\\
\$ seq 5 | xargs -n 1 echo ''Hello''   	[-n 1 means break up via spaces]\\
}{\large Hello 1\\
Hello 2\\
Hello 3\\
Hello 4\\
Hello 5}{\Large \\
\\
Lets apply this to the list command 'ls'\\
\$ ls -1 | xargs echo ''Hello''\\
}{\large Hello bash-loop-demo-1.sh bash-math-with-if.sh file1 file2 file3 file4 outfile}{\Large \\
\\
\\
and using '-n 1' to group in singles or 'ones' with the 'spaces' option to break as above\\
\$ ls -1 | xargs -n 1 echo ''Hello''\\
}{\large Hello bash-loop-demo-1.sh\\
Hello bash-math-with-if.sh\\
Hello file1\\
Hello file2\\
Hello file3\\
Hello file4}{\Large \\
\\
------------------------------------------------------------------------------------------------------------------------\\
Side note: to find out what groups the current user [\$ whoami] has permissions to\\
\$ group\\
\\
example \$ group --->\\
tomdom adm cdrom sudo dip plugdev lpadmin sambashare \hyperlink{docker}{docker}}{\Large \\
------------------------------------------------------------------------------------------------------------------------\\
\\
\$ ls | xargs -n 1 chgrp cdrom\\
\\
[ go through each file in the current directory and changr the group ownership for each to 'cdrom']\\
\\
\\
move all files that begin with the filename 'foobar' into a directory called 'bob'\\
\$ mkdir bob\\
\\
\textbf{\$ ls foobar*  | xargs -I\{\} -n 1 mv \{\} bob/}}{\Large \\
\\
NOTE: -I\{\}   is a place holder for the name and \{\} is that name.\\
This is similar to VAR  and \$\{VAR\}\\
\\
More useful examples include\\
\\
Find all file name ending with .pdf and remove them\\
(bulletproof version: handles filenames with \\n and skips *.pdf directories)\\
-r = --no-run-if-empty\\
 -n10 = group by 10 files\\
\\
\textbf{\$ find -name \\*.pdf -type f -print0 | xargs -0rn10}}{\Large \\
\\
if file name contains spaces you should use this instead\\
\\
\textbf{\$ find -name \\*.pdf | xargs -I\{\} rm -rf '\{\}'}}{\Large \\
\\
Will show every .pdf like:\\
       \&toto.pdf=\\
       \&titi.pdf=\\
 -n1 => One file by one file. ( -n2 => 2 files by 2 files )\\
\\
\textbf{\$ find -name \\*.pdf | xargs -I\{\} -n1 echo '\&\{\}='}}{\Large \\
\\
 group words by three in a string\\
\textbf{\$ seq 1 10 | xargs -n3 echo}}{\Large \\
\\
 ]\\
\\
\\
\\
}134
\hypertarget{bash_it_out!_-_linux_bash_script_challange}{\section {BASH IT OUT! - Linux Bash Script Challange}}
{\large Make 4 files\\
\$ touch file1 file2 file3 file4\\
\\
=====================================================================================\\
=====================================================================================\\
*********************  Count the number of files in a directory   **********************\\
\\
To list them\\
\\
\$ ls\\
\\
To count them pipe them into  'word count' - \\
\$ man wc\\
newline, word, and byte counts for each file\\
\\
\$ ls | wc\\
     13      14     108\\
\\
But if we want detail need 'long'\\
\\
\$ ls -l\\
drwxrwxr-x  6 tomdom tomdom  4096 Nov 12 12:00 'Calibre Library'\\
drwxr-xr-x  2 tomdom tomdom  4096 Nov 12 14:14  Desktop\\
drwxr-xr-x  2 tomdom tomdom  4096 Nov 21 14:09  Documents\\
drwxr-xr-x  7 tomdom tomdom  4096 Nov 21 18:59  Downloads\\
drwxr-xr-x  2 tomdom tomdom  4096 Nov  9 19:19  Music\\
drwxr-xr-x  2 tomdom tomdom  4096 Nov 21 12:08  Pictures\\
drwxrwxr-x  3 tomdom tomdom  4096 Nov 14 20:35  Projects\\
drwxr-xr-x  2 tomdom tomdom  4096 Nov  9 19:19  Public\\
-rw-r--r--  1 tomdom tomdom 97356 Nov 18 13:20  q\\
drwxr-xr-x 23 tomdom tomdom  4096 Nov 19 13:21  snap\\
drwxr-xr-x  4 tomdom tomdom  4096 Nov 19 13:39  Templates\\
-rw-rw-r--  1 tomdom tomdom     5 Nov 13 10:48  test.txt\\
drwxr-xr-x  2 tomdom tomdom  4096 Nov 19 13:30  Videos\\
\\
\\
\$ ls | wc -l\\
13\\
\\
because there are '13' newlines\\
BUT some are directories! \\
\\
\\
\\
==================\\
\$ mkdir -p ItsFOSS\\
\$ cd ItsFOSS\\
\$ touch file1 file2 \$'file3\\nok'\\
\\
\$ ls -l\\
total 0\\
-rw-rw-r-- 1 tomdom tomdom 0 Nov 21 20:15  file1\\
-rw-rw-r-- 1 tomdom tomdom 0 Nov 21 20:15  file2\\
-rw-rw-r-- 1 tomdom tomdom 0 Nov 21 20:15 'file3'\$'\\n''ok'\\
\\
\\
\$ ls | wc -l\\
4\\
\\
DONT FORGET \\n IS A VALID FILE NAME!!  BUT its also 'newline'\\
\\
A corner case but be careful !\\
\\
To fix --> 'q' flag --> replace non-printable characters by question mark (?)\\
\\
\$ itsfoss\$ ls | wc -l\\
4\\
\$ itsfoss\$ ls -q | wc -l\\
3\\
\\
===============  To count No. of files  NOT file names  ================\\
\\
Lets add some directories first to see how good the solution is\\
\$ mkdir dir1 dir2\\
\\
\$ ls -l\\
total 8\\
drwxrwxr-x 2 tomdom tomdom 4096 Nov 22 13:53  dir1\\
drwxrwxr-x 2 tomdom tomdom 4096 Nov 22 13:53  dir2\\
-rw-rw-r-- 1 tomdom tomdom    0 Nov 22 13:36  file1\\
-rw-rw-r-- 1 tomdom tomdom    0 Nov 22 13:36  file2\\
-rw-rw-r-- 1 tomdom tomdom    0 Nov 22 13:36 'file3'\$'\\n''ok'\\
\\
\\
'find'  to find files 'type' to check type, \\
need to check if its an actual file or not, AND insert a newline to circumvent possible 'foo\\n' type filename\\
\\
***  Method 1 (my approach) ***\\
\$ find . -type f -printf '\\n' | wc -l\\
3\\
\\
Method 2 (as found in book)\\
		 'max/min depth 1: to confine search to current directory level)\\
\\
\$ find . -mindepth 1 -maxdepth 1 -printf '\\n' | wc -l\\
5\\
\\
Problem: it counts directories too because its not file type\\
\\
\\
=====================================================================================\\
=====================================================================================\\
*********************  Challenge 2: My shell don't know how to count *********************  \\
\\
\\
I have some data file containing integer numbers, one one each line, and I want to compute the sum of all those numbers.\\
\\
To get the data into sample.data\\
itsfoss\$ echo ''102\\
> 071\\
> 210\\
> 153'' > sample.data\\
\\
----> OR WE COULD USE CAT !\\
\\
itsfoss\$ cat > sample.data << 'THE END'\\
> 102\\
> 071\\
> 210\\
> 153\\
> THE END\\
itsfoss\$ \\
\\
\\
hence\\
\\
itsfoss\$ cat sample.data  \\
102\\
071\\
210\\
153\\
\\
\\
----> Create a loop and push in the data from 'sample.data' and echo out the total\\
  \\
itsfoss\$ 			create an 'i'nteger variable and st to 0\\
itsfoss\$ while read X; do\\
> SUM+=\$X\\
> done < sample.data\\
itsfoss\$ echo ''Sum is: \$SUM''\\
Sum is: 522\\
\\
\\
The problem is the '071' --> unfortunately  the '0' indicates to C compiler that the number it Octal !!\\
\\
Hence\\
itsfoss\$ echo \$((071))\\
57\\
\\
The solution is to remove unnecessary '0's at the beginning of the number before reading them in\\
\\
We can use 'sed' to do this\\
\\
NOTE:\\
sed  Stream Editor for filtering and transforming text\\
-E  use Extended regular expressions in the script\\
\\
		\# To replace all (global) occurrences of ''day'' with ''night'' in file.txt\\
		\$ sed 's/day/night/g' file.txt\\
		\\
\\
\\
\\
** Solution 1: remove leading '0's  ----> \\
\\
itsfoss\$ declare -i SUM=0\\
itsfoss\$ while read X; do SUM+=\$X; done < <(sed -E s/\^0+// sample.data)		replace first character if 0 with space(?)\\
itsfoss\$ echo ''Sum is: \$SUM''\\
Sum is: 536\\
itsfoss\$ \\
\\
\\
** Solution 2 : specify the base to be 10  ----> \\
\\
If we look at \\
itsfoss\$ echo \$((071))\\
57\\
itsfoss\$ echo \$((8\#071))\\
57\\
itsfoss\$ echo \$((10\#071))\\
71\\
\\
\\
We see that we can specify base with \#10 , hence:\\
\\
itsfoss\$ declare -i SUM=0\\
itsfoss\$ kwrite sample.data \\
itsfoss\$ while read X; do SUM+=\$((10\#\$X)); done < sample.data\\
itsfoss\$ echo ''Sum is: \$SUM''\\
Sum is: 536\\
itsfoss\$ \\
\\
\\
=====================================================================================\\
=====================================================================================\\
*****************  Challenge 3: My command outputs are in the wrong order ! ******************  \\
\\
Lets make a function called probe()\\
Note: 	ping flags  - q  quite  -c count  -n  numeric output only\\
		Round-trip time (rtt) is the duration from browser sends to receives response from a server\\
\\
itsfoss\$ probe() (\\
> ping -qnc2 www.google.com}{\large  | \\\\
>  grep rtt \& \\\\
>  date +''OK \%D \%T''\\
> )\\
itsfoss\$ rm -f log\\
itsfoss\$ probe >> log\\
itsfoss\$ cat log\\
OK 11/23/18 11:51:22\\
rtt min/avg/max/mdev = 22.067/22.510/22.954/0.468 ms\\
\\
\\
But what supposed to happen is date given AFTER the rtt time?\\
\\
The error is the '\&'      should be    grep rtt \&\& \\\\
\\
ie do the 'date' command after the rtt command is run ( '\&\&') NOT do in background ( '\&' )\\
\\
Hence first\\
\\
itsfoss\$ rm -f log      to get rid of old result\\
\\
then fix solution\\
\\
itsfoss\$ probe() ( ping -qnc2 www.google.com}{\large  |  grep rtt \&\&  date +''OK \%D \%T''; )\\
itsfoss\$ probe >> log\\
itsfoss\$ cat log\\
rtt min/avg/max/mdev = 22.177/22.728/23.280/0.571 ms\\
OK 11/23/18 12:43:01\\
itsfoss\$ \\
\\
Now date is after the rtt, because the time taken to get the date \\
takes considerably less time than pinging Googles server!\\
\\
\\
When you have race conditions bugs are not always this obvious.\\
It may be that you ping 2 servers, not a date command, then its really hard to spot!\\
\\
\\
=====================================================================================\\
=====================================================================================\\
*****************  Challenge 4:     ******************  \\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
 \\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
}151
\hypertarget{bash_script_examples}{\section {Bash Script examples}}
https://askubuntu.com/questions/760823/how-can-i-update-all-snap-packages\\
\\
\#!/bin/bash\\
ROOT\_UID=''0''\\
\\
\#Check if run as root\\
if [ ''\$UID'' -ne ''\$ROOT\_UID'' ] ; then\\
        echo ''You must be root to do that!''\\
        exit 1\\
fi\\
\\
snap list | awk -F'' '' '\{if (\$1 \&\& NR>1) \{ system(''snap refresh '' \$1 '' 2>/dev/null'') \}\}'\\
\\
\\
\\
358
\hypertarget{change_user_agent_in_firefox}{\section {Change User Agent in Firefox}}
https://winaero.com/blog/change-user-agent-chrome/\\
\\
Not available for Linux here but can get correct Mac value eg\\
\\
Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:46.0) Gecko/20100101 Firefox/46.0\\
\\
or\\
\\
Mozilla/5.0 (Macintosh; Intel Mac OS X 10\_11\_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.80 Safari/537.36\\
\\
If you don't log out this makes Youtube work\\
\\
\\
or\\
\\
Chrome for Android Tablet\\
Mozilla/5.0 (Linux; Android 4.3; Nexus 7 Build/JSS15Q) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.80 Safari/537.36\\
\\
\\
Chrome Android Mobile\\
Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.80 Mobile Safari/537.36\\
\\
\\
Microsoft Edge Windows \\
(Removes Dark Theme option but download size good)\\
\\
Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.10240\\
\\
\\
\\
Chrome On Windows\\
Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.80 Safari/537.36\\
\\
Again changing it without restarting Firefox, allows video size change but rest of screen is unusable\\
\\
\\
Also\\
\\
Look at 'About' in Falkon browser and copy the user agent\\
\\
Mozilla/5.0 (X11; Linux x86\_64) AppleWebKit/537.36 (KHTML, like Gecko) Falkon/3.0.1 Chrome/65.0.3325.230 Safari/537.36\\
\\
\\
In firefox\\
1) about:config\\
\\
accept risk\\
\\
2) search for \\
general.useragent.override\\
\\
If doesn't exist \\
mouse right click --> new --> string --> enter 'general.user.agent'\\
\\
paste in up-to-date Chrome user agent value eg\\
\\
Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:46.0) Gecko/20100101 Firefox/46.0\\
\\
Will now permanently be set to this until \\
\\
\\
(see also https://www.maketecheasier.com/change-user-agents-chrome-firefox-edge/ )\\
\\
217
\hypertarget{checking_sha256_and_md5sum_checksums}{\section {Checking Sha256 and md5sum checksums}}
{\large \\
\\
\$ echo \$((ee0c451efooobarxxxx - ee0c451efooobarxxxx))\\
0\\
tomdom@iMac:\~/Downloads\$ echo \$((ee0c451efooobarxxxx - \$(sha256sum lineage-14.1-20190107-nightly-falcon-signed.zip | cut -d' ' -f1) ))\\
\\
-----\\
\\
echo \$((c3132xxxxfoosumxxxxx - \$(md5sum mysql-workbench-community\_8.0.15-1ubuntu18.04\_amd64.deb | cut -d' ' -f1) ))\\
}228
\hypertarget{chrome_dev_tool_notes}{\section {Chrome DEV TOOL notes}}
{\large Often useful to go into incognito mode to avoid issues with extensions.\\
\\
Use 'resume script extension' 'arrow' or F8 to skip to 'valid' JS code if can't use incognito\\
\\
Can set say\\
Event listener Breakpoints - eg' 'mouse -> click'\\
\\
To investigate a function further can use a 'step into ' next function call 'down arrow'\\
\\
If confident function is behaving as expected then can 'step over next function call' 'curved arrow' \\
\\
Can Click a line for a break point and then 'resume execution' to get code to run up to a line\\
Code will run up to (but not including) a break point\\
\\
\\
Use 'Watch' to set up simple queries eg 'typeof foo' where foo is a variable\\
\\
Press 'escape' to get console up - this will contain all \hyperlink{variables}{variables}}{\large  that are currently in scope\\
\\
CTR+L to 'clear console' (same as Linux) or console.clear()\\
\\
Use CTL+S to save (This save is just in browser no main file!!!)\\
\\
Click ''Deactivate breakpoints''  arrow with line going through it. So can test without removing breakpoints\\
\\
\\
Right Click -> Brek-point  To get 'edit breakpoints' and add conditions eg. fooBar === ''Tom''\\
\\
Right-Click  anywhere under Breakpoints panes to disable breakpoints\\
\\
DOM Breakpoints - click on an element, then right hand click to set a break point\\
e.g. 'break on -> subtree modifications\\
\\
Subtree modifications. \\
Triggered when a child of the currently-selected node is removed or added, or the contents of a child are changed.\\
\\
Attributes modifications: \\
Triggered when an attribute is added or removed/changed on the currently-selected node,\\
\\
Node Removal: \\
Triggered when the currently-selected node is removed.\\
\\
 \\
XHR Breakpoints - for Ajax and fetch API's\\
\\
Event listener breakpoints - eg mouse 'click' \\
\\
\\
----------------\\
\\
\%c\\
console.log('\%c  some text goes here', 'font-size:20px; background:red' )\\
\\
console.warn   console.error   console.info      -->   for text\\
\\
console.assert (p.classList.contains('mymessage), 'message problem')\\
\\
console.group\\
\\
console.dir\\
\\
console.time\\
\\
console.table\\
\\
}1981
\hypertarget{collabara_and_nextcloud_install}{\section {Collabara and Nextcloud install}}
{\Large }\\
\\
============================================================================{\large \\
Install Apache2}\\
\\
	\$ {\large sudo apt install curl software-properties-common apache2\\
\\
Install \hyperlink{docker}{Docker}}{\large   (show errors, silent -sS\\
\\
	\$ sudo curl -sS https://get.docker.com/}{\large  | sh\\
\\
Add user 'tom'\\
\\
	\$ sudo usermod -aG \hyperlink{docker}{docker}}{\large  tom\\
\\
Get Collabora\\
\\
	\$ sudo \hyperlink{docker}{docker}}{\large  pull collabora/code\\
\\
Run \hyperlink{docker}{docker}}{\large  (replace to your Nextcloud domain or domain what will connect to collabora)\\
\\
	\$ sudo \hyperlink{docker}{docker}}{\large  run -t -d -p 127.0.0.1:9980:9980 -e 'domain=example\\\\.tab\\\\.digital' --restart always --cap-add MKNOD collabora/code\\
\\
Check if \hyperlink{docker}{docker}}{\large  container is running\\
\\
	\$ sudo \hyperlink{docker}{docker}}{\large  ps\\
\\
Enable Apache modules\\
\\
	\$ sudo a2enmod proxy\\
	\$ sudo a2enmod proxy\_wstunnel\\
	\$ sudo a2enmod proxy\_http\\
	\$ sudo a2enmod ssl\\
\\
Install Certbot for SSL\\
\\
	\$ sudo apt update\\
	\$ sudo apt install python-certbot-apache\\
\\
Run Certbot\\
\\
	\$ sudo certbot --apache\\
\\
Type information\\
\\
	email\\
	agree\\
	yes/no\\
	type collabora server hostname2 -redirect to SSL\\
[eg.  tom.tab.digital  ]\\
\\
Edit Apache configuration file (add configuration from these comments)\\
\\
	\$ sudo nano /etc/apache2/site-available/000-default-le-ssl.conf}{\large \\
\\
Restart apache and check status\\
\\
	\$ sudo systemctl restart apache2\\
	\$ sudo systemctl status apache2\\
\\
\\
	Add Collabora App in Nextcloud\\
		http://example.tab.digital}{\large    (in this example) \\
		username: admin\\
		password: ?\\
		\\
	Configure Collabora online \\
		In NextCloud --> top right username icon \\
								--> Apps --> Office \&Text --> Collabora Online enable --> \\
								--> Settings --> Collabora online --> in Collabora Online Server enter http://tom.tab.digital}{\large  --> apply\\
\\
	Test\\
		In Nextcloud --> top left 'Files' --> ' + ' --> new Spreadsheet (create one)--> click and should open in Collabora\\
\\
	BUT - IF NOT Connecting !?  Why?\\
		- check container log (with the log you can see error and troubleshoot)\\
			\$ sudo \hyperlink{docker}{docker}}{\large  ps\\
\\
		- copy \hyperlink{docker}{docker}}{\large  container ID\\
			\$ sudo \hyperlink{docker}{docker}}{\large  logs (paste ID here)\\
\\
		- Restart \hyperlink{docker}{docker}}{\large  container\\
			\$ sudo \hyperlink{docker}{docker}}{\large  restart (paste ID here)\\
			eg \$ sudo \hyperlink{docker}{docker}}{\large  restart adc1232456efd\\
\\
====================================================================\\
\\
}\textbf{\textit{{\Large Install NextCloud on a Digital Ocean Droplet}}}{\large \textbf{*** Create a Digital Ocean Droplet ***}}{\large \\
\\
	Create a Digital Ocean account\\
\\
	From menu create a new droplet --> 18.04 LTS --> lowest cost\\
\\
	Choose London region\\
\\
	Choose a hostname eg, toms-nextcloud-demo\\
\\
	create the droplet --> press large create button\\
\\
}
\begin{itemize}
\item 
\begin{itemize}
\item {\large Digital Ocean now email the password}
\item {\large You then \hyperlink{ssh___and_sshfs}{SSH   and SSHFS}}{\large  into this virtual server}
\end{itemize}

\end{itemize}
{\large \\
	copy the IP address of the created droplet called \\
		'toms-nextcloud-demo' eg. 1.2.3.4\\
\\
	Open up email in preparation\\
\\
	In terminal, login at that IP address as root\\
\\
		\$root@\hyperlink{ssh___and_sshfs}{SSH   and SSHFS}}{\large  1.2.3.4\\
\\
	copy the emailed password into the terminal\\
\\
	Update + upgrade everything\\
\\
		\$ sudo apt update \&\& sudo apt upgrade \&\& sudo apt autoremove\\
\\
\\
*** \textbf{Install Apache web server}}{\large  ***\\
\\
	\$ sudo apt install apache2\\
\\
	Now start it up\\
	\$ systemctl start apache2\\
\\
	and enable it so whenever system turns on Apache2 automatically starts up\\
	\$ system enable apache2\\
\\
	In Firefox got to url 1.2.3.4\\
	Should see the Apache2 web server default page\\
	(\$ sudo systemctl stop apache2   -- will kill this page)\\
\\
	\\
*** Install MariaDB and secure***\\
\\
	\$ apt install mariasdb-server   (no need for sudo if we are logged in as root)\\
	say yes to dependencies\\
\\
	secure the installation\\
	\$ mysql\_secure\_installation\\
\\
	set a mariadb password (enter for none)\\
\\
	Accept defaults / yes\\
	\\
	--------------------------------------------------------------------\\
	NOTE:\\
	Referring to the NextCloud Administration Manual --\\
		'' Example installation on Ubuntu 18.04 LTS server ''\\
	https://docs.nextcloud.com/server/15/admin\_manual/installation/source\_installation.html\#example-installation-on-ubuntu-18-04-lts-server}{\large \\
\\
	Shows how you can install NextCloud using a Snap\\
	\$ sudo snap install nextcloud\\
\\
	BUT: To install 'manually'\\
	\$ apt-get install apache2 mariadb-server libapache2-mod-php7.2\\
	\$ apt-get install php7.2-gd php7.2-json php7.2-mysql php7.2-curl php7.2-mbstring\\
	\$ apt-get install php7.2-intl php-imagick php7.2-xml php7.2-zip\\
	--------------------------------------------------------------------\\
\\
\\
*** install PHP  - bothApache and MySQL***\\
\\
	\$ apt install php libapache2-mod-php7.2 php-mysql\\
(if this fails)\\
	\$ apt install php libapache2-mod-php php-mysql\\
	\\
	accept dependencies\\
\\
*** PHP MyAdmin - not strictly necessary but may be helpful)\\
\\
	\$ apt install phpmyadmin\\
\\
	(configure for Apache2 in terminal menu option)\\
\\
	Set another separate password, \\
	for phpMyAdmin to use to authenticate itself with MariaDB\\
\\
	Now in Firefox browser, got to\\
	http://1.2.3.4/phpmyadmin/}{\large \\
\\
	NOTE: MariaDB does NOT allow root login from \\
	\\
	Hence go into the SQL database\\
	\$ mariadb\\
	> CREATE DATABASE NEXTCLOUD;\\
	> CREATE USER nextcloud IDENTIFIED BY 'p@ssc0de';\\
	> GRANT USAGE ON *.* TO nextcloud@localhost IDENTIFIED BY 'p@ssc0de';\\
	> GRANT ALL privileges ON nextcloud.* TO nextcloud@localhost;\\
	> FLUSH PRIVILEGES   \\
	(flush makes sure they are applied)\\
	\\
	Now go back to 1.2.3.4/myphpadmin in firefox\\
	username:nextcloud\\
	password: p@ssc0de\\
\\
	NOW we can see our 'nexcloud' database in nextcloud\\
\\
	We may create tables etc here now if we wish\\
	\\
\\
	> quit;\\
\\
\\
*** Install PHP dependencies recommended by NextCloud example Install ***\\
\\
	see install example above\\
\\
	\$ apt install php7.2-gd php7.2-json php7.2-mysql php7.2-curl php7.2-mbstring\\
	\$ apt install php7.2-intl php-imagick php7.2-xml php7.2-zip\\
\\
	Ubuntu 18.04 ships with PHP 7.2 so can specify 7.2, \\
	or just remove the 7.2 and accept defaults:\\
\\
	\$ apt install php-gd php-json php-mysql php-curl php-mbstring\\
	\$ apt install php-intl php-imagick php-xml php-zip\\
\\
\\
*** Install NextCloud ***\\
	https://nextcloud.com/install/\#}{\large \\
	download for server --> Archive file --> doload as zip or tar.bz2 \\
	by copying the download link for the tarball \\
	(eg. https://download.nextcloud.com/server/releases/nextcloud-15.0.2.tar.bz2}{\large  )\\
\\
	\# pwd \\
	/\\
\\
	So in the root directory of the Remote server, logged in as root\\
\\
	\$ wget https://download.nextcloud.com/server/releases/nextcloud-15.0.2.tar.bz2}{\large \\
\\
	\$ tar -xvf nextcloud-15.0.2.tar.bz2\\
\\
\\
*** Move NextCloud to www-data web server directory***\\
\\
	from \\
	\$ls -al\\
	we see that 'nextcloud' has no owner and no group !!\\
\\
	We can use Ubuntu's default 'web server' www-data user, which is what the \\
	web server directory in /var/www/html}{\large  should, by convention, be set to\\
\\
	This is the default that Apache serves from\\
\\
	Hence we can move the 'nextcloud' install to /var/www/html}{\large \\
\\
	(may need to \$ mkdir too)\\
 \\
	\# cd nextcloud\\
	\# mv ./* /var/www/html/}{\large \\
	\# ls -al\\
	\# mv ./.htaccess /var/www/html/}{\large \\
	\# mv ./.user.ini /var/www/html/}{\large \\
\\
	\# cd /var/www/html/}{\large \\
\\
	\# ls a-l\\
\\
\\
*** Set www-data user and group ***\\
\\
	\# chown -R www-data:www-data /var/www/html}{\large \\
\\
	also to hidden files\\
	\# chown www-data:www-data /var/www/html/.htaccess}{\large \\
	\# chown www-data:www-data /var/www/html/.user.ini}{\large \\
\\
	\\
	checking all www-data owned\\
	\# ls -al /var/www/html/}{\large \\
\\
\\
*** NextCloud should be up and running ***\\
	\\
	\# systemctl restart apache2\\
\\
	Go in Firefox browser to http://1.2.3.4}{\large \\
	we see that at 1.2.3.4/index.php we have NextCloud up and running !\\
\\
	And we can create a login\\
	BUT - we need to create a secure HTTPS login (not HTTP)\\
\\
	Hence we need to setup SSL/TLS\\
\\
*** Set up SSL/TLS ***\\
\\
''Transport Layer Security (TLS), and its now-deprecated predecessor, Secure Sockets Layer (SSL), are cryptographic protocols designed to provide communications security over a computer network. Several versions of the protocols find widespread use in applications such as web browsing, email, instant messaging, and voice over IP (VoIP). Websites can use TLS to secure all communications between their servers and web browsers. ''\\
\\
We can do this using lets-encrypt\\
https://letsencrypt.org/getting-started/}{\large \\
''To enable HTTPS on your website, you need to get a certificate (a type of file) from a Certificate Authority (CA). Let’s Encrypt is a CA. In order to get a certificate for your website’s domain from Let’s Encrypt, you have to demonstrate control over the domain. With Let’s Encrypt, you do this using software that uses the ACME protocol, which typically runs on your web host.''\\
\\
	Will need Secure Shell Access i.e. \hyperlink{ssh___and_sshfs}{SSH   and SSHFS}}{\large  \\
	or a control panel like cPanel, Plesk, or WordPress\\
\\
	We can use \hyperlink{ssh___and_sshfs}{SSH   and SSHFS}}{\large \\
\\
	We also need a domain name\\
\\
==> Go to your domain registry eg GoDaddy, one.com, 123-reg etc\\
\\
Assuming already have a domain name purchased !!! (eg. tom1to1.com)\\
and have a DNS provider (maybe the same company)\\
\\
	Create a DNS record\\
	A record\\
	hostname: toms-nextcloud-demo    (hence url:   toms-nextcloud-demo.tom1to1.com)\\
		NOTE hostname:@   (for no sub-domain)\\
	IP address: 1.2.3.4\\
\\
	Apply the settings and wait...\\
\\
	To check on progress \\
	\$ ping toms-nextcloud-demo.tom1to1.com\\
	\\
	Once pings o.k. then in browser got to 'toms-nextcloud-demo.tom1to1.com'\\
\\
	So now can see NextCloud but with a domain name!\\
\\
	BUT- Still not secure ! - install a client for lets-encrypt\\
	( see https://certbot.eff.org/lets-encrypt/ubuntubionic-apache}{\large  )\\
\\
	For Apache on Ubuntu 18.04\\
\\
	\$ sudo apt-get update\\
	\$ sudo apt-get install software-properties-common\\
	\$ sudo add-apt-repository universe\\
	\$ sudo add-apt-repository ppa:certbot/certbot\\
	\$ sudo apt-get update\\
	\$ sudo apt-get install python-certbot-apache \\
\\
	\$ sudo certbot --apache\\
	\\
	enter email address: tom@tom1to1.com}{\large  etc etc\\
\\
	BUT this may not work !\\
	\\
	/var/www/html/}{\large  is the default dir for Apache \\
	Presently everything is being directed to this directory\\
\\
	We could create another dir just for NextCloud, but in this tutorial case will add\\
	the domain name to the default directory\\
\\
	\$ nano /etc/apache2/sites-available/000-default.conf}{\large \\
\\
	looks like:\\
	-----\\
	\#\\
	\#\\
	\# However, you must set it for any further virtual host explicitly.\\
	\# ServerName www.example.com}{\large \\
	\\
	ServerAdmin webmaster@localhost\\
	DocumentRoot /var/www/html}{\large \\
	-----\\
\\
	Amend this Server name / admin comment to\\
	-----\\
	\#\\
	\#\\
	\# However, you must set it for any further virtual host explicitly.\\
	ServerName toms-nextcloud-demo.tom1to1.com\\
	\\
	ServerAdmin tom@tom1to1.com}{\large \\
	DocumentRoot /var/www/html}{\large \\
	-----\\
	\\
	save and restart Apache server\\
\\
	\# systemctl restart apache2\\
\\
	Again running certbot, this should now work o.k .\\
\\
	\# certbot --apache\\
	leave option blanks (enter)\\
\\
	We should now have created SSL certificate at a virtual host\\
\\
	Can choose \\
		1: No redirect\\
		2: Redirect\\
	Typically choose 2: Redirect\\
\\
	\\
	Refresh your nextcloud url and HTTPS cert should be set up!!\\
\\
	\\
*** NextCloud login/ setup ***\\
\\
	Go to NexctCloud url eg. \\
		toms-nexctcloud-demo.tom1to1.com\\
\\
	Enter a user and password\\
	for this tutorial\\
	user: admin\\
	password: passwd\\
\\
	May wish to change the data folder (where all users documents and are \\
	actually stored) from /var/www/html/data}{\large   to something else.\\
	As we want to serve NextCloud, not the actual documents in Nexcloud\\
\\
	Lets create a new directory in the server root directory\\
	\# mkdir /nextcloud-data\\
	and set its ownership properties\\
	\# chown www-data:www-data /nextcloud-data \\
\\
	Note its still owned by www-data, so Apache can use it ok\\
	BUT as its outside the web server directory, it wont be served !\\
\\
\\
	In NexctCloud url eg. \\
		toms-nexctcloud-demo.tom1to1.com\\
	\\
	change Data folder to /nextcloud-data\\
\\
	Set MariaDB database (from phpMyAdmin above)\\
		\\
		Database user:nextcloud\\
		Password: p@ssc0de\\
		Database name: nextcloud\\
  \\
	click FINISH SETUP\\
\\
	\\
	NextCloud should now be functioning !\\
\\
\\
*** Fixing Warnings and security issues ***\\
	\\
	2MB memory limit fix\\
\\
		\# nano /etc/php/7.2/apache2/php.ini}{\large \\
\\
		search for 'uploads'  ( crtl+w ) to find and change from 2M to 512M\\
		---------\\
		upload\_max\_filesize = 512M\\
		---------\\
	\\
		search for 'memory\_limit'\\
		---------\\
		memory\_limit = 512M\\
		---------\\
\\
		search for 'post\_max\_size'\\
		---------\\
		post\_max\_size = 512M\\
		---------\\
		ctrl+x and Y to save file\\
	\\
		\# systemctl restart apache2\\
\\
\\
	Strict Transport Security\\
\\
		open suggested security tips in browser\\
		scroll down info to ''Enable HTTP Strict Transport Security''\\
		https://docs.nextcloud.com/server/stable/admin\_manual/configuration\_server/harden\_server.html\#enable-hsts-label}{\large \\
\\
		We need to copy and paste in the suggested Apache VirtualHost file settings ie.\\
\\
				++++++++++++++++++++++++++++++++++++\\
				<VirtualHost *:443>\\
  					ServerName cloud.nextcloud.com\\
    						<IfModule mod\_headers.c>\\
      							Header always set Strict-Transport-Security ''max-age=15552000; includeSubDomains''\\
    						</IfModule>\\
 				</VirtualHost>\\
				++++++++++++++++++++++++++++++++++++\\
\\
		and add ' ; preload ' to indicate should only be a https site \\
		aka''We recommend the additional setting ; preload to be added to that header.''\\
\\
		(note: we have enabled lets-encrypt)\\
		\# nano /etc/apache2/sites-enabled/000-default-le-ssl.conf}{\large \\
		\\
		Amend this Server name / admin comment to\\
		-----\\
		ServerName toms-nextcloud-demo.tom1to1.com\\
\\
    		<IfModule mod\_headers.c>\\
      			Header always set Strict-Transport-Security ''max-age=15552000; includeSubDomains; preload''\\
    		</IfModule>\\
	\\
		ServerAdmin tom@tom1to1.com}{\large \\
		DocumentRoot /var/www/html}{\large \\
		-----\\
	\\
		save and exit  (ctrl+x)\\
\\
		enables the header module within the apache2 configuration\\
		\# a2enmod headers\\
\\
		\# systemctl restart apache2\\
\\
		\\
	Fix 'well-known/caldav'\\
\\
		''CardDAV is an open Internet protocol for syncing contacts, like IMAP for email and CalDAV for calendars.\\
		It’s built around the HTTP-based WebDAV protocol and uses vCard format for contact data.''\\
\\
		browsing to \\
		https://toms-nextcloud-demo.tom1to1.com/well-known/caldav}{\large \\
\\
		'Not found'\\
\\
		this is likely because /var/www/html/.htaccess}{\large  is not being accessed by Apache\\
\\
		\# cd /var/www/html/}{\large \\
		\# nano .htaccess\\
\\
		and search for well-known, we see RewriteRule 's for well-known/cardav and /caldav\\
\\
		To fix:\\
		\# nano /etc/apache2/sites-enabled/000-default-le-ssl.conf}{\large \\
		\\
		Amend this Server name / admin comment to\\
		-----\\
		ServerName toms-nextcloud-demo.tom1to1.com\\
\\
    		<IfModule mod\_headers.c>\\
      			Header always set Strict-Transport-Security ''max-age=15552000; includeSubDomains; preload''\\
    		</IfModule>\\
\\
		<Directory /var/www/html/>}{\large \\
				Options +FollowSymlinks\\
				AllowOverride All\\
		</Directory>\\
	\\
		ServerAdmin tom@tom1to1.com}{\large \\
		DocumentRoot /var/www/html}{\large \\
		-----\\
\\
		Save and exit\\
		( Note: 'AllowOverride All'  --> look for .htaccess and allow it to override settings )\\
		\\
		\# systemctl restart apache2\\
\\
		refresh\\
		browsing to \\
		https://toms-nextcloud-demo.tom1to1.com/well-known/caldav}{\large \\
\\
		We should now see the WebDAV interface notice\\
\\
		refreshing errors\\
\\
\\
	Fix 'No memory cache has been configured'\\
\\
			This is an option if using NextCloud in a heavily used context\\
\\
		Search NextCloud manual for 'Configuring memory caching'\\
		https://docs.nextcloud.com/server/stable/admin\_manual/configuration\_server/caching\_configuration.html?highlight=configuring\%20memory\%20caching}{\large \\
\\
		Use APCu as easy on smaller installs\\
\\
		'' APCu is a data cache, and it is available in most Linux distributions. \\
		On Red Hat/CentOS/Fedora systems install php-pecl-apcu. \\
		On Debian/Ubuntu/Mint systems install php-apcu.\\
\\
		After restarting your Web server, add this line to your config.php file: 'memcache.local' => '\\OC\\Memcache\\APCu',  ''\\
\\
		\# apt install php-apcu\\
		\# systemctl restart apache2\\
\\
		\# nano config/config.php\\
		\\
		config.php snipet\\
		----------------------\\
		  'installed' => true,\\
		  'memcache.local' => '\\OC\\Memcache\\APCu',\\
		);\\
		----------------------\\
\\
\\
		save and exit  ( ctrl+x)\\
\\
		refresh browser\\
\\
\\
		\\
	Fix 'PHP OPcache is not properly configured'\\
\\
		From NextCloud manual https://docs.nextcloud.com/server/stable/admin\_manual/configuration\_server/server\_tuning.html?highlight=php\%20opcache}{\large \\
			\\
	---------------\\
	'' The OPcache improves the performance of PHP applications by caching precompiled bytecode. \\
	We recommend at least following settings:\\
\\
			opcache.enable=1\\
			opcache.enable\_cli=1\\
			opcache.interned\_strings\_buffer=8\\
			opcache.max\_accelerated\_files=10000\\
			opcache.memory\_consumption=128\\
			opcache.save\_comments=1\\
			opcache.revalidate\_freq=1\\
	''	\\
	-----------------\\
\\
		\# nano /etc/php/7.2/apache2/php.ini}{\large \\
	\\
		search (ctrl+W) for 'opcache.enable'\\
		\\
		check they are not commented out  and at suggested settings eg \\
		opcache.enable=1 \\
			NOT \\
		;opcache.enable=1\\
\\
		save and exite\\
\\
		\# systemctl restart apache2\\
\\
		refresh browser\\
\\
	\\
\\
	Fix 'Some columns in the database are missing conversion to big int'\\
\\
		copy the command ' occ db:convert-filecache-biginit '\\
		\\
			\# cd /var/www/html}{\large \\
\\
		occ is not on the PATH variable, so need can't run as '\# occ' so run via ' \# ./occ ' ie the local path;,\\
		But its also a php file;\\
	And we need to go in as the 'www-data' superuser (not root)\\
\\
			\# sudo -u www-data php ./occ db:convert-filecache-biginit\\
\\
	\\
	Refresh NextCloud\\
\\
	********* All check passed !  (hopefully) ********\\
\\
\\
=====================================================================\\
=====================================================================\\
\\
SETTING UP Collabora Online Development \\
\\
\$ sudo apt update \&\& sudo apt upgrade\\
\\
*** Install \hyperlink{docker}{Docker}}{\large  CE ***\\
\\
	\hyperlink{docker}{Docker}}{\large  has its own repo for Ubuntu\\
\\
	https://docs.docker.com/install/linux/docker-ce/ubuntu/}{\large \\
\\
	\$ sudo apt install apt-transport-https ca-certificates curl software-properties-common\\
\\
\\
	Now add dockers official GPG key using curl\\
\\
	\# curl -fsSL https://download.docker.com/linux/ubuntu/gpg}{\large  | sudo apt-key add -\\
\\
	Verify that you now have the key with the fingerprint \\
	9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88, \\
	by searching for the last 8 characters of the fingerprint.\\
\\
	\# apt-key fingerprint 0EBFCD88\\
\\
	Add \hyperlink{docker}{Docker}}{\large  repo\\
\\
	\# add-apt-repository \\\\
   	''deb [arch=amd64] https://download.docker.com/linux/ubuntu}{\large  \\\\
   	\$(lsb\_release -cs) \\\\
   	stable''\\
\\
	Install \hyperlink{docker}{Docker}}{\large \\
	\# sudo apt update\\
	\# sudo apt-get install \hyperlink{docker}{docker}}{\large -ce\\
\\
\\
	Check \hyperlink{docker}{docker}}{\large  is running\\
	\$ systemctl status \hyperlink{docker}{docker}}{\large \\
\\
	OR\\
	\# \hyperlink{docker}{docker}}{\large  -ps\\
\\
*** Need a sub-domain for ' Collabora Online Server ' *****\\
\\
	Got to 123-reg, GoDaddy or one.com and create a new \\
	DNS entry with an A record as before with NextCloud install\\
\\
	- a hostname eg  ' office-online.tom1to1.com '\\
	- ip address  (possibly just copy from Digital Ocean Droplet)\\
	This IP address could be the same as the NextCloud one eg 1.2.3.4\\
\\
\\
*** Install Collabora Office Online ***\\
\\
	\# \hyperlink{docker}{docker}}{\large  pull collabora/code\\
\\
\\
*** Run \hyperlink{docker}{Docker}}{\large  Collabora ***\\
\\
	running a local server at 127.0.0.1:9980:9980 on the IP address 1.2.3.4  \\
\\
	\# \hyperlink{docker}{docker}}{\large  run -t -d -p 127.0.0.1:9980:9980 -e 'domain=toms-nextcloud-demo\\\\.tom1to1\\\\.com' --restart always --cap-add MKNOD collabora/code\\
\\
*** Setup Apache for Collabora ****\\
\\
	\# a2enmod proxy\\
	\# a2enmod proxy\_wstunnel\\
	\# a2enmod proxy\_http\\
	\# a2enmod ssl\\
\\
\\
	Create a virtual host\\
\\
	\\
	\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
}18676
\hypertarget{create_a_mount_in_linux_termianl}{\section {Create a Mount in Linux termianl}}
/origin/path/destination/path\\
\\
\# To mount Usb disk as user writable:\\
mount -o uid=username,gid=usergroup /dev/sdx/mnt/xxx\\
\\
\# To mount a remote NFS directory\\
mount -t nfs example.com:/remote/example/dir /local/example/dir\\
\\
\# To mount an ISO\\
mount -o loop disk1.iso /mnt/disk148
\hypertarget{create_ssh_for_github}{\section {Create SSH for Github}}
Create SSH   and SSHFS for Github\\
\\
https://linuxize.com/post/how-to-set-up-ssh-keys-on-ubuntu-1804/https://www.digitalocean.com/community/tutorials/how-to-set-up-ssh-keys-on-ubuntu-1804{\large To see if an \hyperlink{ssh___and_sshfs}{SSH   and SSHFS}}{\large  keys and directory have already been created\\
\\
\$ ls -l \~/.ssh/id\_*.pub}{\large \\
-rw-r--r-- 1 tomdom tomdom 743 Jun 13 11:56 /home/tomdom/.ssh/id\_rsa.pub}{\large \\
\\
To create a new publiv and private key (longer 4096 version)\\
\$ \hyperlink{ssh___and_sshfs}{SSH   and SSHFS}}{\large -keygen -t rsa -b 4096 -C ''tom@appijumbo.com''}{\large \\
	Generating public/private rsa key pair.\\
	Enter file in which to save the key (/home/tomdom/.ssh/id\_rsa}{\large )\\
	/home/tomdom/.ssh/id\_rsa}{\large  already exists.\\
	Overwrite (y/n)? y\\
	Enter passphrase (empty for no passphrase): \\
	Enter same passphrase again: \\
	Your identification has been saved in /home/tomdom/.ssh/id\_rsa.}{\large \\
	Your public key has been saved in /home/tomdom/.ssh/id\_rsa.pub.}{\large \\
	The key fingerprint is:\\
	SHA256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx tom@appijumbo.com}{\large \\
	The key's randomart image is:\\
	+---[RSA 4096]----+\\
	|       11  .=o   		|\\
	|       .o .o...  		|\\
	|      .. .. o... 		|\\
	|     . o D o == .	|\\
	|      = X   O-.+.	|\\
	|     . o . +.=*oo	|\\
	|    .  iii. ++.= 	|\\
	|     .  *o+...o  		|\\
	|      .. +..     		|\\
	+----[SHA256]-----+\\
\\
\\
For a rough check to see if keys exist\\
\$ ls \~/.ssh/id\_*}{\large /home/tomdom/.ssh/id\_rsa}{\large /home/tomdom/.ssh/id\_rsa.pub}{\large \\
\\
\\
Private and public keys have been created. \\
To see the public key 'cat' it out ie\\
\\
\$ cat \~/.ssh/id\_rsa.pub}{\large \hyperlink{ssh___and_sshfs}{SSH   and SSHFS}}{\large -rsa ABCDxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\\
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\\
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx== tom@appijumbo.com}{\large \\
\\
copy this key and paste into the Github \hyperlink{ssh___and_sshfs}{SSH   and SSHFS}}{\large  textarea , where it asks for the key}\\
\\
an277
\hypertarget{curl_\&_wget}{\section {Curl & Wget}}
\textbf{{\Large \\
\\
WGET\\
}}{\large \\
\$ wget http://fooBar.com}{\large \textbf{Downloads the index.html page}}{\large  of fooBar.com into the current working directory\\
\\
\\
	and if we do\\
\\
	\$ ls \\
\\
	we should see \\
\\
	index.html\\
\\
	we can see the file size from\\
\\
	\$ du index.html\\
	76K   index.html\\
\\
	or \\
\\
	\$ ls -l index.html\\
\\
\\
Without options, \textbf{Wget is different from Curl}}{\large  whose standard out is to the \textbf{command line not to a file.}}{\large \\
\\
Suppose an ASCII text file called fooText is at http://fooBar}{\large \\
\\
Hence   	\$ wget fooBar === \$ curl -s fooBar >> fooText\\
\\
		and to check if it's ASCII  \\
		\$ file fooText 		\\
		\\
Likewise 	\$ curl http://fooBar}{\large  === \$ wget  ??? (not sure !)\\
\\
\\
\\
\textbf{Download site}}{\large \\
\\
We need to do it '\textbf{recursively'}}{\large  to not just download the index.html but all the files connected to it\\
\\
Note: this downloads the pages recursively up to a maximum of 5 levels deep.\\
\\
\$ wget http://fooBar.com}{\large \textbf{-r}}{\large \\
\\
We should now have the structure of the site, directories and files\\
\\
	We can see this structure with\\
\\
	\$ tree\\
\\
\textit{Deeper ?}}{\large \\
5 levels deep might not be enough to get everything from the site. You can use the -l switch to set the number of levels you wish to go to as follows:\\
\\
\$ wget -r -l10 http://fooBar.com}{\large \\
\\
\\
For ALL levels ie. INFinite recursion you can use the following:\\
\\
\$ wget -r -l inf http://fooBar.com}{\large \\
\\
OR\\
\\
\$ wget -r -l 0 http://fooBar.com}{\large \\
\\
note that 'inf' === '0' [zero] \\
\\
There is still one more problem. You might get all the pages locally but all the links in the pages still point to their original place. It is therefore not possible to click locally between the links on the pages.\\
\\
You can get around this problem by using the -k or --convert-links option which converts all the links on the pages to point to their locally downloaded equivalent\\
\\
--convert-links: After the download is complete, convert the links in the document to make them suitable for local viewing.  This affects not only the visible hyperlinks, but any part of the document that links to external content, such as embedded images, links to style sheets, hyperlinks to non-HTML content, etc.\\
\\
\$ wget \textbf{-r -k}}{\large http://fooBar.com}{\large \textbf{Mirroring a complete site}}{\large \\
If you want to get a complete mirror of a website you can simply use the following switch which takes away the necessity for using the -r -k and -l switches.\\
\\
\$ wget \textbf{-m}}{\large http://fooBar.com}{\large \\
\\
Therefore if you have your own website you can make a complete backup using this one simple command.\\
\\
Example\\
\\
\$ wget \textbf{-r -k -l5}}{\large http://fooBar.com}{\large \textbf{Spidering (basic) a site to discover broken links (404's)}}{\large {\large \\
needs options like\\
\\
\textbf{--spider}}{\large {\large \\
Don't download the pages, just check that they exist\\
\\
\textbf{--no-directories}}{\large  or\textbf{-nd}}{\large {\large     don't create directories\\
\\
\textbf{--wait}}{\large =SECONDS or \textbf{-w}}{\large {\large     wait between retrievals in seconds\\
\\
\textbf{--output-file}}{\large =FILE or\textbf{-o}}{\large {\large \textbf{log messages}}{\large  to FILE (so can see what is broken)\\
\\
\textbf{--no-verbose}}{\large  or \textbf{-nv}}{\large {\large   to turn off verboseness\\
\\
\\
(plus we want it to be recursive for 'all' levels too ie. -r -l inf )\\
\\
Hence a basic 'spider' to find 404's is\\
\\
\$ wget -r --spider -nd -nv -l 1 -w 1 -o testLogFooBar http://fooBar}{\large \textbf{TIP 1: tail -f}}{\large {\large \\
: To see the output as it crawls the web page, open up another terminal, or split it eg ' CTRL+SHIFT+)' then \\
\\
Use \textbf{tail}}{\large  with \textbf{-f follow}}{\large  option, so can see it working !\\
\\
	\$ tail -f testLogFooBar\\
\\
\\
\textbf{Tested on my own site appijumbo.com}}{\large \\
\\
\$ wget -r --spider -nd -nv -l inf -w 2 -o appiLog http://appijumbo.com}{\large \\
\\
split then\\
\\
\$ tail -f appiLog\\
--->\\
2018-04-13 14:05:08 URL:http://www.appijumbo.com/}{\large  [21958/21958] -> ''index.html.tmp.tmp'' [1]\\
Found no broken links.\\
\\
FINISHED --2018-04-13 14:05:08--\\
Total wall clock time: 4.6s\\
Downloaded: 1 files, 21K in 0.03s (728 KB/s)\\
\\
SUCCESS !!\\
\\
\textbf{TIP2: Chron job to keep checking site after launch}}{\large {\large \\
Put this on a Chron job and set an alert to tell you if you get 404 errors or similar!!\\
\\
Use 'notify-send'  (sudo apt install libnotify-bin) to create pop up alert messages \\
\\
	\$ notify-send -i face-wink ''Hello World!''\\
\\
or send an email ( https://bit.ly/2ISD80p}{\large  ) with sendmail, mail, mutt, ssmtp or telnet\\
\\
\\
\\
\\
\\
-------------\\
\\
\\
To download an entire Web site, perhaps for off-line viewing, wget can do the\\
job—for example:\\
\\
\$ wget \\\\
     --recursive \\\\
     --no-clobber \\\\
     --page-requisites \\\\
     --html-extension \\\\
     --convert-links \\\\
     --restrict-file-names=windows \\\\
     --domains website.org \\\\
     --no-parent \\\\
         www.website.org/tutorials/html/}{\large \\
\\
This command downloads the Web site www.website.org/tutorials/html/.}{\large \\
\\
The options are:\\
\\
    --recursive: download the entire Web site.\\
\\
    --domains website.org: don't follow links outside website.org.\\
\\
    --no-parent: don't follow links outside the directory tutorials/html/.\\
\\
    --page-requisites: get all the elements that compose the page (images, CSS and so on).\\
\\
    --html-extension: save files with the .html extension.\\
\\
    --convert-links: convert links so that they work locally, off-line.\\
\\
    --restrict-file-names=windows: modify filenames so that they will work in Windows as well.\\
\\
    --no-clobber: don't overwrite any existing files (used in case the download is interrupted and\\
    resumed).\\
\\
\\
--------\\
wget 'url' just created a new file itself \\
To force wget to send output to desired file by telling wget to output its payload to stdout (with flag -O-) and suppress its own output (with flag -q):\\
\\
wget -qO- 'http://api.openweathermap.org/data/2.5/weather?q=Ellesmere}{\large  Port,uk\&appid=4595334ecc0bf10a9aa1461cc222ef14' >> wgettest-qO-.json \\
\\
\\
--------\\
\\
try\\
wget -qO- 'http://api.openweathermap.org/data/2.5/weather?q=Ellesmere}{\large  Port,uk\&appid=4595334ecc0bf10a9aa1461cc222ef14' >> wgettest2-qO-.json | python -m json.tool >> wgettest2-qO-Prettyjson.json\\
\\
\\
\\
\\
================================================================\\
================================================================\\
\\
\\
\\
------\\
\\
oh-my-zsh has a pp json toll plug-in\\
\\
------\\
\\
A fake ReST api JSON test site :\\
https://jsonplaceholder.typicode.com}{\large \\
\\
-------\\
http://api.openweathermap.org/data/2.5/weather?q=Ellesmere\%20Port,uk\&appid=4595334ecc0bf10a9aa1461cc222ef14}{\large \\
\\
-----\\
\\
\\
\\
================================================================\\
================================================================\\
\\
\\
\\
}\textbf{{\Large CURL\\
}}{\large \\
-----\\
Curl and libcurl - (installed by default in Linux)\\
query url, \\
GET POSt PUT DELETE\\
auth users , \\
save responces to file.\\
Transfer cookies, test speeds etc\\
Good for testing ReST api's\\
\$ curl http://}{\large  xxx    or say  \$ curl http://localhost:3000}{\large \\
-> gives script from browser\\
Testing JSON responce\\
\$ curl http://xxxx}{\large    will give json pacge back -> BUT !\\
\\
\\
\\
----\\
\\
cURL info  https://curl.haxx.se/docs/httpscripting.html}{\large \\
\\
---------\\
\\
curl 'http://api.openweathermap.org/data/2.5/weather?q=Ellesmere}{\large  Port,uk\&appid=4595334ecc0bf10a9aa1461cc222ef14' | python -m json.tool >> test1\\
\\
------\\
curl -o test2.json 'http://api.openweathermap.org/data/2.5/weather?q=Ellesmere}{\large  Port,uk\&appid=4595334ecc0bf10a9aa1461cc222ef14'\\
\\
\\
\\
To get responce header 'i'nformation with the JSON package use:\\
\$  curl -i http://xxxx}{\large \\
and for just the 'head'er 'I'nformation, ie on its own\\
\$ curl -I http://xxxxx}{\large       or    \$ curl --head http://xxxxx}{\large  \\
\\
To GET , POST, PUT (update), DELETE  ie http methods\\
\\
GET\\
\$ curl http://}{\large     is itself a GET\\
\\
POST sending 'd'ata (e.g. a first and last name to an api called xxxxx)\\
\$ curl -d ''first=Tom\&last=Ormiston'' http://}{\large  xxxxx\\
example 2\\
\$ curl -d ''title=myHello\&body=hello world'' https://jsonplaceholder.typicode.com/posts}{\large    \\
\\
PUT (update)\\
we 'request a command ' (-X) to PUT 'd'ata (PUT -d)\\
\$ curl -X PUT -d ''first=Thomas\&last=Ormiston'' http://}{\large  xxxxx\\
example 2\\
curl -X PUT -d ''title=myHello\&body=hello world'' https://jsonplaceholder.typicode.com/posts/99}{\large \\
\\
DELETE\\
we 'request a command ' (-X) to DELETE \\
\$ curl -X DELETE http://xxxxxx}{\large \\
example 2\\
 curl -X DELETE https://jsonplaceholder.typicode.com/posts/99}{\large   \\
\\
For a'u'thentication  -> use 'u'\\
for   username: bob      password:123\\
\$ curl -u bob:123  http://xxxxx}{\large \\
\\
D'o'wnload a file/page - the 'o'utput (also format is prettyfied json)\\
\$ curl -o pic1.jpg http://xxxxx}{\large \\
this image data is downloaded and the output saved in a file automaticly created called pic1.jpg\\
Can also save the output of a JSON packge to a file\\
\$ curl -o jsfile.json http://xxxxx}{\large \\
\\
or example 2 using the fake json rest api tester site:\\
\$ curl -o dowloadJson.json https://jsonplaceholder.typicode.com/posts/6}{\large \\
\\
To save a file, not a GET request as such use capital 'O' ie -O, \\
this doesn't need a filename as it come from the remote url\\
\\
\$ curl -O http://xxxx}{\large     \\
\\
eg, this just downloads a file called 'posts'\\
\$ curl -O https://jsonplaceholder.typicode.com/posts}{\large \\
\\
This is good for downloading images too\\
\$ curl -O http://bit.ly/2v4Dx8t}{\large \\
\\
Dowloading \\
'  -O  ' remote name  ---> Write output to a file named as the remote file\\
'  -o  '  output FILE  ---> Write to FILE instead of stdout\\
\\
RE-DIREDTION   -->   'L'\\
if we do\\
\$ curl http://google.com}{\large    \\
--->\\
<TITLE>302 Moved</TITLE></HEAD><BODY> \\
<H1>302 Moved</H1> \\
The document has moved \\
<A HREF=''http://www.google.co.uk/?gfe\_rd=cr\&ei=YYSVWbqSFa338Aew3Z\_oBw''>here</A>.}{\large  \\
</BODY></HTML>\\
The reason is that the site has moved to www.google.com}{\large \\
Hence we use a re-direct option  ' -L '\\
\$ curl -L http://google.com}{\large    \\
now works ok because to redirects to www.google.com}{\large  automaticly\\
\\
----------\\
File '  T 'ransfersing using  \hyperlink{ftp}{FTP}}{\large    ---> ' T '  flag\\
\\
This needs authentication so use the -u\\
so for this example \\
username: tom@appijumbo.com}{\large    password:1234  file is 'myfile.txt'\\
\\
To upload myfile.txt\\
\$ curl -u tom@appijumbo.com:1234}{\large   -T myfile.txt ftp://ftp.appijumbo.com}{\large \\
\\
To download myfile.txt\\
\$ curl -u tom@appijumbo.com:1234}{\large   -O ftp://ftp.appijumbo.com/myfile.txt}{\large \\
\\
------\\
To install Yarn\\
\\
curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg}{\large  | sudo apt-key add -\\
echo ''deb https://dl.yarnpkg.com/debian/}{\large  stable main'' | sudo tee /etc/apt/sources.list.d/yarn.list}{\large }7096
\hypertarget{disk_utilities__lsblk,_du,_df,_fdisk__(not_dd)}{\section {Disk Utilities  lsblk, du, df, fdisk  (not dd)}}
https://youtu.be/tMVj22EWg6Ahttps://www.youtube.com/watch?v=\_6VJ8WfWI4k\textbf{{\large Lsblk}}\textbf{{\large   ( L}}{\large i\textbf{S}}{\large t \textbf{BL}}{\large oc\textbf{K }}{\large devices\textbf{ )}}{\large \\
\\
List all storage devices in a tree-like format: 	\$ lsblk\\
\\
Also list empty devices:  	\$ lsblk -a\\
\\
Print the SIZE column in bytes not human-readable format:	\$ lsblk -b\\
\\
Output info about filesystems:		\$ lsblk -f\\
\\
Use ASCII characters for tree formatting:	\$ lsblk -i\\
\\
Output info about block-device topology:	\$ lsblk -t\\
  \\
---------------------------------------------------------------------------------------------------\\
\\
\textbf{Fdisk}}{\large \textbf{   F}}{\large ree-up the\textbf{ DISK (manipulate disk partition table)}}{\large \\
\\
list partitions  \$ fdisk -l /dev/sda}{\large \\
\\
delete a partition\\
    \$ fdisk /dev/sda}{\large \\
    Command (m for help): d\\
    Partition number (1-9): XXX\\
\\
---------------------------------------------------------------------------------------------------\\
\\
\textbf{du}}{\large \textbf{   D}}{\large isk\textbf{ U}}{\large sage\textbf{ ( estimate file space usage)}}{\large \\
\\
sort directories/files by size	\$ du -sk *| sort -rn\\
\\
cumulative human readable size	\$ du -sh\\
\\
\\
---------------------------------------------------------------------------------------------------\\
\\
\textbf{df }}{\large \textbf{}}{\large what \textbf{D}}{\large isk is \textbf{F}}{\large ree?\textbf{  ( file system disk space usage )}}{\large \\
\\
Printout disk free space in a human readable format	\$  df -h\\
\\
can use \$ df -h  with \$ ls -lh\\
\\
\$ ls-lh \\
total 2.5M \\
drwxrwxr-x  2 tomdom tomdom 4.0K Sep 19 15:17  bin \\
drwxrwxr-x  6 tomdom tomdom 4.0K Mar 25  2018 'Calibre Library' \\
drwxr-xr-x  2 tomdom tomdom 4.0K Aug 11 14:31  Desktop\\
\\
\\
\\
Disk free space for ext2 file systems	\$ df -t ext2\\
\\
Disk free space for file systems except ext2	\$ df -x ext2\\
\\
Show inode usage	\$ df -i\\
\\
Show information about a distinct file system /path	\$ df /path}1013
\hypertarget{docker}{\section {DOCKER}}
https://docs.docker.com/get-started/{\large \textbf{Container}}{\large \\
Runtime instance of an 'image'\\
Has state, processes, native on Linux\\
\\
\textbf{Image}}{\large \\
Everything needed to run an application\\
\\
scaling means spinning up new executable\\
\\
Avoid sudo -> add user to the docker group\\
Ensure 'user' is not root for production builds!\\
\\
--------------------------------------\\
\textbf{Docker Processes}}{\large \\
\$ docker ps -a \\
\\
\textbf{Display Docker version and info}}{\large \\
\$docker --version\\
\$docker version\\
\$docker info\\
\\
\textbf{Execute (and test) Docker image}}{\large \\
\$ docker run hello-world -->  checks docker working ok\\
\\
\textbf{List Docker images}}{\large \\
\$ docker image ls\\
\\
\textbf{List Docker containers (running, all, all in quiet mode)}}{\large \\
docker container ls\\
docker container ls --all\\
docker container ls -aq\\
\\
\textbf{List Docker CLI commands}}{\large \\
docker\\
docker container --help\\
----------------------------------------\\
\\
\textbf{Development environment eg 'Python'}}{\large \\
Python version + your code + networking etc \~= image\\
Image created by a 'Dockerfile'\\
\\
\\
Tutorial https://docs.docker.com/get-started/part2/\#dockerfile}{\large \textit{Dockerfile}}{\large \\
--------------------------------------------------------------------------------------\\
\# Use an official Python runtime as a parent image\\
FROM python:2.7-slim\\
\\
\# Set the [containers] working directory to /app\\
WORKDIR /app\\
\\
\# Copy the current directory contents [where Dockerfie is] into the container at /app\\
ADD . /app\\
\\
\# Install any needed packages specified in requirements.txt\\
RUN pip install --trusted-host pypi.python.org -r requirements.txt\\
\\
\# Make port 80 available to the world outside via HTTP on this container\\
EXPOSE 80\\
+\\
\\
\# Define environment variable [container is env name is 'world']\\
ENV NAME World\\
\\
\# Run app.py when the container launches\\
CMD [''python'', ''app.py'']\\
-----------------------------------------------------------------------------------------\\
\\
create files  'requirements.txt'  and  'app.py' in same folder as Dockerfile\#\\
(see https://docs.docker.com/get-started/part2/\#the-app-itself}{\large  )\\
\\
/\\
	|\\
	| Dockerfile\\
	| requirements.txt\\
	| app.py\\
\\
\\
-----------------------------------\\
\\
\textbf{Build the app}}{\large \\
\\
This creates the docker image\\
\$ docker build -t hello    [ the -t 'tag' gives it a friendly 'hello' name]\\
\\
and to see it\\
\\
\$ docker image ls\\
\\
You can also 'tag' images and 'publish' images to the docker hub repo\\
\\
\\
------------------\\
}https://docs.docker.com/get-started/part3/\#docker-composeyml{\large \textbf{Services}}{\large \\
different pieces of the app are called ``services''\\
Scaling a service changes the number of container instances running that piece of software\\
\textbf{\\
docker-compose}}{\large \\
define, run, and scale services via docker-compose\\
[this example assumes have published above Dockerfile first for 'image:username/repo:tag' to work]\\
----------------------------------------------\\
version: ''3''\\
services:\\
  web:\\
    \# [replace username/repo:tag with your name and image details]\\
    \# Pull the image we uploaded in step 2 from the registry\\
    image: username/repo:tag\\
    deploy:\\
      \# Run 5 instances of that image as a service called web, \\
      \# limiting each one to use, at most, 10\% of the CPU (across all cores), and 50MB of RAM\\
      replicas: 5\\
      resources:\\
        limits:\\
          cpus: ''0.1''\\
          memory: 50M\\
      \# Immediately restart containers if one fails\\
      restart\_policy:\\
        condition: on-failure\\
    \# Map port 4000 on the host to web’s port 80\\
    ports:\\
	- ''4000:80''       \\
   \# nstruct web’s containers to share port 80 via a load-balanced network called webnet\\
    networks:\\
       - webnet\\
\# Define the webnet network with the default settings\\
networks:\\
  webnet:\\
\\
----------------------------------------------\\
\\
\textbf{Run load-balanced app}}{\large \\
\\
docker swarm init\\
\\
\textit{Now run it [app's name is 'getstartedlab'}}{\large \\
\\
docker stack deploy -c docker-compose.yml getstartedlab\\
\\
----------------------------------------------\\
\\
\textbf{Swarm clusters}}{\large \\
\\
a group of machines [nodes] that are running Docker and joined into a cluster. \\
A cluster of nodes  they are executed by a swarm manager\\
\\
Docker can execute in 'swarm mode'\\
\\
-----------------------------------------------\\
\\
}\textbf{{\Large Stacks}}{\large }https://docs.docker.com/get-started/part5/{\large \\
\\
group of interrelated services that share dependencies, and can be orchestrated and scaled together\\
\\
a single service stack running on a single host, which is not usually what takes place in production\\
\\
----------------------------\\
version: ''3''\\
services:\\
  web:\\
    \# replace username/repo:tag with your name and image details\\
    image: username/repo:tag\\
    deploy:\\
      replicas: 5\\
      restart\_policy:\\
        condition: on-failure\\
      resources:\\
        limits:\\
          cpus: ''0.1''\\
          memory: 50M\\
    ports:\\
      - ''80:80''\\
    networks:\\
      - webnet\\
  visualizer:\\
    image: dockersamples/visualizer:stable\\
    ports:\\
      - ''8080:8080''\\
    volumes:\\
      - ''/var/run/docker.sock:/var/run/docker.sock''\\
    deploy:\\
      placement:\\
        constraints: [node.role == manager]\\
    networks:\\
      - webnet\\
networks:\\
  webnet:\\
----------------------------\\
\\
\textbf{VOLUMES}}{\large \textit{from docker-compose stack above:}}{\large \\
	volumes key\\
	giving the visualizer access to the host’s socket file for Docker\\
\\
	placement key\\
	ensuring that this service only ever runs on a swarm manager\\
\\
Volumes are for persisting data in containers. \\
Bind mounts are dependent on the directory structure of the host machine.\\
\\
from docs: }https://docs.docker.com/compose/compose-file/\#volumes{\large \\
\\
'host paths' or 'named volumes'\\
\\
host path\\
	part of a definition for a single service; \\
	no need to define in the top level volumes key.\\
\\
volumes key: top-level\\
	volume across multiple services, \\
	For services, swarms, and stack files.\\
	[Note: replaces 'volumes\_from' in earlier versions of the compose]\\
\\
example\\
\\
-------------\\
version: ''3.2''\\
services:\\
  web:\\
    image: nginx:alpine\\
    volumes:\\
      - type: volume      \# Named volume [long syntax]\\
        source: mydata  \#\\
        target: /data       \#\\
        volume:\\
          nocopy: true\\
      - type: bind                   \\
        source: ./static            \\
        target: /opt/app/static}{\large {\large   \\
\\
  db:\\
    image: postgres:latest\\
    volumes:\\
      - ''/var/run/postgres/postgres.sock:/var/run/postgres/postgres.sock''    bind mount [old format]\\
      - ''dbdata:/var/lib/postgresql/data'' [named volume: short syntax    up-to-date]}{\large \\
\\
\# Named Volumes must be listed on 'top level'\\
volumes:\\
  mydata:\\
  dbdata:}{\large \\
-------------\\
\\
Long Syntax: allows for more options\\
type [volume or bind], tmpfs,source,target,read-only etc etc\\
\\
When no 'named volume', service uses an 'anonymous volume' which is erased when container removed.\\
\\
Tom make data persist use a \\
named volume + Volume driver = multihost aware\\
OR\\
Set constraints\\
\\
eg database\\
-----\\
version: ''3''\\
services:\\
  db:\\
    image: postgres:9.4\\
    volumes:\\
      - db-data:/var/lib/postgresql/data\\
    networks:\\
      - backend\\
    deploy:\\
      placement:\\
        constraints: [node.role == manager]\\
-----\\
\\
Volume Config Reference\\
\\
Allows you to create named volumes [without 'volumes\_from' which is obsolete]\\
that can be \\
used across multiple services}{\large    \\
Easily inspected via docker API\\
\\
Example - database data directory shared with another service\\
\\
------------\\
version: ''3''\\
\\
services:\\
  db:\\
    image: db\\
\textbf{\textit{    volumes:\\
      - data-volume:/var/lib/db}}}{\large {\large \\
  backup:\\
    image: backup-service\\
\textbf{\textit{    volumes:\\
      - data-volume:/var/lib/backup/data}}}{\large {\large \textbf{\textit{volumes: }}}{\large {\large  \# top-level    [can configure with 'driver, driver\_opts, external, labels, name]}{\large \textbf{\textit{\\
  data-volume:}}}{\large {\large \\
------------\\
\\
Top-level volume keys: [not all shown]\\
\\
\textit{driver: foobar}}{\large    \\
specify which driver; default to docker engine config\\
	\\
external\\
If set to true volume has been created outside of compose\\
Example instead of creating a volme, compose can look for an existing volume called say 'data' and mount into the 'db' services containers\\
\\
Labels\\
For DNS style labeling\\
\\
\\
\\
=============================\\
\\
\\
\textbf{FROM 2016 - OLDER VERSION OF DOCKER}}{\large }https://www.linux.com/learn/docker-volumes-and-networks-compose{\large \\
========\\
ghost:  \\
  image: ghost\\
  volumes:\\
    - ./ghost/config.js:/var/lib/ghost/config.js\\
=========\\
\\
we defined a volume for the ghost container, \\
this mounts the local `config.js` file into the `/var/lib/ghost/config.js` file in the container. \\
\\
Docker created a volume for the `/var/lib/ghost` directory and pointed the container `config.js` file to the one we have in our project directory. If you were to edit the file on the host and restart the container, the changes would take effect immediately.\\
\\
Persistant data\\
We can create a Docker volume and mount it in `/var/lib/mysql` of the database container. \\
The life of this volume would be totally separate from the container lifecycle.\\
\\
Below is a snippet which creates a `mysql` named volume and uses it in the `mysql` service.\\
=========\\
version: '2'\\
services:\\
 mysql:  \\
  image: mysql\\
  container\_name: mysql\\
  volumes:\\
    - mysql:/var/lib/mysql\\
...\\
\\
volumes:\\
 mysql:\\
==========\\
\\
Can see named volumes with \\
\$docker volume ls 			and 		\$docker volume inspect <volume\_name>\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
}8909
\hypertarget{docker_cheat_sheet}{\section {DOCKER CHEAT SHEET}}
{\large \textbf{List \hyperlink{docker}{Docker}}}{\large \textbf{ CLI commands}}{\large \\
	sudo \hyperlink{docker}{docker}}{\large \\
\\
	sudo \hyperlink{docker}{docker}}{\large  container --help\\
\\
\textbf{Display \hyperlink{docker}{Docker}}}{\large \textbf{ version and info}}{\large \hyperlink{docker}{docker}}{\large  --version\\
\\
	\hyperlink{docker}{docker}}{\large  version\\
\\
	\hyperlink{docker}{docker}}{\large  info\\
\\
\textbf{Execute \hyperlink{docker}{Docker}}}{\large \textbf{ image}}{\large \\
	sudo \hyperlink{docker}{docker}}{\large  run hello-world\\
\\
\textbf{List \hyperlink{docker}{Docker}}}{\large \textbf{ images}}{\large \\
	sudo \hyperlink{docker}{docker}}{\large  image ls\\
\\
\textbf{List \hyperlink{docker}{Docker}}}{\large \textbf{ containers (running, all, all in quiet mode)}}{\large \hyperlink{docker}{docker}}{\large  container ls\\
\\
	sudo \hyperlink{docker}{docker}}{\large  container ls --all\\
\\
	\hyperlink{docker}{docker}}{\large  container ls -aq\\
\\
\\
\\
}156
\hypertarget{downlods_and_unzip}{\section {downlods and unzip}}
https://download.gimp.org/mirror/pub/gimp/v2.10/gimp-2.10.0-RC1.tar.bz2\\
\\
----\\
\\
cd \~/Downloads/ \\
\\
\$ wget https://download.gimp.org/mirror/pub/gimp/v2.10/gimp-2.10.0-RC1.tar.bz2\\
\\
\{OR\\
\\
\$ curl https://download.gimp.org/mirror/pub/gimp/v2.10/gimp-2.10.0-RC1.tar.bz2\\
\}\\
\\
\\
to decompress and extract\\
\\
	\$ tar xfvj gimp-2.10.0-RC1.tar.bz2\\
\\
Also download MD5 checksum to check integrity relabelling as mdsum.txt\\
\\
\$ curl https://download.gimp.org/mirror/pub/gimp/v2.10/gimp-2.10.0-RC1.tar.bz2.md5 -o md5sum.txt\\
\\
This will contain the string ''e8892481e70c4ee3c204b6aa484f4eba  gimp-2.10.0-RC1.tar.bz2''\\
\\
So to compare automatically we also need to 'cut' off the filename ie in this case gimp-2.10.0-RC1.tar.bz2\\
\\
\$ cut -d' ' -f1 md5sum.txt >  cutmd\\
\\
\\
Check integrity\\
\$ md5sum gimp-2.10.0-RC1\\
\\
BUT :  How to compare these two ie the md5sum result  and the content of the downloaded md5 checksum\\
\\
\\
-----\\
\\
\\
curl -L https://geolite.maxmind.com/download/geoip/database/GeoLite2-City.mmdb.gz \\\\
| gunzip | tee -a GeoLite2-City.dat | cut -d\\  -f1 | md5sum > md5sum.txt\\
\\
This uses the tee command to split the file into its ''save'' location and another pipe, which goes through md5sum to generate your .txt file.\\
\\
Might save you a minute that would otherwise be eaten by the md5sum that runs afterwards. And it'll take better advantage of SMP. :)\\
\\
\\
-----\\
\\
How SIgnal does it\\
\\
curl -s https://updates.signal.org/desktop/apt/keys.asc | sudo apt-key add -\\
echo ''deb [arch=amd64] https://updates.signal.org/desktop/apt xenial main'' | sudo tee -a /etc/apt/sources.list.d/signal-xenial.list\\
\\
sudo apt update \&\& sudo apt install signal-desktop \\
\\
-----\\
\\
To install\\
\\
\$ sudo apt update \&\& sudo apt install gimp-2.10.0-RC1\\
\\
\\
---------------------\\
\\
\textbf{To archive}\\
tar -cvf\\
tar --create --verbose --file\\
	Example:   \$tar -cvf newFooBar.tar file1FooBar file2FooBar\\
\\
E\textbf{xtract then archived file}\\
	tar -xvf\\
	tar --extract --verbose --file\\
	Example   \$tar -xvf newFooBar.tar\\
\\
\textbf{gZip then archive}\\
	tar -cvzf\\
	tar --create --verbose --zipped --file\\
	Example:   \$tar -cvzf gzipNewFooBar.tar file1FooBar file2FooBar\\
\\
\textbf{Extract then unzip}\\
	tar -xvzf fooBar.tgz\\
\\
\textbf{To create bz2 compressed file:}\\
\$ bzip2 fooBar.txt\\
\\
\textbf{To decompress a bz2}\\
\\
bzip2 -d fooBar.txt.bz2\\
\\
\textbf{Combining files in a compressed archive:}\\
\\
tar cfvj newArchive.tar.bz2 file1 file2\\
\\
Resulting archive is:      newArchive.tar.bz2\\
\\
\textbf{To decompress and extract an archive:}\\
\\
tar xfvj archive.tar.bz2\\
\\
(Note: the lowercase ' j 'flag -j is also --bzip2 meaning 'filter the archive through bzip2') \\
\\
Example: \\
Downloaded Gimp tarball is\\
gimp-2.10.0-RC1.tar.bz2\\
\\
Now to decompress and extract\\
tar xfvj gimp-2.10.0-RC1.tar.bz2\\
\\
\\
\\
12.21\\
\\
Example: Extracting from the latest Wordpress 'latest'\\
\$ tar -zxvf latest.tar.gz\\
\\
And to see this directory\\
\\
\\
\\
bzip2223
\hypertarget{executing_bash_script_in_'source'_vs_just_executing_it'}{\section {executing Bash script in 'source' vs just executing it'}}
{\large \\
Executing it  \\
	\$ ./foobar.sh\\
\\
Source\\
	\$ source foobar  or  \$ . foobar\\
\\
Note: to source it must be a valid shell script and the file can be in current directory or in a directory in \$PATH (check \$ export for PATH info)\\
\\
\\
Both sourcing and executing the script will run the commands in the script line by line, as if you typed those commands by hand line by line.\\
\\
The differences are:\\
When you execute the script you are opening a new shell, type the commands in the new shell, copy the output back to your current shell, then close the new shell. \\
\\
Any changes to environment will take effect only in the new shell and will be lost once the new shell is closed.\\
\\
When you source the script you are typing the commands in your current shell. \\
Any changes to the environment will take effect and stay in your current shell. \\
\\
Use source if you want the script to change the environment in your currently running shell.\\
use execute otherwise.\\
\\
\\
\textbf{Example}}{\large \\
------------------------------------------------------------------------------------\\
\#!/bin/sh\\
\# Demonstrates variable behavior in a subshell environment\\
VAR=10\\
echo ''VAR is'' \$VAR\\
echo ''x is '' \$x\\
echo ''y is '' \$y\\
(\\
echo ''In the subshell, VAR is still'' \$VAR\\
VAR=\$((\$VAR+5))\\
echo ''The new value of VAR in the subshell is'' \$VAR\\
)\\
echo ''Outside of the subshell, VAR is'' \$VAR\\
-----------------------------------------------------------------------------------\\
\\
\\
tomdom\$ x=50\\
tomdom\$ y=300\\
tomdom\$ ./example\_sub\_shell.sh\\
VAR is 10\\
x is \\
y is \\
In the subshell, VAR is still 10\\
The new value of VAR in the subshell is 15\\
Outside of the subshell, VAR is 10\\
\\
==============================\\
and if we do the same with 'source'\\
==============================\\
\\
tomdom\$ source ./example\_sub\_shell.sh\\
VAR is 10\\
x is  50\\
y is  300\\
In the subshell, VAR is still 10\\
The new value of VAR in the subshell is 15\\
Outside of the subshell, VAR is 10\\
\\
==============================\\
we see that x=50 and y=300 is available because \\
its the same shell as from where it was run\\
==============================\\
}86
\hypertarget{extract_fields_from_html_using_bash}{\section {extract fields from html using bash}}
\textbf{Split off the names}\\
\\
sed -n '/class=speaker-teaser\_content/p' 'cogx 3.html' > cogx\_sed\_1.txt\\
\\
cat cogx\_sed\_1.txt | sed 's|class=speaker-teaser\_content><h3><strong>|-|g' > cog\_sed\_1\_strong.txt\\
\\
cat cog\_sed\_1\_strong.txt | sed 's|</strong></h3>|-|g' > cog\_names.txt\\
\\
\\
\\
\textbf{split off the company name and job title}\\
\\
\\
sed -n '/<span>/p' 'cogx 3.html' > cogx\_sed\_span.txt\\
\\
cat cogx\_sed\_span.txt | sed 's|<span>|-|g' > cogx\_sed\_span\_remove.txt\\
\\
\\
cat cogx\_sed\_span\_remove.txt | sed 's|</span>|-|g' > cogx\_sed\_span\_remove\_span.txt\\
\\
cat cogx\_sed\_span\_remove\_span.txt | sed 's|</div>|-|g' > cogx\_sed\_span\_remove\_span\_div.txt\\
\\
cat cogx\_sed\_span\_remove\_span\_div.txt | sed 's|--|-|g' > cogx\_sed\_span\_remove\_span\_div\_clean.txt\\
\\
\\
\\
\textbf{Merge the job title and name onto same line}\\
\\
paste -d '' ''  - - < cogx\_sed\_span\_remove\_span\_div\_clean.txt > single\_line\_company.txt\\
\\
\\
\textbf{Merge the name and single line company titles files as a CSV (comma separated)\\
ie cog\_names.txt and single\_line\_company.txt}\\
\\
paste -d',' cog\_names.txt single\_line\_company.txt > name\_n\_company.txt\\
\\
\\
paste -d',' cog\_names.txt single\_line\_company.txt > name\_n\_company.csv\\
\\
\\
\textbf{Then in LibreOffice re-save as an .odt}88
\hypertarget{ffmpeg_\&_youtube-dl}{\section {ffmpeg & youtube-dl}}
{\large }\textbf{{\Large ffmpeg}}\textbf{{\large \\
tidying up the 'help' facility}}{\large \\
          	ffmpeg -hide\_banner -i fooVid.mp4 -c:v copy -c:a copy fooVid.mov     }{\large \\
man ffmpeg\\
\\
search for 'copy' and 'stream}{\large \\
 ffmepeg container change\\
\\
https://askubuntu.com/questions/50433/how-to-convert-mkv-file-into-mp4-file-losslessly?utm\_medium=organic\&utm\_source=google\_rich\_qa\&utm\_campaign=google\_rich\_qa}{\large }{\large \$ ffmpeg -i test.mkv -c:v copy -c:a copy test.mp4}{\large }\textbf{{\large Basic conversion}}{\large \\
ffmpeg -i fooBar.mkv fooBar.mp4\\
\\
\\
\textbf{Convert videos to MP4 format}}{\large }https://www.bugcodemaster.com/article/convert-videos-mp4-format-using-ffmpeg{\large \\
		ffmpeg -i example.mov -vf scale=320:180 -c:v libx264 -preset fast -c:a aac output.mp4 -hide\_banner\\
\\
\\
\textbf{Quickest mkv to mp4 collection conversion}}{\large \\
Just changing the 'container label', not its contents           \\
\\
          	ffmpeg -i fooVid.mp4 -c:v copy -c:a copy fooVid.mov\\
          \\
		for file in *.mp4;do ffmpeg -i ''\$file'' -c:v copy -c:a copy ''\$\{file\%\}.mov''; done\\
\\
	goes at \~50X speed\\
\\
\\
\textbf{Completely converting the video ie Trans-coding the mkv to mp4 collection conversion}}{\large \\
\\
For a collection of mkv files in a directory that need converting into mp4 to play on TV\\
\\
for f in *.mkv; do ffmpeg -i ''\$f'' ''\$\{f\%.mkv\}.mp4''; done\\
\\
\\
\textbf{ALSO}}{\large \\
Look at  http://ffmpeg.org/ffmpeg-all.html\#Main-options}{\large \textbf{Scaling}}{\large }https://www.bugcodemaster.com/article/changing-resolution-video-using-ffmpeg\#{\large \\
ffmpeg -i video\_320x180.mp4 -vf scale=160:90 video\_180x90.mp4 -hide\_banner\\
\\
\textbf{ffmpeg Audio strip}}{\large \\
ffmpeg -i [input\_file] -vcodec copy -an [output\_file]}{\Large \\
\\
see : http://ffmpeg.org/ffmpeg.html\#Audio-Options}{\Large \\
\\
===================================================\\
\\
\\
\textbf{Re-label a collection of youtube-dl videos in a directory}}{\Large \\
\\
they will look like:\\
\$ ls\\
'Mounting Drives-AH9LEr3k5T4.mp4'\\
'Moving and Copying Files and Directories in Linux-GKEGNdNIQrw.mp4'\\
'Path \& Command Basics-irYWpAZKurA.mp4'\\
'Regular Expression Basics-KJG1dETacLI.mp4'\\
'Scheduling Jobs in Linux-z3EDu\_IP8v8.mp4'\\
'Streams, Redirection, and Piping-EuzOw7M15vg.mp4'\\
\\
\\
We can use the ' - ' delimiter to cut off and tidy\\
\\
Hence\\
\\
		\textbf{for file in *.mp4;do mv ''\$file'' ''\$(echo ''\$file'' | cut -d- -f1 )''.mp4; done}}{\Large \\
\\
Where \\
cut -d- -f1     means cut the first field (f1) that has the delimiter (-d) of ' - ' ie  '-d-'\\
\\
this is applied to an 'echo' of the filename in a seperate expression, whose result (the new filename) is then put in '' '' quotes to say that its a string and not a command. Then its concated with ' .mp4 '.\\
\\
The whole statement is wrapped in a for loop to be applied to all files ( * ) with an .mp4 file extension\\
\\
\\
====================================================\\
\\
\textbf{Moving all .mp4 files into a separate folder}}{\Large \\
\\
Suppose post ffmpeg loop, we have\\
\\
\$ ls\\
'foo bar video.mp4'\\
'foo bar video.mp4.mov'\\
'abcde video.mp4.mov'\\
'abcde video.mp4'\\
\\
and we want all the genuine .mp4 in one folder and the .mov's in another\\
\\
\$ mkdir mp4-versions\\
\\
\$ \textbf{for file in *.mp4; do mv ''\$file'' mp4-versions/''\$file''; done }}{\Large \\
\\
Now if we do\\
\$ ls\\
\\
'foo bar video.mp4.mov'\\
'abcde video.mp4.mov'\\
mp4-versions\\
\\
with the mp4's in the mp4-versions directory\\
\\
\textbf{To fix the .mp4.mov}}{\Large \\
\\
\$ \textbf{for file in *.mp4.mov;do mv ''\$file'' ''\$(echo ''\$file'' | cut -d. -f1 )''.mov; done}}{\Large \\
\\
hence\\
\\
\$ ls\\
'foo bar video.mov'\\
'abcde video.mov'\\
mp4-versions\\
\\
\\
===================================================\\
\\
\textbf{Section of video to convert}}{\Large \\
\\
InputFile -ss StartTime -t Duration Outputfile\\
\\
\\
ffmpeg -i in\_movie.avi -ss 00:26:20 -t 00:02:04 out\_movie.avi\\
\\
ffmpeg -i 'inputVideo.flv' -ss 00:26:20 -t 00:02:04 'outputVideo.mp4'\\
\\
\\
============================================================\\
\\
\textbf{ffprobe - to get JSON format data etc}}{\Large \\
\\
\$ ffprobe -v quiet -print\_format json -show\_format -show\_streams ''fooVideo.mp4'' > ''fooVideo.mp4.json''\\
\\
\\
\\
or for format just\\
\\
\$ ffprobe -v quiet -print\_format json -show\_format ''fooVideo.mp4'' > ''fooVideo.mp4.json''\\
\\
this 'format' example would produce something like\\
\\
\\
}\textit{\{\\
    ''format'': \{\\
        ''filename'': ''test\_video.mp4'',\\
        ''nb\_streams'': 2,\\
        ''nb\_programs'': 0,\\
        ''format\_name'': ''mov,mp4,m4a,3gp,3g2,mj2'',\\
        ''format\_long\_name'': ''QuickTime / MOV'',\\
        ''start\_time'': ''0.000000'',\\
        ''duration'': ''264.406000'',\\
        ''size'': ''171860053'',\\
        ''bit\_rate'': ''5199883'',\\
        ''probe\_score'': 100,\\
        ''tags'': \{\\
            ''major\_brand'': ''isom'',\\
            ''minor\_version'': ''512'',\\
            ''compatible\_brands'': ''isomiso2avc1mp41'',\\
            ''encoder'': ''Lavf57.71.100''\\
        \}\\
    \}\\
\}}{\Large \\
\\
To get just the 'format\_long\_name', for example we can use the jq JSON library\\
\\
\$ cat test\_video\_probe\_2.mp4.json | jq '.format.format\_long\_name'\\
\\
\\
We could also output in another format of course and use a 'cut' command or similar!\\
============================================================{\large }}{\Large \textbf{Cutting a video }}{\Large \\
\\
-t 670 		or 		-t 00:11:10 \\
\\
starts (ss) at 0 hours, 30 min and 20 seconds for a (t) 1hour duration (60*60*60=216000)\\
\\
ffmpeg -i fooBarVideo.mp4 -ss 00:30:20 -t 216000 cutFooBar.mp4\\
}{\large }{\Large \\
\#!/bin/sh\\
filename=\$1\\
starttime=\$2\\
endtime=\$3\\
ffmpeg -i \$1 -ss \$starttime -t \$endtime -async 1 -c copy \$1\_CUT.mkv\\
\\
\\
\\
============================================================\\
\\
\textbf{Brightness Saturation Contrast  Gamma}}{\Large  (speed x3.5)\\
\\
ffmpeg -i 'input.mp4' -vf eq=brightness=0.04:contrast=1.03:saturation=2 -c:a copy 'output.mp4'\\
\\
Popping a dark theme\\
ffmpeg -i 'input.mp4' -vf eq=brightness=0.05:contrast=0.9:saturation=2:gamma=0.9 -c:a copy 'output.mp4'\\
\\
\textbf{Sharpening}}{\Large   (speed x1.5)\\
\\
ffmpeg -i 'input.mp4' -filter:v ''unsharp=luma\_msize\_x=3:luma\_msize\_y=3:luma\_amount=1.5'' -c:a copy 'output.mp4'\\
\\
\\
\\
\textbf{Procedure to cut section then sharpen is:}}{\Large \\
\\
\$ ffmpeg -i 'input.flv' -ss 00:26:20 -t 00:01:04 'out1.mp4'\\
\\
\$ ffmpeg -i 'out1.mp4' -filter:v ''unsharp=luma\_msize\_x=3:luma\_msize\_y=3:luma\_amount=1.5'' -c:a copy 'out1.sharp.mp4'\\
\\
\\
Bash script\\
Cycle through long video then from an array or file pull calculate duration times and then create cut sequences. Then loop through these cut sequences and sharpen them slightly.\\
\\
===================================\\
\\
\textbf{Adding Text}}{\Large }[ https://stackoverflow.com/questions/17623676/text-on-video-ffmpeg ]{\Large \textit{Example 1}}{\Large \\
------------------\\
ffmpeg -i input.mp4 -vf drawtext=''fontfile=/path/to/font.ttf: \\ text='Stack Overflow': fontcolor=white:fontsize=24: box=1: boxcolor=black@0.5:}{\Large  \\boxborderw=5: x=(w-text\_w)/2: y=(h-text\_h)/2'' -codec:a copy output.mp4\\
\\
\\
The @0.5 controls the opacity of the text box. In this example it is set to 50\%. You can remove @0.5 and there will be no transparency.\\
\\
  -codec:a copy will stream copy} [ http://ffmpeg.org/ffmpeg.html\#Stream-copy ]{\Large  (re-mux) the audio and avoid re-encoding.\\
\\
An alternative to the drawtext filter is to use ASS or SRT subtitles }[ https://trac.ffmpeg.org/wiki/HowToBurnSubtitlesIntoVideo ]{\Large  especially if you want timed text or softsubs.\\
\\
If you want to update or change the text see the textfile and reload options for this filter.\\
\\
This filter requires your ffmpeg to be compiled with --enable-libfreetype. If you get No such filter: 'drawtext' it is probably missing --enable-libfreetype. Most of the ffmpeg static builds available support this, so see the FFmpeg Download page for links.\\
\\
See the drawtext filter documentation for more options and examples.\\
}http://ffmpeg.org/ffmpeg-filters.html\#drawtext-1{\Large \\
\\
To see a video with it WITHOUT actually making a video (good for testing!)\\
\\
Use 'ffplay'\\
\\
ffplay -vf drawtext=''fontsize=30:fontfile=FreeSerif.ttf:text='The quick brown fox':x=(w-text\_w)*0.80:y=(h-text\_h)*0.80'' 'fooBarVideo.mp4'\\
\\
\\
\\
\textit{Example 2}}{\Large \\
---------------\\
Show the text at the center of the video frame: \\
\\
	drawtext=''fontsize=30:fontfile=FreeSerif.ttf:text='hello world':x=(w-text\_w)/2:y=(h-text\_h)/2''\\
\\
\\
Example 2 b\\
\\
Change font color to black and shadow color to black\\
\\
Add the following to the fontsize description \\
	fontcolor=white:shadowcolor=black:shadowx=1:shadowy=1\\
\\
i.e.\\
\\
}{\large ffplay -vf drawtext=''fontsize=30:fontcolor=white:shadowcolor=black:shadowx=1:shadowy=1:fontfile=FreeSerif.ttf:text='The quick brown fox':x=(w-text\_w)*0.80:y=(h-text\_h)*0.80'' 'fooBarVideo.mp4'}{\Large \\
\\
\\
Example 2c\\
Add a new line (a lot fiddler than it looks! )\\
Need to create a text file\\
\\
\$ echo -e ''This is a test\\nto see if a new line appears'' > test.txt\\
\\
\$ ffplay -vf drawtext=''fontsize=30:fontfile=FreeSerif.ttf:text=\$(cat test.txt):x=(w-text\_w)*0.80:y=(h-text\_h)*0.80'' fooBarVideo.mp4'\\
\\
get --->\\
		This is a test\\
		to see if a new line appear\\
\\
on video :)\\
\\
\\
\textit{Example 2d}}{\Large \\
-----------------\\
\\
This is max 20 char wide and max 12 lines - very simple!\\
test.text  is set to\\
----------->\\
\\
}			Session 1 Lecture 4\\
\\
			What's the Meaning \\
			of the Universe?\\
\\
			by\\
			Tom Ormiston,\\
\\
			Linux and \\
			FOSS advocate{\Large \\
\\
ffplay -vf drawtext=''fontsize=25:fontcolor=white:shadowcolor=black:shadowx=2:shadowy=2:fontfile=FreeSerif.ttf:text=\$(cat test.txt):x=(w-text\_w)*0.90:y=(h-text\_h)*0.80'' 'foBarVid.mov'\\
\\
\\
\\
\textit{Example 3}}{\Large \\
---------------\\
Show text fading in and out (appearing/disappearing): \\
\\
\#!/bin/sh\\
DS=1.0 \# display start\\
DE=10.0 \# display end\\
FID=1.5 \# fade in duration\\
FOD=5 \# fade out duration\\
ffplay -f lavfi ''color,drawtext=text=TEST:fontsize=50:fontfile=FreeSerif.ttf:fontcolor\_expr=ff0000\%\{eif\\\\\\\\: clip(255*(1*between(t\\\\, \$DS + \$FID\\\\, \$DE - \$FOD) + ((t - \$DS)/\$FID)*between(t\\\\, \$DS\\\\, \$DS + \$FID) + (-(t - \$DE)/\$FOD)*between(t\\\\, \$DE - \$FOD\\\\, \$DE) )\\\\, 0\\\\, 255) \\\\\\\\: x\\\\\\\\: 2 \}''\\
\\
===================================\\
\\
\textbf{Invert video}}{\Large   - use the 'negate' option\\
\\
\$ ffmpeg -i fooIn -vf negate barOutInverted\\
\\
for a bunch of mp4 videos, creating new '\_inverted' ones\\
\\
\textbf{for f in *.mp4; do ffmpeg -i ''\$f'' -vf negate ''\$f''\_inverted.mp4; done}}{\Large \\
\\
-----------------------------------------------------------------\\
\textbf{Playlist}}{\large \\
youtube-dl http://fooBarPlaylist}{\large  --yes-playlist -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best'\\
\\
\textbf{\\
Audio only}}{\large \\
youtube-dl http://fooBarPlaylist}{\large  -x --yes-playlist -f 'bestaudio[ext=m4a]/best[ext=mp4]/best'}{\large \\
===============================================\\
\\
ffmpeg -i example.mkv -vf scale=1920:1080 -c:v libx264 -c:a aac output.mp4\\
\\
\\
}\textbf{{\Large for f in *.mkv; do ffmpeg -i ''\$f'' -vf scale=1920:1080 -c:v libx264 -c:a aac ''\$f''.mp4; done}}{\large }\textbf{{\Large for f in *.wemb; do ffmpeg -i ''\$f'' -vf scale=1920:1080 -c:v libx264 -preset fast -c:a aac ''\$f''.mp4; done}}{\large \\
\\
=========================================================\\
Find out what formats available\\
\\
\$ youtube-dl --list-formats https://fooBar}{\large \\
\\
example for 1080p we need 22\\
\\
249          webm       audio only DASH audio   52k , opus @ 50k, 5.19MiB\\
250          webm       audio only DASH audio   75k , opus @ 70k, 6.94MiB\\
171          webm       audio only DASH audio   90k , vorbis@128k, 8.55MiB\\
140          m4a        audio only DASH audio   96k , m4a\_dash container, mp4a.40.2@128k, 9.73MiB\\
251          webm       audio only DASH audio  113k , opus @160k, 10.60MiB\\
160          mp4        256x144    144p   71k , avc1.4d400c, 25fps, video only, 4.41MiB\\
278          webm       256x144    144p  100k , webm container, vp9, 25fps, video only, 8.99MiB\\
133          mp4        426x240    240p  131k , avc1.4d4015, 25fps, video only, 8.00MiB\\
242          webm       426x240    240p  204k , vp9, 25fps, video only, 15.04MiB\\
134          mp4        640x360    360p  345k , avc1.4d401e, 25fps, video only, 20.92MiB\\
243          webm       640x360    360p  393k , vp9, 25fps, video only, 28.72MiB\\
135          mp4        854x480    480p  706k , avc1.4d401e, 25fps, video only, 43.69MiB\\
244          webm       854x480    480p  720k , vp9, 25fps, video only, 52.05MiB\\
136          mp4        1280x720   720p 1298k , avc1.4d401f, 25fps, video only, 84.09MiB\\
247          webm       1280x720   720p 1488k , vp9, 25fps, video only, 115.49MiB\\
\textbf{\textit{137          mp4        1920x1080  1080p 2439k , avc1.640028, 25fps, video only, 161.86MiB}}}{\large {\large \\
248          webm       1920x1080  1080p 2698k , vp9, 25fps, video only, 228.42MiB\\
271          webm       2560x1440  1440p 8809k , vp9, 25fps, video only, 735.33MiB\\
313          webm       3840x2160  2160p 18196k , vp9, 25fps, video only, 1.67GiB\\
17           3gp        176x144    small , mp4v.20.3, mp4a.40.2@ 24k\\
36           3gp        320x180    small , mp4v.20.3, mp4a.40.2\\
43           webm       640x360    medium , vp8.0, vorbis@128k\\
18           mp4        640x360    medium , avc1.42001E, mp4a.40.2@ 96k\\
\textbf{\textit{22           mp4        1280x720   hd720 , avc1.64001F, mp4a.40.2@192k (best)}}}{\large {\large \\
\\
Hence\\
\\
\$ youtube-dl -f 22 https://fooBar}{\large \\
\\
NB: 137 is video only\\
==========================================================\\
\\
The general syntax for format selection is --format FORMAT or shorter -f FORMAT where FORMAT is a selector expression, i.e.  an expression that describes format or formats you would like to download.\\
\\
tl;dr: navigate me to examples (\#format-selection-examples).\\
\\
The  simplest case is requesting a specific format, for example with -f 22 you can download the format with format code equal to 22.  You can get the list of available format codes for particular video using --list-formats or -F. Note that these format codes are extractor specific.\\
\\
You  can also use a file extension (currently 3gp, aac, flv, m4a, mp3, mp4, ogg, wav, webm are supported) to down‐load the best quality format of a particular file extension served as a single file, e.g.  -f webm  will  download the best quality format with the webm extension served as a single file.\\
\\
You can also use special names to select particular edge case formats: - best: Select the best quality format represented by a single file with video and audio.  - worst: Select the worst quality format represented by a  single file with video and audio.  - bestvideo: Select the best quality video-only format (e.g.  DASH video).  May not be available.  - worstvideo: Select the worst quality video-only format.  May not be available.  - bestaudio:  Select the best quality audio only-format.  May not be available.  - worstaudio: Select the worst quality audio only-format.  May not be available.\\
\\
For example, to download the worst quality video-only format you can use -f worstvideo.\\
\\
If you want to download multiple videos and they don't have the same formats available, you can specify the  order of  preference  using  slashes.  Note that slash is left-associative, i.e.  formats on the left hand side are preferred, for example -f 22/17/18 will download format 22 if it's available, otherwise it will download format 17 if it's  available,  otherwise it will download format 18 if it's available, otherwise it will complain that no suitable formats are available for download.\\
\\
If you want to download several formats of the same video use a comma as a separator, e.g.  -f 22,17,18 will download  all these three formats, of course if they are available.  Or a more sophisticated example combined with the precedence feature: -f 136/137/mp4/bestvideo,140/m4a/bestaudio.\\
\\
You can also filter the video formats by  putting  a  condition  in  brackets,  as  in  -f ''best[height=720]''  (or -f ''[filesize>10M]'').\\
\\
\\
\\
===========================================\\
\\
\textbf{Installed latest ffmpeg via  }}{\large \\
\\
\$ snap install ffmpeg\\
\\
it will resolve the same way that all commands do. via the PATH\\
\\
or you can force it by calling either \\
\\
\$ snap run ffmpeg 		or		 /snap/bin/ffmpeg}{\large  		directly\\
\\
\\
===============================================\\
\\
}{\Large Clean up a downloaded youtube list\\
\\
\textbf{for f in *; do echo ''\$f'' | cut -d' ' -f5-10 | cut -d'-' -f1; done}}{\large \\
\\
=================================================================\\
\\
}\textbf{{\Large High Quality Gifs with FFMPEG}}{\large https://medium.com/@colten\_jackson/doing-the-gif-thing-on-debian-82b9760a8483}{\large https://engineering.giphy.com/how-to-make-gifs-with-ffmpeg/}{\large \\
\\
Editing and palette config for gif\\
ffmpeg -ss 61.0 -t 2.5 -i StickAround.mp4 -filter\_complex ''[0:v] split [a][b];[a] palettegen [p];[b][p] paletteuse'' FancyStickAround.gif\\
\\
\\
Palette config for gif\\
ffmpeg -i fooBarr.mp4 -filter\_complex ''[0:v] split [a][b];[a] palettegen [p];[b][p] paletteuse'' gifyFooBar.gif\\
\\
\\
With scaling to width 480\\
ffmpeg -ss 61.0 -t 2.5 -i StickAround.mp4 -filter\_complex ''[0:v] fps=12,scale=w=480:h=-1,split [a][b];[a] palettegen=stats\_mode=single [p];[b][p] paletteuse=new=1'' gifyFooBar.gif\\
\\
\\
With scaling to width 480 - no editing - with colour pallette for gif - fps 10\\
ffmpeg  -i StickAround.mp4 -filter\_complex ''[0:v] fps=12,scale=w=480:h=-1,split [a][b];[a] palettegen=stats\_mode=single [p];[b][p] paletteuse=new=1'' gifyFooBar.gif\\
\\
\\
ffmpeg -i 'fooBar.mp4' -filter\_complex ''[0:v]  fps=120,scale=w=480:h=-1,split [a][b];[a] palettegen [p];[b][p] paletteuse'' gify\_fooBarr.gif\\
\\
\\
}\textbf{{\Large For my GitHub Installation script video demo used: \\
\\
\\
\\
}}{\large }9494
\hypertarget{firefox_-_set_new_tab_next_to_current}{\section {Firefox - Set New Tab next to Current}}
https://www.ghacks.net/2018/05/10/open-tabs-in-firefox-to-the-right-of-the-current-tab/\\
\\
set URL to ''  about:config '' \\
\\
ok to the '' here be dragons '' warning\\
\\
search for ``  browser.tabs.insertAfterCurrent  '' \\
\\
set it to True.264
\hypertarget{flatpaks}{\section {Flatpaks}}
{\Large \textbf{\$ flatpak search libreoffice}}{\Large \\
\\
but bash tools keep it simple aka \\
\textbf{\\
\\
	\$ if [ -d /var/lib/flatpak/app}}{\Large \textbf{ | grep *libreoffice* ] ; then ....\\
}}{\Large \\
\\
Also Flatpack LibreOffice , AbiWord etc fonts use the standard FHS font location ie /usr/share/fonts}{\Large }279
\hypertarget{ftp}{\section {FTP}}
tom09052019@lucidflair.com\\
\\
Password  elephantbannanacheeseWATER8956\\
\\
\\
Home Directory /      Leave blank if uncertain\\
\\
\\
This is relative to your home directory. If in doubt, just leave the box blank. \\
Your website files should go into public\_html.\\
\\
\\
==================================================================\\
\\
tomdom@iMac:\~/Documents/James - Recruitment/Lucid Flair \_ gitgigs/Lucid Flair Website/Lucid Flair Website - holding\$ ftp ftp.lucidflair.com\\
Connected to ftp.lucidflair.com.\\
220---------- Welcome to Pure-FTPd [privsep] ----------\\
220-You are user number 152 of 5000 allowed.\\
220-Local time is now 15:40. Server port: 21.\\
220-This is a private system - No anonymous login\\
220-IPv6 connections are also welcome on this server.\\
220 You will be disconnected after 15 minutes of inactivity.\\
Name (ftp.lucidflair.com:tomdom): tom09052019@lucidflair.com\\
331 User tom09052019@lucidflair.com OK. Password required\\
Password:\\
230-This server supports FXP transfers\\
230 OK. Current restricted directory is /\\
Remote system type is UNIX.\\
Using binary mode to transfer files.\\
ftp> ls\\
200-FXP transfer: from 10.168.1.13 to 80.47.11.214\\
200 PORT command successful\\
425 Could not open data connection to port 39569: Network is unreachable\\
ftp> \\
\\
\\
=================================================================\\
\\
tomdom@iMac:\~/Documents/James - Recruitment/Lucid Flair \_ gitgigs/Lucid Flair Website/Lucid Flair Website - holding\$ ftp ftp.gridhost.co.uk\\
Connected to ftp.gridhost.co.uk.\\
220---------- Welcome to Pure-FTPd [privsep] ----------\\
220-You are user number 148 of 5000 allowed.\\
220-Local time is now 16:00. Server port: 21.\\
220-This is a private system - No anonymous login\\
220-IPv6 connections are also welcome on this server.\\
220 You will be disconnected after 15 minutes of inactivity.\\
Name (ftp.gridhost.co.uk:tomdom): tom09052019@lucidflair.com\\
331 User tom09052019@lucidflair.com OK. Password required\\
Password:\\
230-This server supports FXP transfers\\
230 OK. Current restricted directory is /\\
Remote system type is UNIX.\\
Using binary mode to transfer files.\\
ftp> ls\\
200-FXP transfer: from 10.168.1.13 to 80.47.11.214\\
200 PORT command successful\\
\\
\\
\\
=================================================================\\
134
\hypertarget{git_commit_--amend}{\section {git commit --amend}}
https://www.atlassian.com/git/tutorials/rewriting-history?section=git-commit--amend33
\hypertarget{g'mic}{\section {G'MIC}}
\textbf{{\Large }}{\large \\
sudo apt install gimp\\
\\
sudo apt install gimp-plugin-registry\\
\\
\\
\\
\\
\\
dependencies :\\
\\
wget https://gmic.eu/files/linux/gmic\_ubuntu\_bionic\_amd64.deb}{\large \\
\\
sudo apt install libopencv-core3.2 libopencv-imgproc3.2 libopencv-videoio3.2 \\
\\
sudo dpkg -i gmic\_ubuntu\_bionic\_amd64.deb\\
\\
\\
-------------------------------------------------------------------------------------------------------------\\
\\
G'MIC    Bionic Beaver  \\
https://gmic.eu/files/linux/gmic\_ubuntu\_bionic\_amd64.deb}{\large \\
\\
\\
Krita - Bionic Beaver\\
https://gmic.eu/files/linux/gmic\_krita\_qt\_ubuntu\_bionic\_amd64.zip}{\large \\
\\
Gimp - Bionic Beaver\\
https://gmic.eu/files/linux/gmic\_gimp2.8\_qt\_ubuntu\_bionic\_amd64.zip}{\large \\
\\
\\
\\
Gimp plugin folder - standard\\
/home/tomdom/.gimp-2.8/plug-ins}{\large /usr/lib/gimp/2.0/plug-ins}{\large      <-----\\
\\
\\
Gimp plugin folder - 2.10 Snap\\
/snap/gimp/current/usr/lib/gimp/2.0/plug-ins/}{\large /home/tomdom/snap/gimp/current/.config/GIMP/2.10/plug-ins}{\large     <-------\\
\\
\\
Gimp plugin folder - 2.10 Flatpak\\
\~/.var/app/org.gimp.GIMP/config/GIMP/2.10}{\large /var/lib/flatpak/app/org.gimp.GIMP/current/active/files/lib/gimp/2.0/plug-ins}{\large      <-------\\
\\
\\
=======================================================================================\\
\\
for 2.8 plugin\\
\\
pushd /home/tomdom/snap/gimp/current/.config/GIMP/2.10/plug-ins}{\large  \\
\\
sudo wget https://gmic.eu/files/linux/gmic\_gimp2.8\_qt\_ubuntu\_bionic\_amd64.zip}{\large \\
\\
sudo unzip gmic\_gimp2.8\_qt\_ubuntu\_bionic\_amd64.zip \\
\\
sudo rm gmic\_gimp2.8\_qt\_ubuntu\_bionic\_amd64.zip \\
\\
sudo mkdir -p gmic\_gimp\\
\\
sudo mv gmic\_gimp\_qt gmic\_gimp/\\
\\
popd\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
}1385
\hypertarget{heredocs__using_cat_<<_eof_>_fancyhmtl.html}{\section {Heredocs  using Cat << EOF > fancyHMTL.html}}
\textbf{\\
Reminder:\\
\\
\textit{}}Redirection is\textit{ (mostly) \textbf{FOR FILES}}\textit{ (you redirect streams to/from files).\\
\\
	}\\
	Piping\textit{ is \textbf{FOR PROCESSES}}\textit{: you pipe (redirect) streams from one process to another.\\
\\
		Essentially what you really do is ''connect'' one standard stream (usually stdout) of  one process to standard stream of another process (usually stdin) via pipe.\\
\\
		Pipes have also the synchronisation ''side effect'' : they block one process (on reading) when the other has nothing to write (yet) \\
		or when reading process cannot read fast enough (when the pipe's buffer is full).}{\large }{\Large Normally use cat to output text to the terminal\\
\\
cat << \_EOF\_\\
blah blah blah\\
foo bar\\
hello world\\
etc etc etc\\
\_EOF\_\\
\\
where \_EOF\_  is the 'end of file' text (can be anything)\\
\\
Now if we save that file as say catFoo.sh\\
\\
\$ sudo chmod +x catFoo.sh\\
\\
Then  run it \\
\$ ./catFOO.sh  \\
blah blah blah\\
foo bar\\
hello world\\
etc etc etc\\
\\
====  BUT  We can code in here instead !! eg HTML\\
\\
Editing and saving catFoo.sh\\
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\
cat << \_EOF\_ \\
<html>\\
    <head>\\
        <title>This is a test</title>\\
    </head>\\
\\
    <body>\\
        <h1>A fancy new website </h1>\\
        \\
        <p>Jujubes topping tart halvah muffin cookie candy canes lemon drops brownie. Tootsie roll lemon drops fruitcake macaroon sugar plum cheesecake halvah cake sesame snaps. Cupcake cheesecake jelly-o muffin cotton candy dragée danish. Bonbon jelly beans carrot cake dessert cheesecake brownie. Jelly-o icing tiramisu. Powder jelly beans topping chupa chups caramels cake cotton candy donut. Sugar plum gummi bears donut pudding brownie liquorice. Topping sugar plum tootsie roll fruitcake. Chocolate candy canes jujubes. Gummies icing bonbon tart ice cream fruitcake danish bonbon. Sweet roll topping jelly beans danish. Dessert topping cake biscuit powder cotton candy toffee sweet bear claw. Bear claw jelly beans pudding caramels.</p>\\
        \\
        <img src=''http://www.cupcakeipsum.com/assets/blue\_muffin.png''}{\Large  >\\
        \\
    </body>\\
\\
</html>\\
\_EOF\_\\
\\
---------------------------------------\\
\\
Now the clever bit!\\
\\
Redirect the output from the terminal to a file with a .html extension\\
(remember Linux will just create a file if it needs to so no need to use 'touch')\\
\\
Hence\\
\\
\$ ./.catFoo.sh > fancyFooHTML.html\\
\\
and we can open this .html file with a browser eg Falkon\\
\\
\$ falkon fancyFooHTML.html\\
\\
BUT GOING FURTHER !!!\\
\\
\textbf{We can put this redirect in the 'cat' , no need to add it later, hence catFoo.sh becomes}}{\Large \\
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\
cat << \_EOF\_  > fancyFooHTML.html\\
<html>\\
    <head>\\
        <title>This is a test</title>\\
    </head>\\
\\
    <body>\\
        <h1>Now with redirect built in</h1>\\
        \\
        <p>Jujubes topping tart halvah muffin cookie candy canes lemon drops brownie. Tootsie roll lemon drops fruitcake macaroon sugar plum cheesecake halvah cake sesame snaps. Cupcake cheesecake jelly-o muffin cotton candy dragée danish. Bonbon jelly beans carrot cake dessert cheesecake brownie. Jelly-o icing tiramisu. Powder jelly beans topping chupa chups caramels cake cotton candy donut. Sugar plum gummi bears donut pudding brownie liquorice. Topping sugar plum tootsie roll fruitcake. Chocolate candy canes jujubes. Gummies icing bonbon tart ice cream fruitcake danish bonbon. Sweet roll topping jelly beans danish. Dessert topping cake biscuit powder cotton candy toffee sweet bear claw. Bear claw jelly beans pudding caramels.</p>\\
        \\
        <img src=''http://www.cupcakeipsum.com/assets/blue\_muffin.png''}{\Large  >\\
        \\
    </body>\\
\\
</html>\\
\_EOF\_\\
\\
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\
\\
Now the all we need to do is \\
\$ ./catFoo.sh\\
\$ falkon fancyFooHTML.html\\
\\
NEAT !\\
\\
\textbf{ADDING VARIABLE'S , using bash commands}}{\Large \\
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\
\# We can introduce some \hyperlink{variables}{variables}}{\Large  into the HTML\# We can introduce some \hyperlink{variables}{variables}}{\Large  into the HTML\\
\\
MY\_TITLE=''Yet another title goes here''\\
DATE\_IS=\$(date +''\%Y\%m\%d\_\%H\%M\%S'') \# result of executing the date command\\
CREATED\_BY=''this was made by \$USER on \$DATE\_IS''\\
\\
cat << \_EOF\_ > straightToHTML.html\\
\\
<html>\\
    <head>\\
        <title>\$MY\_TITLE</title>\\
    </head>\\
\\
    <body>\\
        <h1>Now with redirect built in</h1>\\
        \\
        <p>\$CREATED\_BY</p>\\
        \\
        <p>Jujubes topping tart halvah muffin cookie candy canes lemon drops brownie. Tootsie roll lemon drops fruitcake macaroon sugar plum cheesecake halvah cake sesame snaps. Cupcake cheesecake jelly-o muffin cotton candy dragée danish. Bonbon jelly beans carrot cake dessert cheesecake brownie. Jelly-o icing tiramisu. Powder jelly beans topping chupa chups caramels cake cotton candy donut. Sugar plum gummi bears donut pudding brownie liquorice. Topping sugar plum tootsie roll fruitcake. Chocolate candy canes jujubes. Gummies icing bonbon tart ice cream fruitcake danish bonbon. Sweet roll topping jelly beans danish. Dessert topping cake biscuit powder cotton candy toffee sweet bear claw. Bear claw jelly beans pudding caramels.</p>\\
        \\
        <img src=''http://www.cupcakeipsum.com/assets/blue\_muffin.png''}{\Large  >\\
        \\
    </body>\\
\\
</html>\\
\_EOF\_\\
\\
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
}676
\hypertarget{how_to_find_your_ip_address_in_linux}{\section {How to find your IP address in Linux}}
{\large https://opensource.com/article/18/5/how-find-ip-address-linux}{\large }
\begin{itemize}
\item \textbf{\textit{{\Large curl ifconfig.me}}}
\end{itemize}
{\large }
\begin{itemize}
\item {\large curl -4/-6 icanhazip.com}
\item {\large curl ipinfo.io/ip}
\item {\large curl api.ipify.org}
\item {\large curl checkip.dyndns.org}
\item {\large dig +short myip.opendns.com @resolver1.opendns.com}
\item {\large host myip.opendns.com resolver1.opendns.com}
\item {\large curl ident.me}
\item {\large curl bot.whatismyipaddress.com}
\item {\large curl ipecho.net/plain}
\end{itemize}
{\Large \\
\\
The following commands will get you the private IP address of your interfaces:\\
\\
\\
}
\begin{itemize}
\item \textbf{\textit{{\Large hostname -I | cut -d' ' -f1}}}
\end{itemize}
{\large }
\begin{itemize}
\item {\large hostname -I | awk '\{print \$1\}'}
\item {\large ifconfig -a}
\item {\large ip addr (ip a)}
\item {\large ip route get 1.2.3.4 | awk '\{print \$7\}'}
\end{itemize}
{\large \\
(Fedora) Wifi-Settings→ click the setting icon next to the Wifi name that you are connected to → Ipv4 and Ipv6 both can be seen\\
\\
    nmcli -p device show\\
\\
Note: Some utilities need to be installed on your system based on the Linux distro you are using. Also, some of the noted commands use a third-party website to get the IP}471
\hypertarget{how_to_view_source_code}{\section {How to view source code}}
http://xxxxxxxx\\
to see HTML source code of the site !53
\hypertarget{https://youtu.be/wx6-axutjck}{\section {https://youtu.be/wX6-AxuTJck}}
https://www.aswf.io/\# Another miss understanding is when you talk about 'Ubuntu' video editors. In an open source platform, those 'third party' apps are typically front end GUI's. What powers Linux video is the engines which are open source and driven by the industry for example the MLT multimedia framework and ffmpeg are typically used by the editors/ encoders eg Handbrake. Ffmpeg is also often used at the command line as I do myself routinely, eg to convert a batch of files video format. The community wouldn't want Ubuntu (Canonical) to make 'video editors' (they certainly wouldn't either!), they just support the underlying technology eg ffmpeg , that's exactly what the community wants and that's how the ecosystem grows. Moreover you stated mp3 requires a license... err..nope. not since 2012. But its not an issue anyhow because Opus was developed (mp3 is dated tech). That's what your using right now in fact as Google is one of the companies who develop it for YouTube. Ffmpeg , the video/media engine used by Linux distros also comes with the latest encoders including opus direct from the same code base that Google works on. As for Adobe on Linux, ok but personally I'd use DR anyhow, if I were doing high end pro-editing , combined with my own scripts in ffmpeg. Especially as getting a basic Blackmagic pocket 4k would be an obvious choice even if just as a B camera for many even small film companies at just \$1.3K. This would give you the full Davinci Resolve license too. https://www.blackmagicdesign.com/products/blackmagicpocketcinemacamera  Its good you tried to discuss Linux , but sorry you come across as Windows users that don't understand the Linux ethos and ecosystem very well. You need to explore some more, and 'live' in the Linux system somewhat. Mac is different from Windows, Linux is very different.﻿214
\hypertarget{imagemagic}{\section {ImageMagic}}
{\large To shrink or compress in Imagemagick\\
\\
https://www.smashingmagazine.com/2015/06/efficient-image-resizing-with-imagemagick/}{\large \\
\\
--------------------\\
\\
\$ mkdir compressed\\
\\
for f in *.jpg; do convert ''\$f'' -quality 70 compressed/''\$f''; done \\
}157
\hypertarget{install_gimp_plug-ins_into_2.10}{\section {Install GIMP Plug-ins into 2.10}}
{\large To easily download around 100 plugins on Linux install the 'gimp-plugin-registry' \\
\\
1) First ensure plug-in folder exists. If you already have 2.8 install it will exist but just to make sure\\
\$ mkdir -p /usr/lib/gimp/2.0/plug-ins}{\large \\
\\
\\
2) Install the 'gimp-plugin-registry' for Debian/Ubuntu this is\\
\$ sudo apt install gimp-plugin-registry\\
\\
This installs a bunch (100 ish) plugins into usr/lib/gimp/2.0/plug-ins\\
\\
3)  copy the plugin scripts to the 2.10 folder \\
\\
If you've installed via Flatpak GIMP install\\
\$ cp -r /usr/lib/gimp/2.0/plug-ins}{\large \~/.var/app/org.gimp.GIMP/config/GIMP/2.10}{\large \\
\\
If you've installed via Snap GIMP Install\\
\$ cp -r /usr/lib/gimp/2.0/plug-ins}{\large \~/snap/gimp/47/.config/GIMP/2.10}{\large \\
\\
\\
TL;DR\\
\$ mkdir -p /usr/lib/gimp/2.0/plug-ins}{\large \\
\$ sudo apt install gimp-plugin-registry\\
\$ cp -r /usr/lib/gimp/2.0/plug-ins}{\large \~/.var/app/org.gimp.GIMP/config/GIMP/2.10}{\large   \\
OR\\
\$ cp -r /usr/lib/gimp/2.0/plug-ins}{\large \~/snap/gimp/47/.config/GIMP/2.10}{\large \\
\\
\\
\\
---------------------------------------\\
Note: If you haven't already installed Gimp 2.10 I recommend Flatpak or Snaps as modern developer orientated distribution systems\\
\\
* Flatpak\\
To check if Flatpak installed\\
\$ flatpak --version\\
\\
If not, then to install go to https://flatpak.org/setup/}{\large \\
\\
And to install Gimp 2.10\\
\$ flatpak install https://flathub.org/repo/appstream/org.gimp.GIMP.flatpakref}{\large \\
\\
To update ALL your flatpak's   \\
\$ flatpak update\\
\\
* Snap\\
To check if Snap already installed (default in Ubuntu)\\
\$ snap --version\\
\\
If not, then install via\\
\$ sudo apt install snapd\\
\\
Then to install Gimp 2.10\\
\$ sudo snap install gimp\\
\\
To refresh ALL your snaps \\
\$ snap refresh}264
\hypertarget{installing_gimp_2.10.x_filters_via_snaps_and_flatpak}{\section {Installing GIMP 2.10.x Filters via Snaps and Flatpak}}
/usr/lib/gimp/2.0/plug-ins \&\& sudo apt install gimp-plugin-registry \&\& cp -r /usr/lib/gimp/2.0/plug-ins\~/.var/app/org.gimp.GIMP/config/GIMP/2.10\\
\\
\\
For Snap\\
Code:\\
\$ sudo mkdir -p /usr/lib/gimp/2.0/plug-ins \&\& sudo apt install gimp-plugin-registry \&\& cp -r /usr/lib/gimp/2.0/plug-ins\~/snap/gimp/47/.config/GIMP/2.10\\
\\
\\
\\
Longer more detailed description\\
\\
1)  \\
I assumed that you may not have installed GIMP 2.8, so the first step is either to install GIMP 2.8, OR create a set of 'fake' directory's for the filter scripts to go into that would exist if you had installed GIMP 2.8\\
\\
Code:\\
\$ sudo mkdir -p /usr/lib/gimp/2.0/plug-ins\\
\\
2)\\
Install the gimp-plugin-registry to get the scripts\\
Code:\\
\$ sudo apt install gimp-plugin-registry\\
\\
\\
3)\\
Now you need to move or copy (I chose copy because I also wanted to keep GIMP 2.8) these python scripts to the correct folder in Flatpak and Snap\\
\\
Flatpak\\
Code:\\
\$ cp -r /usr/lib/gimp/2.0/plug-ins\~/.var/app/org.gimp.GIMP/config/GIMP/2.10\\
\\
Note: you can find the Flatpak directory from\\
\\
Code:\\
find \~/.var plug-ins | grep GIMP/2.10/plug-ins | head -1\\
which, if Flatpak installed will return\\
/home/yourusername/.var/app/org.gimp.GIMP/config/GIMP/2.10/plug-ins\\
\\
Snap\\
Code:\\
\$ cp -r /usr/lib/gimp/2.0/plug-ins\~/snap/gimp/47/.config/GIMP/2.10\\
\\
\\
Note: you can find the Snap directory from\\
\\
Code:\\
find \~/snap plug-ins | grep GIMP/2.10/plug-ins | head -1\\
which, if Snap installed will return\\
/home/yourusername/snap/gimp/47/.config/GIMP/2.10/plug-ins\\
\\
\\
\\
4)\\
If needed delete original directory\\
\\
Code:\\
\$ rm -r /usr/lib/gimp/2.0/plug-ins\\
\\
\\
\\
\\
NOTES:\\
\\
To check if Flatpak installed\\
Code:\\
\$ command -p flatpak\\
\\
To install Flatpak\\
Code:\\
\$ sudo add-apt-repository ppa:alexlarsson/flatpak\\
\$ sudo apt update\\
\$ sudo apt install flatpak\\
\\
To install Gimp 2.10 via Flatpak\\
\\
Code:\\
\$ flatpak install https://flathub.org/repo/appstream/org.gimp.GIMP.flatpakref\\
\\
\\
To update ALL your flatpak's\\
Code:\\
\$ flatpak update\\
\\
\\
\\
\\
To check if Snap already installed (default in Ubuntu) and install GIMP\\
\\
Code:\\
\$ command -p snap\\
\\
\\
To install Snap\\
Code:\\
\$ sudo apt update\\
\$ sudo apt install snapd\\
\\
\\
Then to install Gimp 2.10 via Snap\\
Code:\\
\$ sudo snap install gimp\\
\\
\\
To refresh ALL your snaps\\
Code:\\
\$ snap refresh\\
\\
\\
\\
\\
To find the install location via the GIMP software itself\\
\\
Edit --> Preferences \\
scroll down to folders, click on folders\\
click on icon '2.10' , the swap folder\\
click on 'other'\\
you should now see the location of where your GIMP directory location is470
\hypertarget{installing_on_linux_via_sourc.list_and_apt-key}{\section {Installing on Linux via sourc.list and apt-key}}
\textbf{Riot-web}\\
\\
sudo sh -c ''echo 'deb https://riot.im/packages/debian/ artful main' > /etc/apt/sources.list.d/matrix-riot-im.list''\\
\\
curl -L https://riot.im/packages/debian/repo-key.asc | sudo apt-key add -\\
\\
sudo apt-get update \&\& sudo apt-get -y install riot-web \\
\\
\\
\textbf{WeeChat}\\
\\
\# Clone this repo\\
\\
git clone https://github.com/torhve/weechat-matrix-protocol-script.git\\
\\
\# Copy the script into WeeChat's Lua dir\\
\\
\# mkdir -p \~/.weechat/lua/\\
\\
cp weechat-matrix-protocol-script/matrix.lua \~/.weechat/lua/\\
\\
\# Make a symlink into the autoload dir to load script automatically when WeeChat starts\\
\\
ln -s \~/.weechat/lua/matrix.lua\~/.weechat/lua/autoload\\
\\
\\
\# Clone this repo\\
\\
git clone https://github.com/torhve/weechat-matrix-protocol-script.git\\
\\
\# Copy the script into WeeChat's Lua dir\\
\\
\# mkdir -p \~/.weechat/lua/\\
\\
cp weechat-matrix-protocol-script/matrix.lua \~/.weechat/lua/\\
\\
\# Make a symlink into the autoload dir to load script automatically when WeeChat starts\\
\\
ln -s \~/.weechat/lua/matrix.lua\~/.weechat/lua/autoload\\
\\
\$ sudo apt install weechat-curse\\
\\
\# Start WeeChat\\
\\
weechat\\
\\
\\
\\
\\
\\
\\
\textbf{Signal}1118
\hypertarget{lamp_stack_+_wp}{\section {LAMP stack + WP}}
{\large on Ubuntu 16.04\\
\\
https://www.digitalocean.com/community/tutorials/how-to-install-wordpress-with-lamp-on-ubuntu-16-04}{\large https://www.digitalocean.com/community/tutorials/how-to-install-linux-apache-mysql-php-lamp-stack-on-ubuntu-16-04}{\large }\textbf{{\Large \\
How To Install Linux, Apache, MySQL, PHP (LAMP) stack on Ubuntu 16.04 }}{\large \\
\\
\\
Linux\\
Apache\\
MySQL\\
PHP\\
\\
\textbf{1) Create a non-root user account with sudo privileges set up on your serve}}{\large r\\
This is typically done as default in initial set-up for desktop use.\\
\\
\\
\textbf{2)Install Apache Web server}}{\large \\
\\
Check if already installed\\
\$ apt list apache*\\
\\
and/or\\
\\
\$ apache2 --v\\
\\
and if not installed or unsure\\
\\
\$ sudo apt update \&\& sudo apt install apache2\\
\\
\textbf{3) Set Global ServerName}}{\large \\
\\
Amend the apache2 configuration file 'apache2.conf'\\
\\
Hence before amending if we do\\
\\
\$ sudo apache2ctl configtest \\
---->\\
AH00558: apache2: Could not reliably determine the server's fully qualified domain name, using 127.0.1.1. Set the 'ServerName' directive globally to suppress this message}{\large \\
Syntax OK\\
\\
Thus to edit the config file\\
\\
\$ kwrite sudoedit /etc/apache2/apache2.conf}{\large \\
\\
OR\\
\\
\$ sudo nano /etc/apache2/apache2.conf}{\large \\
\\
Inside, at the bottom of the file, add a ServerName directive, pointing to your primary domain name. \\
\\
--------------------------------------------------------\\
.\\
.\\
.\\
ServerName 127.0.0.1\\
--------------------------------------------------------\\
\\
where 127.0.0.1 is localhost  hence:\\
\\
\$ sudo apache2ctl configtest\\
Syntax OK\\
\\
\\
restart the apache2 server\\
\\
\$ sudo systemctl restart apache2\\
\\
\\
Check if apache is listed on the uncomplicated firewall\\
\\
\$ sudo ufw app list\\
---->\\
Available applications:\\
  Apache\\
  Apache Full\\
  Apache Secure\\
  CUPS\\
\\
so we see it is\\
\\
Checking the list in detail\\
\\
\$ sudo ufw app info ''Apache Full'' \\
---->\\
Profile: Apache Full\\
Title: Web Server (HTTP,HTTPS)\\
Description: Apache v2 is the next generation of the omnipresent Apache web\\
server.\\
\\
Ports:\\
  80,443/tcp\\
\\
\\
Now checkout\\
127.0.0.1\\
\\
Should get the ''Apache2 Ubuntu Default Page''\\
\\
\\
\textbf{Install MySQL / Mariadb}}{\large \\
\\
Check if this has been installed already\\
\\
\$ sudo apt list --installed | grep  mysql*\\
\\
If mySQL , or MariaDb is not installed\\
\\
\$ sudo apt-get install mariadb-server mariadb-client\\
\$ sudo mysql\_secure\_installation\\
\\
[https://www.itzgeek.com/how-tos/linux/ubuntu-how-tos/install-mariadb-on-ubuntu-16-04.html}{\large ]\\
\\
\textbf{Install PHP}}{\large \\
\\
Check if PHP has been installed already\\
\\
\$ sudo apt list --installed | grep  PHP*\\
\\
Also\\
\\
\$sudo apt list --installed | grep  libapache2-mod-php*\\
\\
\$ sudo apt list --installed | grep php-mcrypt\\
\\
\\
If not, to install PHP\\
\$ sudo apt-get install php libapache2-mod-php php-mcrypt php-mysql\\
\\
\\
Note the 'libapache2-mod-php''  ''php-mcrypt''   ''php-mysql''  helper packages\\
\\
\\
Need to tell Apache to prefer PHP files, so getApache to look for an index.php file first.\\
\\
Open the dir.conf file in a text editor\\
\\
\$ kwrite sudoedit /etc/apache2/mods-enabled/dir.conf}{\large \\
OR\\
\$ sudo nano /etc/apache2/mods-enabled/dir.conf}{\large \\
\\
It will look like\\
-----------------------------------------------------------------------------------------\\
<IfModule mod\_dir.c>\\
    DirectoryIndex index.html index.cgi index.pl index.php index.xhtml index.htm\\
</IfModule>\\
-----------------------------------------------------------------------------------------\\
\\
put index.php to the front i.e. need to make the file look like this\\
------------------------------------------------------------------------------------------\\
<IfModule mod\_dir.c>\\
    DirectoryIndex index.php index.html index.cgi index.pl index.xhtml index.htm\\
</IfModule>\\
------------------------------------------------------------------------------------------\\
\\
Save and restart the Apache server\\
\\
\$ sudo systemctl restart apache2\\
\\
and to look at the status of the Apache server\\
\\
\$ sudo systemctl status apache2\\
--->\\
}● apache2.service - The Apache HTTP Server\\
   Loaded: loaded (/lib/systemd/system/apache2.service; enabled; vendor preset: enabled)\\
  Drop-In: /lib/systemd/system/apache2.service.d\\
           └─apache2-systemd.conf\\
   Active: active (running) since Mon 2018-06-25 16:07:21 BST; 10s ago\\
  Process: 20310 ExecStop=/usr/sbin/apachectl stop (code=exited, status=0/SUCCESS)\\
  Process: 3618 ExecReload=/usr/sbin/apachectl graceful (code=exited, status=0/SUCCESS)\\
  Process: 20315 ExecStart=/usr/sbin/apachectl start (code=exited, status=0/SUCCESS)\\
 Main PID: 20327 (apache2)\\
    Tasks: 6 (limit: 4915)\\
   Memory: 31.7M\\
      CPU: 63ms\\
   CGroup: /system.slice/apache2.service\\
           ├─20327 /usr/sbin/apache2 -k start\\
           ├─20332 /usr/sbin/apache2 -k start\\
           ├─20333 /usr/sbin/apache2 -k start\\
           ├─20335 /usr/sbin/apache2 -k start\\
           ├─20336 /usr/sbin/apache2 -k start\\
           └─20339 /usr/sbin/apache2 -k start\\
\\
Jun 25 16:07:21 tomdom-iMac systemd[1]: Starting The Apache HTTP Server...\\
Jun 25 16:07:21 tomdom-iMac systemd[1]: Started The Apache HTTP Server.{\large \textbf{Install PHP modules}}{\large \\
\\
(Optional PHP modules to install)\\
\\
To see them\\
\\
\$ apt-cache search php- | less\\
\\
\$ apt-cache show \textit{package1 package2 package3 ....}}{\large \textbf{Test PHP on web server}}{\large \\
\\
Need to create a PHP test script 'info.php'\\
\\
Save this to the 'web root' directory which in Ubuntu 16.04 is /var/www/html/}{\large \\
\\
Hence\\
\\
\$ cd /var/www/html}{\large  \\
\\
\$ sudo touch info.php\\
\\
\$ kwrite sudoedit info.php\\
\\
info.php\\
---------------------------------\\
<?php \\
phpinfo();\\
?>\\
---------------------------------\\
\\
NOTE:\\
Tried \$ sudo cat > info.php   method but didn't get the superuser right\\
\\
\\
Now checkout URL  127.0.0.1/info.php  \\
\\
And should see the purple 'PHP Version' default page\\
\\
This means its worksing ok. Now delete the info.php file\\
\\
\$ sudo rm /var/www/html/info.php}{\large \\
\\
\\
LAMP STACK INSTALLED !\\
\\
\\
Now install/ tweak for Wordpress, add phpMyAdmin etc\\
\\
For WordPress\\
\\
Create a sudo user on your server\\
\\
Install a LAMP stack\\
\\
Secure your site with SSL\\
	1) Have a domain name... try Let's Encrypt\\
	2) For testing or personal use, use a self-signed certificate\\
\\
[https://www.digitalocean.com/community/tutorials/how-to-create-a-self-signed-ssl-certificate-for-apache-in-ubuntu-16-04}{\large ]\\
transport layer security (TLS),or  secure sockets layer (SSL)\\
web protocols used to wrap normal traffic in a protected, encrypted wrapper.\\
\\
1) Create the SSL Certificate\\
\\
\$ sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/ssl/private/apache-selfsigned.key}{\large  -out /etc/ssl/certs/apache-selfsigned.crt}{\large \\
\\
\\
Fill out the prompts\\
The Common Name (e.g. server FQDN or YOUR name). \\
You need to enter the domain name associated with your server or, more likely, your server's public IP address.\\
\\
Files created in the subdirectories of /etc/ssl}{\large  directory.\\
\\
\$ cd /etc/ssl}{\large \\
certs  openssl.cnf  private\\
\\
\$ sudo openssl dhparam -out /etc/ssl/certs/dhparam.pem}{\large  2048\\
This generates DH parameters; takes a few minutes\\
\\
2) Configure Apache to Use SSL\\
\\
Create a configuration snippet to specify strong default SSL settings\\
\\
\$ sudo nano /etc/apache2/conf-available/ssl-params.conf}{\large \\
\\
[https://cipherli.st/}{\large ]\\
\\
To set up Apache SSL securely, we will be using the recommendations by Remy van Elst on the Cipherli.st site. \\
This site is designed to provide easy-to-consume encryption settings for popular software.\\
\\
------------------------------------------------\\
\# from https://cipherli.st/}{\large \\
\# and https://raymii.org/s/tutorials/Strong\_SSL\_Security\_On\_Apache2.html}{\large \\
\\
SSLCipherSuite EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH\\
SSLProtocol All -SSLv2 -SSLv3\\
SSLHonorCipherOrder On\\
\# Disable preloading HSTS for now.  You can use the commented out header line that includes\\
\# the ''preload'' directive if you understand the implications.\\
\#Header always set Strict-Transport-Security ''max-age=63072000; includeSubdomains; preload''\\
Header always set Strict-Transport-Security ''max-age=63072000; includeSubdomains''\\
Header always set X-Frame-Options DENY\\
Header always set X-Content-Type-Options nosniff\\
\# Requires Apache >= 2.4\\
SSLCompression off \\
SSLSessionTickets Off\\
SSLUseStapling on \\
SSLStaplingCache ''shmcb:logs/stapling-cache(150000)''\\
\\
SSLOpenSSLConfCmd DHParameters ''/etc/ssl/certs/dhparam.pem''\\
------------------------------------------------\\
\\
save and exit\\
\\
\\
\textbf{Modify the Default Apache SSL Virtual Host File}}{\large \\
\\
Virtual Host file to point to our generated SSL certificates.\\
Also automatically redirect requests to the encrypted Virtual Host.\\
\\
Backup original SSL Vitual Host file\\
\\
\$ sudo cp /etc/apache2/sites-available/default-ssl.conf}{\large /etc/apache2/sites-available/default-ssl.conf.bak}{\large \\
\\
open the SSL Virtual Host file to make adjustments\\
\\
\$ sudo nano /etc/apache2/sites-available/default-ssl.conf}{\large \\
\\
Set ServerAdmin email address, ServerName, etc.\\
adjust the SSL directives to point to our certificate and key files\\
uncomment the section that provides compatibility for older browsers.\\
\\
After making these changes, your server block should look similar to this:\\
\\
-----------------------------------\\
<IfModule mod\_ssl.c>\\
        <VirtualHost \_default\_:443>\\
                ServerAdmin your\_email@example.com}{\large \\
                ServerName server\_domain\_or\_IP\\
\\
                DocumentRoot /var/www/html}{\large \\
\\
                ErrorLog \$\{APACHE\_LOG\_DIR\}/error.log\\
                CustomLog \$\{APACHE\_LOG\_DIR\}/access.log combined\\
\\
                SSLEngine on\\
\\
                SSLCertificateFile      /etc/ssl/certs/apache-selfsigned.crt}{\large \\
                SSLCertificateKeyFile /etc/ssl/private/apache-selfsigned.key}{\large \\
\\
                <FilesMatch ''\\.(cgi|shtml|phtml|php)\$''>\\
                                SSLOptions +StdEnvVars\\
                </FilesMatch>\\
                <Directory /usr/lib/cgi-bin>}{\large \\
                                SSLOptions +StdEnvVars\\
                </Directory>\\
\\
                BrowserMatch ''MSIE [2-6]'' \\\\
                               nokeepalive ssl-unclean-shutdown \\\\
                               downgrade-1.0 force-response-1.0\\
\\
        </VirtualHost>\\
</IfModule>\\
\\
-----------------------------------\\
save and exit\\
\\
\\
\textbf{Modify the Unencrypted Virtual Host File to Redirect to HTTPS}}{\large \\
\\
For better security, it is recommended in most cases to redirect HTTP to HTTPS automatically. If you do not want or need this functionality, you can safely skip this section.\\
\\
[I'll skip]\\
\\
\textbf{Adjust the Firewall}}{\large \\
\\
\$ sudo ufw app list\\
\\
Should see\\
------------------\\
Available applications:\\
  Apache\\
  Apache Full\\
  Apache Secure\\
  OpenSSH\\
------------------\\
\\
To allow OpenSSH\\
\\
\$ sudo ufw allow 'OpenSSH'\\
\\
\\
To allow for HTTPS [which we've not setup here]\\
\\
\$ sudo ufw allow  'Apache Full'\\
\$ sudo ufw delete allow 'Apache'\\
\\
\\
\\
\$ sudo ufw status\\
\\
\\
\textbf{Enable the Changes in Apache}}{\large \\
\\
Enable mod\_ssl, the Apache SSL module, and mod\_headers, needed by some of the settings in our SSL snippet, with the a2enmod command:\\
\\
\$ sudo a2enmod ssl\\
\$ sudo a2enmod headers\\
\\
\$ sudo a2ensite default-ssl\\
\\
\$ sudo a2enconf ssl-params\\
\\
\$ sudo apache2ctl configtest\\
\\
\$ systemctl restart apache2\\
\\
\$ systemctl reload apache2\\
\\
\textbf{Test Encryption}}{\large https://127.0.0.1}{\large \\
\\
Should get a 'scary warning' --> that's actually ok\\
\\
\\
\\
\\
\\
Change to a Permanent Redirect\\
....\\
\\
\\
skipped...\\
\\
\\
-------------\\
\\
INSTALL WORDPRESS !!\\
\\
\textbf{Create a MySQL Database and User for WordPress}}{\large \\
\\
\\
log into the MySQL root\\
\\
\$ mysql -u root -p\\
Note: default password is sometimes 'password', 'root' 'admin' or blank [return key]\\
\\
Checkout the current databases available\\
mysql>show databases;\\
+--------------------+\\
| Database           |\\
+--------------------+\\
| information\_schema |\\
| mysql              |\\
| performance\_schema |\\
| sys                |\\
| wordpress          |\\
| wp\_headless        |\\
+--------------------+\\
6 rows in set (0.18 sec)\\
\\
Here we already have a wordpress db.\\
\\
mysql> CREATE DATABASE wordpress2}{\large  DEFAULT CHARACTER SET utf8 COLLATE utf8\_unicode\_ci;\\
\\
Now create a mysql user account called 'wordpressuser' for this wordpress2 database. This approach is typical\\
\\
mysql> GRANT ALL ON wordpress2.* TO 'wordpressuser}{\large '@'localhost' IDENTIFIED BY 'password}{\large ';\\
Query OK, 0 rows affected, 1 warning \\
\\
So mysql knows of recent changes\\
\\
mysql> FLUSH PRIVILEGES;\\
\\
mysql> exit;\\
\\
\\
\textbf{Install Additional PHP Extensions}}{\large \\
\\
\\
Only need a very minimal set of extensions to link PHP to MySQL. \\
WordPress / plugins leverage additional PHP extensions.\\
\\
\$ sudo apt-get update\\
\\
\$ sudo apt-get install php-curl php-gd php-mbstring php-mcrypt php-xml php-xmlrpc\\
\\
\$ sudo systemctl restart apache2\\
\\
\\
\textbf{Adjust Apache's Configuration to Allow for .htaccess Overrides and Rewrites}}{\large \\
\\
The use of .htaccess files is disabled. \\
WordPress and many WordPress plugins use these files extensively for in-directory tweaks to the web server's behaviour.\\
\\
\\
Enable .htaccess Overrides\\
\\
\$ sudo nano /etc/apache2/apache2.conf}{\large \\
\\
------\\
<Directory /var/www/html/>}{\large \\
    AllowOverride All\\
</Directory>\\
------\\
\\
What I did\\
======\\
<Directory /var/www/html/>}{\large \\
        Options Indexes FollowSymLinks\\
        AllowOverride All \\
        Require all granted\\
</Directory>\\
======\\
\\
save and exit\\
\\
Enable the Rewrite Module\\
\\
\$ sudo a2enmod rewrite\\
\\
Enable the Changes\\
\\
\$ sudo apache2ctl configtest\\
\\
\\
\$ sudo systemctl restart apache2\\
\\
\\
\textbf{Download WordPress}}{\large \\
\\
Change into a writable directory \\
\\
\$ cd myWordpressFolder\\
\\
then download the compressed release by typing:\\
\\
\$ curl -O https://wordpress.org/latest.tar.gz}{\large \\
\\
\$ tar xzvf latest.tar.gz\\
\\
we can add a dummy .htaccess file and set its permissions use later\\
\\
\$ cd wordpress\\
\\
\$ touch .htaccess\\
\\
\$ chmod 660 .htaccess\\
\\
Create a wp-config by copying the sample default\\
\$ cp wp-config-sample.php wp-config.php\\
\\
To fix permissions issues on update to Wordpress, create the upgrade directory\\
\\
\$ pwd\\
wordpress\\
\\
\$ mkdir wp-content/upgrade\\
\\
\\
copy everything [ ' . ' ] including hidden files [eg ' .htaccess '] from the WP directory into web document root.\\
\\
' -a ' option to maintain permissions.\\
\\
\$ cd ..\\
\\
\$ pwd\\
wp-test   [the project directory]\\
\\
\\
\$ sudo cp -a wordpress/. /var/www/html}{\large \textbf{Configure the WordPress Directory}}{\large \\
\\
Adjusting the Ownership and Permissions\\
\\
Write files normal user\\
also web server to also be able to access and adjust certain files and directories in order to function correctly.\\
\\
assigning ownership over all of the files in our document root to our username 'tomdom'\\
\\
\$ sudo chown -R tomdom:www-data /var/www/html}{\large \\
\\
\\
Next, we will set the setgid bit on each of the directories within the document root. This causes new files created within these directories to inherit the group of the parent directory (which we just set to www-data) instead of the creating user's primary group. This just makes sure that whenever we create a file in the directory on the command line, the web server will still have group ownership over it.\\
\\
\$ sudo find /var/www/html}{\large  -type d -exec chmod g+s \{\} \\;\\
\\
give group write access to the wp-content directory so that the web interface can make theme and plugin changes:\\
\\
\$ sudo chmod g+w /var/www/html/wp-content}{\large \\
\\
give the web server write access to all of the content in these two directories:\\
\\
\$ sudo chmod -R g+w /var/www/html/wp-content/themes}{\large \\
\\
\$ sudo chmod -R g+w /var/www/html/wp-content/plugins}{\large \textbf{Setting up the WordPress Configuration File}}{\large \\
\\
 WordPress provides a secure generator for these values so that you do not have to try to come up with good values on your own. These are only used internally, so it won't hurt usability to have complex, secure values here.\\
\\
To grab secure values from the WordPress secret key generator, type:\\
\\
\$ curl -s https://api.wordpress.org/secret-key/1.1/salt/}{\large \\
\\
\\
Copy this 'SALT' info on terminal\\
\\
\$ nano /var/www/html/wp-config.php}{\large \\
\\
replace the dummy values with the 'SALT' stuff copied\\
\\
ie. this\\
\\
---------------------------\\
define('AUTH\_KEY',         'put your unique phrase here');\\
define('SECURE\_AUTH\_KEY',  'put your unique phrase here');\\
define('LOGGED\_IN\_KEY',    'put your unique phrase here');\\
define('NONCE\_KEY',        'put your unique phrase here');\\
define('AUTH\_SALT',        'put your unique phrase here');\\
define('SECURE\_AUTH\_SALT', 'put your unique phrase here');\\
define('LOGGED\_IN\_SALT',   'put your unique phrase here');\\
define('NONCE\_SALT',       'put your unique phrase here');\\
---------------------------\\
\\
\\
is replaced by\\
---------------------------\\
define('AUTH\_KEY',         'S*>Gt3umWp|Pl1(G\{+\{?\~Ff|X3D\~vt\}\^B,O-fY9i69Np/GS!WJ\#QW+4PzLc qx(!');\\
define('SECURE\_AUTH\_KEY',  'z9sC3<y*v\~:\#3=j);1X8z`h|\%C+1|r`6lAHo?ok/5J\_ePq>/qahncsDyy0Hb|4PV');\\
define('LOGGED\_IN\_KEY',    'qfhq6Pl2pePm\_Jh.E:O\}Sb\$G=:,T1Xbk\&l XV3vr0xnW1;svkqH.f: 5b@bH`Oz7');\\
define('NONCE\_KEY',        ' |/> R;zalGf6t\}q(\{l:6ll\{?S!pZ+Smq/Kuf\_m+\#b[Q-W,C BGryF!29N\^hsT\&X');\\
define('AUTH\_SALT',        '|U1VG;sLzPcwN?6D\%.BD(CZ\#M6\{|hz)Fr`L8-kd6,\^4pevb(FQczS2iX*gM*g\_t\$');\\
define('SECURE\_AUTH\_SALT', 'w\{u2?h\#+0RBs+JpBS\&V71Ayg\&]\$po7pjd7Qrw+(c)p>[qE\$:Tz5NX<t\_6d|>.p1q');\\
define('LOGGED\_IN\_SALT',   '-T:\$96:9,6QW\&8aJ69eV;B\#-LGVkG1MiT*x\~)/Hzc@U*vg\$1S3x(`gKpT09kw5u\{');\\
define('NONCE\_SALT',       '2mV./IRd (-wkarn4\&aW1\%bSM+NT.zm>,|mby\{PZ<*@T9\~[i<Xgbw4j3 \~\^G\{z\^Z');\\
---------------------------\\
\\
Go to the top of file to adjust database name, user and password configured within MySQL hence:\\
\\
----------------------------\\
define('DB\_NAME', 'wordpress2');\\
\\
/** MySQL database username */\\
define('DB\_USER', 'wordpressuser');\\
\\
/** MySQL database password */\\
define('DB\_PASSWORD', 'password');\\
----------------------------\\
\\
\\
WordPress should use to write to the filesystem. \\
Explicitly set the filesystem method to ''direct'' by adding in wp-config.php\\
----------------------------------------\\
define('FS\_METHOD', 'direct');\\
-----------------------------------------\\
\\
save and exit wp-config.php\\
\\
\\
\textbf{Complete the Installation Through the Web Interface}}{\large \\
\\
\\
In your web browser, navigate to your server's domain name or public IP address:\\
\\
http://server\_domain\_or\_IP}{\large \\
\\
\\
In my case I chose localhost,  127.0.0.1\\
\\
\\
Select language  English (UK)\\
\\
Fill in the ' 5 minute WordPress installation' eg \\
You can change settings later\\
\\
Site Title:  toms-dev-wp-guten-react-site\\
\\
username: tomdom\\
\\
password: password\\
confirm weak password\\
\\
email: tom@appijumbo.com}{\large \\
\\
confirm discourage robots\\
\\
------------------------\\
Success ! ---->  prompt given\\
------------------------\\
\\
\textbf{Upgrading WordPress}}{\large You can't install updates through the interface with the current permissions}{\large \\
\\
This is to get a balance between security and usability.\\
\\
To give the web server access to the whole document root and allow updates\\
\\
\$ sudo chown -R www-data /var/www/html}{\large \\
\\
And to turn this off post updates to WordPress ['tomdom' is username]\\
\\
\$ sudo chown -R tomdom /var/www/html}{\large \\
\\
BUT IF YOUR JUST DOING A LOCALHOST TEST SITE \\
DON'T NEED THIS !!\\
\\
=============================\\
\\
\textbf{ADD GUTENBURG and Guten-block-react}}{\large \\
\\
\$ cd /var/www/html/wp-content/plugins}{\large \\
\$ sudo wget https://downloads.wordpress.org/plugin/gutenberg.3.1.0.zip}{\large \\
\$ sudo unzip gutenberg.3.1.0.zip\\
\$ sudo rm gutenberg.3.1.0.zip\\
\\
-------------------------------------------------------------------\\
in /var/www/html/wp-content/plugins}{\large \\
ls -al\\
----->\\
drwxrwsr-x  5 www-data   www-data 4096 Jun 26 17:30 .\\
drwxrwsr-x  7 www-data   www-data 4096 Jun 26 11:29 ..\\
drwxr-xr-x   4 www-data   www-data 4096 Jun 26 11:37 akismet\\
drwxr-sr-x   7 root    }{\large          www-data 4096 Jun 21 17:04 gutenberg\\
-rw-rw-r--     1 www-data  www-data   28 Jun  5  2014 index.php\\
drwxr-sr-x    3 root }{\large            www-data 4096 Jun 26 17:31 mygutenblock\\
-rw-r--r--       1 root}{\large             www-data   27 Jun 26 13:20 package-lock.json\\
\\
\\
Change permissions for \\
\\
\$ sudo chown -R www-data  gutenberg/\\
\$ sudo chown -R www-data  mygutenblock/\\
\$ sudo chown -R www-data  package-lock.json\\
\\
\$ ls -al\\
total 28\\
drwxrwsr-x 5 www-data www-data 4096 Jun 26 17:30 .\\
drwxrwsr-x 7 www-data www-data 4096 Jun 26 11:29 ..\\
drwxr-xr-x   4 www-data www-data 4096 Jun 26 11:37 akismet\\
drwxr-sr-x   7 www-data}{\large  www-data 4096 Jun 21 17:04 gutenberg\\
-rw-rw-r--    1 www-data www-data   28 Jun  5  2014 index.php\\
drwxr-sr-x   3 www-data}{\large  www-data 4096 Jun 26 17:31 mygutenblock\\
-rw-r--r-- 	   1 www-data}{\large  www-data   27 Jun 26 13:20 package-lock.json\\
\\
--------------------------------------------------------------------\\
\\
\$ cd \~/\\
\\
\$ ls -al | grep .npm\\
drwxrwxr-x 105 tomdom tomdom    4096 Jun 17 22:41 .npm\\
\\
\$ sudo chown -R www-data .npm\\
\\
\$ cd /var/www/html/wp-content/plugins}{\large \\
\\
\$ sudo npx create-guten-block myblock\\
\\
\\
\\
\textbf{NPM - How to Prevent Permissions Errors}}{\large \\
[https://docs.npmjs.com/getting-started/fixing-npm-permissions}{\large ]\\
\\
Reinstall npm with a version manager (recommended)\\
\\
\\
When installing Node Modules globally with npm, you will encounter EACCESS npm errors\\
\\
global node modules are stored in\\
/usr/lib/node\_modules/npm/node\_modules}{\large \\
\\
npx is a tool for running npm packages that \\
live inside of a local node\_modules folder \\
or \\
are not installed globally.\\
\\
npx looks into the local /node\_modules folder for the package \\
If it can’t find it, it will download and run it without having that package globally installed.\\
\\
npx will download and execute any package you give\\
\\
\$ npx create-guten-block my-block\\
\\
IF THIS DOSNT WORK - PERMISSION\\
\\
\$ sudo npx create-guten-block\\
}{\large \$ sudo create-guten-block myblock}{\large \\
\\
\\
Using npx, the Node Package Executor\\
This executes command from local node\_modules/.bin\\
or a central cache\\
\\
DON'T install create-guten-block globally\\
\$ sudo npm uninstall -g create-guten-block\\
\\
In the plugins folder\\
\$ cd /var/www/html/wp-content/plugins}{\large \\
\\
\$ npx -p @angular/cli ng new my-app\\
\$ npx ng serve\\
\\
\\
[https://medium.com/@thierry\_45533/global-node-modules-without-sudo-aacc3781e900}{\large ]\\
\\
\textbf{Install Create-guten-block}}{\large \\
Whilst \textit{still in the plugins directory}}{\large \\
\\
check npm up-to-date (globally)\\
\$ npm update -g\\
\\
Install Create-guten-block (can also do an npx for local)\\
\\
\$ sudo npm uninstall -g create-guten-block\\
\\
\$ sudo npm install -g create-guten-block --unsafe-perm=true --allow-root\\
\\
\$ create-guten-block --version\\
\\
now create a guten-block to check\\
in plugins/ \\
\$ sudo create-guten-block test-blk-1\\
\\
\\
Note: to see 'real' users\\
\$ cat /etc/passwd}{\large  | grep '/home' | cut -d: -f1\\
\\
\\
Need 'sudo' because we've created a separate user for the document root var/www/html/ directory I believe\\
\\
\\
==================================================\\
\\
Solving the web file permissions problem once and for all\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
==================================================\\
\\
\textbf{Add a Linux User With Document Root Permissions}}{\large \\
\\
setting up a Linux user with read and write permissions for your web document root}{\large \\
Connecting with this user via SFTP will let you upload your website content directly to the /var/www/site}{\large \\
\\
\\
1) Need to know the group the Apache web server process is running under\\
2) Location of web servers document root\\
\\
apache2.conf in /etc/apache2}{\large  \\
--------\\
<Directory /usr/share>}{\large \\
        AllowOverride None\\
        Require all granted\\
</Directory>\\
\\
<Directory/var/www/html/>}{\large {\large \\
        Options Indexes FollowSymLinks\\
        AllowOverride All\\
        Require all granted\\
</Directory>\\
--------------------\\
\\
\\
\$ sudo useradd -d /var/www/html}{\large  -G www-data admin}{\large \\
and\\
\$ sudo passwd admin}{\large \\
---> password\\
\\
if you want to modify an existing user then add it to the group used by your web server\\
\$ sudo usermod -a -G www-data admin}{\large \\
\\
to change the account to use the document root as its home directory\\
\$ sudo usermod -d /var/www/html}{\large admin}{\large \textbf{Change the document root permissions}}{\large \\
change the document root so it and its contents are in the same group as the web server\\
\$ sudo chgrp -R www-data /var/www/html}{\large \textbf{Set the permissions}}{\large \\
make the document root group-writable, \\
also set the ``setgid'' permission on the document root directory}{\large . \\
This ensures that new files created in the document root will inherit the group ID from their parent directory.\\
\\
\$ sudo chmod -R g+w /var/www/html}{\large \\
\\
\$ sudo chmod g+s /var/www/html}{\large \\
\\
\\
==================================================\\
\\
\textbf{What is the best way to set up users and groups for web folders?}}{\large \\
--> web folder is /var/www/domain}{\large \\
--> Apache default user is www-data\\
---> user name is 'tomdom'\\
\\
add user to www-data group                                   \$sudo usermod -aG www-data \$USER}{\large \\
\\
add a symlink for www to users home folder          \$ln -s /var/www}{\large   \~/}{\large \\
\\
To create new files                                                    \$ sudo chown -R www-data:www-data /var/www}{\large {\large \\
\\
\\
To set www-data as the default group for tomdom  \$ sudo usermod tomdom -g www-data}{\large \\
\\
then set 'tomdom' as the owner of /var/www}{\large  and www-data as the group\\
\\
sudo chown -R tomdom:www-data /var/www}{\large \\
\\
\\
\\
================================================================\\
================================================================\\
Create a user account and password for the 'www-data' web directory group\\
\\
Must be in user --> 'admin'\\
\\
admin@tomdom-iMac:\~\$ whoami\\
admin\\
\\
\\
update npm [not sure which way is correct]\\
-------------------------------------------------------------\\
admin@tomdom-iMac:\~\$ npm --version\\
\\
admin@tomdom-iMac:\~\$ npm update npm\\
\\
admin@tomdom-iMac:\~\$ npm update -g npm\\
\\
admin@tomdom-iMac:\~\$ sudo npm install npm@latest -g\\
\\
\\
once npm updated can create a guten block\\
-------------------------------------------------------------------------------\\
admin@tomdom-iMac:\~\$ npx create-guten-block block-2\\
\\
admin@tomdom-iMac:\~\$ cd block-2\\
\\
admin@tomdom-iMac:\~\$ npm start\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
}23025
\hypertarget{lamp_stack_+_wp__2}{\section {LAMP stack + WP  2}}
{\large on Ubuntu 16.04\\
\\
https://www.digitalocean.com/community/tutorials/how-to-install-wordpress-with-lamp-on-ubuntu-16-04}{\large https://www.digitalocean.com/community/tutorials/how-to-install-linux-apache-mysql-php-lamp-stack-on-ubuntu-16-04}{\large }\textbf{{\Large \\
How To Install Linux, Apache, MySQL, PHP (LAMP) stack on Ubuntu 16.04 }}{\large \\
\\
\\
Linux\\
Apache\\
MySQL\\
PHP\\
\\
\textbf{1) Create a non-root user account with sudo privileges set up on your serve}}{\large r\\
This is typically done as default in initial set-up for desktop use.\\
\\
\\
\textbf{2)Install Apache Web server}}{\large \\
\\
Check if already installed\\
\$ apt list apache*\\
\\
and/or\\
\\
\$ apache2 --v\\
\\
and if not installed or unsure\\
\\
\$ sudo apt update \&\& sudo apt install apache2\\
\\
\textbf{3) Set Global ServerName}}{\large \\
\\
Amend the apache2 configuration file 'apache2.conf'\\
\\
Hence before amending if we do\\
\\
\$ sudo apache2ctl configtest \\
---->\\
AH00558: apache2: Could not reliably determine the server's fully qualified domain name, using 127.0.1.1. Set the 'ServerName' directive globally to suppress this message}{\large \\
Syntax OK\\
\\
Thus to edit the config file\\
\\
\$ kwrite sudoedit /etc/apache2/apache2.conf}{\large \\
\\
OR\\
\\
\$ sudo nano /etc/apache2/apache2.conf}{\large \\
\\
Inside, at the bottom of the file, add a ServerName directive, pointing to your primary domain name. \\
\\
--------------------------------------------------------\\
.\\
.\\
.\\
ServerName 127.0.0.1\\
--------------------------------------------------------\\
\\
where 127.0.0.1 is localhost  hence:\\
\\
\$ sudo apache2ctl configtest\\
Syntax OK\\
\\
\\
restart the apache2 server\\
\\
\$ sudo systemctl restart apache2\\
\\
\\
Check if apache is listed on the uncomplicated firewall\\
\\
\$ sudo ufw app list\\
---->\\
Available applications:\\
  Apache\\
  Apache Full\\
  Apache Secure\\
  CUPS\\
\\
so we see it is\\
\\
Checking the list in detail\\
\\
\$ sudo ufw app info ''Apache Full'' \\
---->\\
Profile: Apache Full\\
Title: Web Server (HTTP,HTTPS)\\
Description: Apache v2 is the next generation of the omnipresent Apache web\\
server.\\
\\
Ports:\\
  80,443/tcp\\
\\
\\
Now checkout\\
127.0.0.1\\
\\
Should get the ''Apache2 Ubuntu Default Page''\\
\\
\\
\textbf{Install MySQL / Mariadb}}{\large \\
\\
Check if this has been installed already\\
\\
\$ sudo apt list --installed | grep  mysql*\\
\\
If mySQL , or MariaDb is not installed\\
\\
\$ sudo apt-get install mariadb-server mariadb-client\\
OR\\
\$ sudo mysql\_secure\_installation\\
\\
[https://www.itzgeek.com/how-tos/linux/ubuntu-how-tos/install-mariadb-on-ubuntu-16-04.html}{\large ]\\
\\
\textbf{Install PHP}}{\large \\
\\
Check if PHP has been installed already\\
\\
\$ sudo apt list --installed | grep  PHP*\\
\\
Also\\
\\
\$sudo apt list --installed | grep  libapache2-mod-php*\\
\\
\$ sudo apt list --installed | grep php-mcrypt\\
\\
\\
If not, to install PHP\\
\$ sudo apt-get install php libapache2-mod-php php-mcrypt php-mysql\\
\\
Note the 'libapache2-mod-php''  ''php-mcrypt''   ''php-mysql''  helper packages\\
\\
Need to tell Apache to prefer PHP files, so getApache to look for an index.php file first.\\
\\
Open the dir.conf file in a text editor\\
\\
\$ kwrite sudoedit /etc/apache2/mods-enabled/dir.conf}{\large \\
OR\\
\$ sudo nano /etc/apache2/mods-enabled/dir.conf}{\large \\
\\
It will look like\\
-----------------------------------------------------------------------------------------\\
<IfModule mod\_dir.c>\\
    DirectoryIndex index.html index.cgi index.pl index.php index.xhtml index.htm\\
</IfModule>\\
-----------------------------------------------------------------------------------------\\
\\
put index.php to the front i.e. need to make the file look like this\\
------------------------------------------------------------------------------------------\\
<IfModule mod\_dir.c>\\
    DirectoryIndex index.php index.html index.cgi index.pl index.xhtml index.htm\\
</IfModule>\\
------------------------------------------------------------------------------------------\\
\\
Save and restart the Apache server\\
\\
\$ sudo systemctl restart apache2\\
\\
and to look at the status of the Apache server\\
\\
\$ sudo systemctl status apache2\\
--->\\
}● apache2.service - The Apache HTTP Server\\
   Loaded: loaded (/lib/systemd/system/apache2.service; enabled; vendor preset: enabled)\\
  Drop-In: /lib/systemd/system/apache2.service.d\\
           └─apache2-systemd.conf\\
   Active: active (running) since Mon 2018-06-25 16:07:21 BST; 10s ago\\
  Process: 20310 ExecStop=/usr/sbin/apachectl stop (code=exited, status=0/SUCCESS)\\
  Process: 3618 ExecReload=/usr/sbin/apachectl graceful (code=exited, status=0/SUCCESS)\\
  Process: 20315 ExecStart=/usr/sbin/apachectl start (code=exited, status=0/SUCCESS)\\
 Main PID: 20327 (apache2)\\
    Tasks: 6 (limit: 4915)\\
   Memory: 31.7M\\
      CPU: 63ms\\
   CGroup: /system.slice/apache2.service\\
           ├─20327 /usr/sbin/apache2 -k start\\
           ├─20332 /usr/sbin/apache2 -k start\\
           ├─20333 /usr/sbin/apache2 -k start\\
           ├─20335 /usr/sbin/apache2 -k start\\
           ├─20336 /usr/sbin/apache2 -k start\\
           └─20339 /usr/sbin/apache2 -k start\\
\\
Jun 25 16:07:21 tomdom-iMac systemd[1]: Starting The Apache HTTP Server...\\
Jun 25 16:07:21 tomdom-iMac systemd[1]: Started The Apache HTTP Server.{\large \textbf{Install PHP modules}}{\large \\
\\
(Optional PHP modules to install)\\
\\
To see them\\
\\
\$ apt-cache search php- | less\\
\\
\$ apt-cache show \textit{package1 package2 package3 ....}}{\large \textbf{Test PHP on web server}}{\large \\
\\
Need to create a PHP test script 'info.php'\\
\\
Save this to the 'web root' directory which in Ubuntu 16.04 is /var/www/html/}{\large \\
\\
Hence\\
\\
\$ cd /var/www/html}{\large  \\
\\
\$ sudo touch info.php\\
\\
\$ kwrite sudoedit info.php\\
\\
info.php\\
---------------------------------\\
<?php \\
phpinfo();\\
?>\\
---------------------------------\\
\\
NOTE:\\
Tried \$ sudo cat > info.php   method but didn't get the superuser right\\
\\
\\
Now checkout URL  127.0.0.1/info.php  \\
\\
And should see the purple 'PHP Version' default page\\
\\
This means its worksing ok. Now delete the info.php file\\
\\
\$ sudo rm /var/www/html/info.php}{\large }\textbf{{\Large LAMP STACK INSTALLED !}}{\large \\
=========================================================\\
=========================================================\\
\\
\textbf{Install Wordpress, add phpMyAdmin etc}}{\large \\
\\
For WordPress\\
\\
Create a sudo user on your server\\
\\
Install a LAMP stack\\
\\
Secure your site with SSL}{\large \\
	1) Have a domain name... try Let's Encrypt\\
	2) For testing or personal use, use a self-signed certificate\\
\\
[https://www.digitalocean.com/community/tutorials/how-to-create-a-self-signed-ssl-certificate-for-apache-in-ubuntu-16-04}{\large ]\\
transport layer security (TLS),or  secure sockets layer (SSL)\\
web protocols used to wrap normal traffic in a protected, encrypted wrapper.\\
\\
1) Create the SSL Certificate\\
\\
\$ sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/ssl/private/apache-selfsigned.key}{\large  -out /etc/ssl/certs/apache-selfsigned.crt}{\large \\
\\
\\
Fill out the prompts\\
The Common Name (e.g. server FQDN or YOUR name). \\
You need to enter the domain name associated with your server or, more likely, your server's public IP address.\\
\\
Files created in the subdirectories of /etc/ssl}{\large  directory.\\
\\
\$ cd /etc/ssl}{\large \\
certs  openssl.cnf  private\\
\\
\$ sudo openssl dhparam -out /etc/ssl/certs/dhparam.pem}{\large  2048\\
This generates DH parameters; takes a few minutes\\
\\
2) Configure Apache to Use SSL\\
\\
Create a configuration snippet to specify strong default SSL settings\\
\\
\$ sudo nano /etc/apache2/conf-available/ssl-params.conf}{\large \\
\\
[https://cipherli.st/}{\large ]\\
\\
To set up Apache SSL securely, we will be using the recommendations by Remy van Elst on the Cipherli.st site. \\
This site is designed to provide easy-to-consume encryption settings for popular software.\\
\\
------------------------------------------------\\
\# from https://cipherli.st/}{\large \\
\# and https://raymii.org/s/tutorials/Strong\_SSL\_Security\_On\_Apache2.html}{\large \\
\\
SSLCipherSuite EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH\\
SSLProtocol All -SSLv2 -SSLv3\\
SSLHonorCipherOrder On\\
\# Disable preloading HSTS for now.  You can use the commented out header line that includes\\
\# the ''preload'' directive if you understand the implications.\\
\#Header always set Strict-Transport-Security ''max-age=63072000; includeSubdomains; preload''\\
Header always set Strict-Transport-Security ''max-age=63072000; includeSubdomains''\\
Header always set X-Frame-Options DENY\\
Header always set X-Content-Type-Options nosniff\\
\# Requires Apache >= 2.4\\
SSLCompression off \\
SSLSessionTickets Off\\
SSLUseStapling on \\
SSLStaplingCache ''shmcb:logs/stapling-cache(150000)''\\
\\
SSLOpenSSLConfCmd DHParameters ''/etc/ssl/certs/dhparam.pem''\\
------------------------------------------------\\
\\
save and exit\\
\\
\\
\textbf{Modify the Default Apache SSL Virtual Host File}}{\large \\
\\
Virtual Host file to point to our generated SSL certificates.\\
Also automatically redirect requests to the encrypted Virtual Host.\\
\\
Backup original SSL Vitual Host file\\
\\
\$ sudo cp /etc/apache2/sites-available/default-ssl.conf}{\large /etc/apache2/sites-available/default-ssl.conf.bak}{\large \\
\\
open the SSL Virtual Host file to make adjustments\\
\\
\$ sudo nano /etc/apache2/sites-available/default-ssl.conf}{\large \\
\\
Set ServerAdmin email address, ServerName, etc.\\
adjust the SSL directives to point to our certificate and key files\\
uncomment the section that provides compatibility for older browsers.\\
\\
After making these changes, your server block should look similar to this:\\
\\
-----------------------------------\\
<IfModule mod\_ssl.c>\\
        <VirtualHost \_default\_:443>\\
                ServerAdmin your\_email@example.com}{\large \\
                ServerName server\_domain\_or\_IP\\
\\
                DocumentRoot /var/www/html}{\large \\
\\
                ErrorLog \$\{APACHE\_LOG\_DIR\}/error.log\\
                CustomLog \$\{APACHE\_LOG\_DIR\}/access.log combined\\
\\
                SSLEngine on\\
\\
                SSLCertificateFile      /etc/ssl/certs/apache-selfsigned.crt}{\large \\
                SSLCertificateKeyFile /etc/ssl/private/apache-selfsigned.key}{\large \\
\\
                <FilesMatch ''\\.(cgi|shtml|phtml|php)\$''>\\
                                SSLOptions +StdEnvVars\\
                </FilesMatch>\\
                <Directory /usr/lib/cgi-bin>}{\large \\
                                SSLOptions +StdEnvVars\\
                </Directory>\\
\\
                BrowserMatch ''MSIE [2-6]'' \\\\
                               nokeepalive ssl-unclean-shutdown \\\\
                               downgrade-1.0 force-response-1.0\\
\\
        </VirtualHost>\\
</IfModule>\\
\\
-----------------------------------\\
save and exit\\
\\
\\
\textbf{Modify the Unencrypted Virtual Host File to Redirect to HTTPS}}{\large \\
\\
For better security, it is recommended in most cases to redirect HTTP to HTTPS automatically. If you do not want or need this functionality, you can safely skip this section.\\
\\
[I'll skip]\\
\\
\textbf{Adjust the Firewall}}{\large \\
\\
\$ sudo ufw app list\\
\\
Should see\\
------------------\\
Available applications:\\
  Apache\\
  Apache Full\\
  Apache Secure\\
  OpenSSH\\
------------------\\
\\
To allow OpenSSH}{\large \\
\\
\$ sudo ufw allow 'OpenSSH'\\
\\
\\
To allow for HTTPS [which we've not setup here]\\
\\
\$ sudo ufw allow  'Apache Full'\\
\$ sudo ufw delete allow 'Apache'\\
\\
\\
\\
\$ sudo ufw status\\
\\
\\
\textbf{Enable the Changes in Apache}}{\large \\
\\
Enable mod\_ssl, the Apache SSL module, and mod\_headers, needed by some of the settings in our SSL snippet, with the a2enmod command:\\
\\
\$ sudo a2enmod ssl\\
\$ sudo a2enmod headers\\
\\
\$ sudo a2ensite default-ssl\\
\\
\$ sudo a2enconf ssl-params\\
\\
\$ sudo apache2ctl configtest\\
\\
\$ systemctl restart apache2\\
\\
\$ systemctl reload apache2\\
\\
\textbf{Test Encryption}}{\large https://127.0.0.1}{\large \\
\\
Should get a 'scary warning' --> that's actually ok\\
\\
\\
\\
\\
\\
Change to a Permanent Redirect\\
....\\
\\
\\
skipped...\\
\\
\\
-------------\\
\\
}\textbf{{\Large INSTALL WORDPRESS !!}}{\large \textbf{Create a MySQL Database and User for WordPress}}{\large \\
\\
\\
log into the MySQL root\\
\\
\$ mysql -u root -p\\
Note: default password is sometimes 'password', 'root' 'admin' or blank [return key]\\
\\
Checkout the current databases available\\
mysql>show databases;\\
+--------------------+\\
| Database           |\\
+--------------------+\\
| information\_schema |\\
| mysql              |\\
| performance\_schema |\\
| sys                |\\
| wordpress          |\\
| wp\_headless        |\\
+--------------------+\\
6 rows in set (0.18 sec)\\
\\
Here we already have a wordpress db.\\
\\
mysql> CREATE DATABASE wordpress2}{\large  DEFAULT CHARACTER SET utf8 COLLATE utf8\_unicode\_ci;\\
\\
Now create a mysql user account called 'wordpressuser' for this wordpress2 database. This approach is typical\\
\\
mysql> GRANT ALL ON wordpress2.* TO 'wordpressuser}{\large '@'localhost' IDENTIFIED BY 'password}{\large ';\\
Query OK, 0 rows affected, 1 warning \\
\\
So mysql knows of recent changes\\
\\
mysql> FLUSH PRIVILEGES;\\
\\
mysql> exit;\\
\\
\\
\textbf{Install Additional PHP Extensions}}{\large \\
\\
\\
Only need a very minimal set of extensions to link PHP to MySQL. \\
WordPress / plugins leverage additional PHP extensions.\\
\\
\$ sudo apt-get update\\
\\
\$ sudo apt-get install php-curl php-gd php-mbstring php-mcrypt php-xml php-xmlrpc\\
\\
\$ sudo systemctl restart apache2\\
\\
\\
\textbf{Adjust Apache's Configuration to Allow for .htaccess Overrides and Rewrites}}{\large \\
\\
The use of .htaccess files is disabled. \\
WordPress and many WordPress plugins use these files extensively for in-directory tweaks to the web server's behaviour.\\
\\
\\
Enable .htaccess Overrides\\
\\
\$ sudo nano /etc/apache2/apache2.conf}{\large \\
\\
------\\
<Directory /var/www/html/>}{\large \\
    AllowOverride All\\
</Directory>\\
------\\
\\
What I did\\
======\\
<Directory /var/www/html/>}{\large \\
        Options Indexes FollowSymLinks\\
        AllowOverride All \\
        Require all granted\\
</Directory>\\
======\\
\\
save and exit\\
\\
Enable the Rewrite Module\\
\\
\$ sudo a2enmod rewrite\\
\\
Enable the Changes\\
\\
\$ sudo apache2ctl configtest\\
\\
\\
\$ sudo systemctl restart apache2\\
\\
\\
\textbf{Download WordPress}}{\large \\
\\
Change into a writable directory \\
\\
\$ cd myWordpressFolder\\
\\
then download the compressed release by typing:\\
\\
\$ curl -O https://wordpress.org/latest.tar.gz}{\large \\
\\
\$ tar xzvf latest.tar.gz\\
\\
we can add a dummy .htaccess file and set its permissions use later\\
\\
\$ cd wordpress\\
\\
\$ touch .htaccess\\
\\
\$ chmod 660 .htaccess\\
\\
Create a wp-config by copying the sample default\\
\$ cp wp-config-sample.php wp-config.php\\
\\
To fix permissions issues on update to Wordpress, create the upgrade directory\\
\\
\$ pwd\\
wordpress\\
\\
\$ mkdir wp-content/upgrade\\
\\
\\
\textbf{copy everything [ ' . ' ] including hidden files [eg ' .htaccess '] \\
from the WP directory into web document root}}{\large /var/www/html}{\large \\
\\
' -a ' option to maintain permissions.\\
\\
\$ cd ..\\
\\
\$ pwd\\
wp-test   [the project directory]\\
\\
\\
\$ sudo cp -a wordpress/. /var/www/html}{\large \textbf{Configure the WordPress Directory}}{\large \textbf{Adjusting the Ownership and Permissions}}{\large {\large \\
\\
Write files normal user\\
also web server to also be able to access and adjust certain files and directories in order to function correctly.\\
\\
assigning ownership over all of the files in our 'web document root' to our username 'tomdom'\\
\\
\$ sudo chown -R tomdom:www-data /var/www/html}{\large {\large \\
\\
\\
Next, we will set the setgid bit on each of the directories within the document root. This causes new files created within these directories to inherit the group of the parent directory (which we just set to www-data) instead of the creating user's primary group. This just makes sure that whenever we create a file in the directory on the command line, the web server will still have group ownership over it.\\
\\
\$ sudo find /var/www/html}{\large  -type d -exec chmod g+s \{\} \\;\\
\\
give group write access to the wp-content directory so that the web interface can make theme and plugin changes:\\
\\
\$ sudo chmod g+w /var/www/html/wp-content}{\large \\
\\
give the web server write access to all of the content in these two directories:\\
\\
\$ sudo chmod -R g+w /var/www/html/wp-content/themes}{\large \\
\\
\$ sudo chmod -R g+w /var/www/html/wp-content/plugins}{\large \textbf{Setting up the WordPress Configuration File}}{\large \\
\\
 WordPress provides a secure generator for these values so that you do not have to try to come up with good values on your own. These are only used internally, so it won't hurt usability to have complex, secure values here.\\
\\
To grab secure values from the WordPress secret key generator, type:\\
\\
\$ curl -s https://api.wordpress.org/secret-key/1.1/salt/}{\large \\
\\
\\
Copy this 'SALT' info on terminal\\
\\
\$ nano /var/www/html/wp-config.php}{\large \\
\\
replace the dummy values with the 'SALT' stuff copied\\
\\
ie. this\\
\\
---------------------------\\
define('AUTH\_KEY',         'put your unique phrase here');\\
define('SECURE\_AUTH\_KEY',  'put your unique phrase here');\\
define('LOGGED\_IN\_KEY',    'put your unique phrase here');\\
define('NONCE\_KEY',        'put your unique phrase here');\\
define('AUTH\_SALT',        'put your unique phrase here');\\
define('SECURE\_AUTH\_SALT', 'put your unique phrase here');\\
define('LOGGED\_IN\_SALT',   'put your unique phrase here');\\
define('NONCE\_SALT',       'put your unique phrase here');\\
---------------------------\\
\\
\\
is replaced by\\
---------------------------\\
define('AUTH\_KEY',         'S*>Gt3umWp|Pl1(G\{+\{?\~Ff|X3D\~vt\}\^B,O-fY9i69Np/GS!WJ\#QW+4PzLc qx(!');\\
define('SECURE\_AUTH\_KEY',  'z9sC3<y*v\~:\#3=j);1X8z`h|\%C+1|r`6lAHo?ok/5J\_ePq>/qahncsDyy0Hb|4PV');\\
define('LOGGED\_IN\_KEY',    'qfhq6Pl2pePm\_Jh.E:O\}Sb\$G=:,T1Xbk\&l XV3vr0xnW1;svkqH.f: 5b@bH`Oz7');\\
define('NONCE\_KEY',        ' |/> R;zalGf6t\}q(\{l:6ll\{?S!pZ+Smq/Kuf\_m+\#b[Q-W,C BGryF!29N\^hsT\&X');\\
define('AUTH\_SALT',        '|U1VG;sLzPcwN?6D\%.BD(CZ\#M6\{|hz)Fr`L8-kd6,\^4pevb(FQczS2iX*gM*g\_t\$');\\
define('SECURE\_AUTH\_SALT', 'w\{u2?h\#+0RBs+JpBS\&V71Ayg\&]\$po7pjd7Qrw+(c)p>[qE\$:Tz5NX<t\_6d|>.p1q');\\
define('LOGGED\_IN\_SALT',   '-T:\$96:9,6QW\&8aJ69eV;B\#-LGVkG1MiT*x\~)/Hzc@U*vg\$1S3x(`gKpT09kw5u\{');\\
define('NONCE\_SALT',       '2mV./IRd (-wkarn4\&aW1\%bSM+NT.zm>,|mby\{PZ<*@T9\~[i<Xgbw4j3 \~\^G\{z\^Z');\\
---------------------------\\
\\
Go to the top of file to adjust database name, user and password configured within MySQL hence:\\
\\
----------------------------\\
define('DB\_NAME', 'wordpress2');\\
\\
/** MySQL database username */\\
define('DB\_USER', 'wordpressuser');\\
\\
/** MySQL database password */\\
define('DB\_PASSWORD', 'password');\\
----------------------------\\
\\
\\
WordPress should use to write to the filesystem. \\
Explicitly set the filesystem method to ''direct'' by adding in wp-config.php\\
----------------------------------------\\
define('FS\_METHOD', 'direct');\\
-----------------------------------------\\
\\
save and exit wp-config.php\\
\\
\\
\textbf{Complete the Installation Through the Web Interface}}{\large \\
\\
\\
In your web browser, navigate to your server's domain name or public IP address:\\
\\
http://server\_domain\_or\_IP}{\large \\
\\
\\
In my case I chose localhost,  127.0.0.1\\
\\
\\
Select language  English (UK)\\
\\
Fill in the ' 5 minute WordPress installation' eg \\
You can change settings later\\
\\
Site Title:  toms-dev-wp-guten-react-site\\
\\
username: tomdom\\
\\
password: password\\
confirm weak password\\
\\
email: tom@appijumbo.com}{\large \\
\\
confirm discourage robots\\
\\
------------------------\\
Success ! ---->  prompt given\\
------------------------\\
\\
\textbf{Upgrading WordPress}}{\large You can't install updates through the interface with the current permissions}{\large \\
\\
This is to get a balance between security and usability.\\
\\
To give the web server access to the whole document root and allow updates\\
\\
\$ sudo chown -R www-data /var/www/html}{\large \\
\\
And to turn this off post updates to WordPress ['tomdom' is username]\\
\\
\$ sudo chown -R tomdom /var/www/html}{\large \\
\\
BUT IF YOUR JUST DOING A LOCALHOST TEST SITE \\
DON'T NEED THIS !!\\
\\
\\
\\
\\
\\
=======================================\\
\\
\textbf{ADD GUTENBURG}}{\large \\
\\
\$ cd /var/www/html/wp-content/plugins}{\large \\
\$ sudo wget https://downloads.wordpress.org/plugin/gutenberg.3.1.0.zip}{\large \\
\$ sudo unzip gutenberg.3.1.0.zip\\
\$ sudo rm gutenberg.3.1.0.zip\\
\\
\\
\\
=====================================================================}\textbf{{\Large \\
Setting up a Create-guten-block avoiding npm EACCES errors }}{\large \\
\\
The problem I had with setting up the create-guten-block npm app is that it produced EACCES errors.\\
\\
The problem is that I had the web server in var/www/html but the user I had difficulties getting permissions correct.\\
\\
Tried the following; this looks unsafe and just didn't work\\
\\
\$ sudo npx create-guten-block --unsafe-perm=true --allow-root myblock\\
\$ sudo npx create-guten-block myblock --unsafe-perm=true --allow-root\\
\\
\\
We have two users 'tomdom' and 'www-data'\\
\\
switching to 'www-data' user\\
\$ sudo su www-data\\
\\
\\
\\
If we check the groups for www-data, tomdom\\
\\
\$ groups tomdom www-data\\
tomdom : tomdom adm cdrom sudo dip plugdev lpadmin sambashare \hyperlink{docker}{docker}}{\large \\
www-data : www-data\\
\\
So tomdom is NOT a member of the www-data 'web root' group\\
'www-data' user is a member of the 'www-data' group\\
\\
Checking the status of the passwords for these users\\
\$ sudo passwd --status tomdom\\
tomdom P 03/07/2018 0 99999 7 -1\\
\\
\$ sudo passwd --status www-data\\
www-data L 01/05/2018 0 99999 7 -1\\
\\
Fields 1 to 7 mean:\\
1) User's login name\\
2) If user has a locked password (L), no password (NP), usable password (P)\\
3 to 7) Date of the last password change, min age ,max age, warning period, inactivity period\\
\\
We see that the \textbf{www-data user}}{\large  p\textbf{assword is locked down}}{\large  for security reasons.\\
\\
\\
We could unlock it OR create a new user that has a password enabled and is assigned permissions to the 'www-data' group\\
\\
\textbf{Add a Linux User With Document Root Permissions}}{\large \\
checking that\\
apache2.conf in /etc/apache2}{\large  \\
--------\\
<Directory /usr/share>}{\large \\
        AllowOverride None\\
        Require all granted\\
</Directory>\\
\\
<Directory /var/www/html/>}{\large \\
        Options Indexes FollowSymLinks\\
        AllowOverride All\\
        Require all granted\\
</Directory>\\
--------------------\\
\\
\textbf{Lets create/add a new 'admin' user}}{\large  \\
called 'admin' and assign it permissions to the 'www-data' web server group\\
\$ sudo useradd -d /var/www/html}{\large  -G www-data admin     \textit{[use usermod for an existing user]}}{\large \\
\$ sudo passwd admin\\
---> password    [gave the password as 'password']\\
\\
and to change the account to use the document root as its home directory\\
\$ sudo usermod -d /var/www/html}{\large  admin\\
\\
Checking the status of the passwords for admin\\
\$ sudo passwd --status admin\\
admin P 06/29/2018 0 99999 7 -1\\
\\
Change the owner of everything in [ie recursivley] /var/www/html}{\large  ie the 'web document root' to the group 'www-data'\\
Hence all users [www-data and admin] in the www-data group will own the web server\\
\$ sudo chgrp -R www-data /var/www/html}{\large \\
\\
make the 'web document root' is writable by the www-data group. Also set the ``setgid'' permission so new files created in 'var/www/html' will inherit the www-data group ID from their parent directory.\\
\$ sudo chmod -R g+w /var/www/html}{\large \\
\$ sudo chmod g+s /var/www/html}{\large \\
\\
Setgid bit is set so any files created in /var/www/html}{\large  will inherit 'www-data' group id\\
OR could have done [safer]\\
\$ chmod -R 2775 /var/www/html}{\large \\
\\
OR - which is the same as doing\\
\$ sudo chmod -R a+rwx,o-w,ug+s,+t,u-s,-t  /var/www/html}{\large \\
\\
\\
Checking  'admin' and 'www-data' users are members of the 'www-data' group\\
\$ groups admin www-data\\
admin : admin www-data\\
www-data : www-data\\
\\
[(d)   user   group   other]\\
\$ ls -al /var/www/html}{\large \\
drwxrwsr-x  7   www-data    www-data    4096 Jun 29 17:36 html\\
\\
So 'html' web root project directory is 'user', and 'group' is www-data. \\
The 'www-data' group has read, write and execute permissions, \\
\\
\\
\\
and the 'plugin' and 'gutenburg' directories have user and group permissions of 'www-data'\\
\$ ls -al /var/www/html/wp-content/plugins}{\large \\
drwxrwsr-x 5    www-data    www-data  .\\
drwxrwxr-x 7    www-data    www-data   gutenberg\\
\\
\\
\\
Lets create a symbolic soft link inside our 'wordpress' project folder that points to the 'web root' directory\\
\$ ln -s /var/www/html}{\large  '/home/tomdom/Temp stuff/WP\_Using hosts MySQL db/wp\_test/wordpress'\\
\\
\\
Switch to the 'admin' user\\
\$ su admin\\
\\
now as 'admin' is a member of www-data group we can create a guten-block with npm\\
lets call it 'block-2'\\
\\
\$ sudo npx create-guten-block\\
\$ sudo npx create-guten-block block-2\\
\\
\\
And if we check the newly created guten-block 'block-2' we see \\
its user and group permissions are 'admin' and 'ww-data' as required\\
\\
\$ ls -al /var/www/html/wp-content/plugins}{\large \\
drwxrwsr-x 5    admin       www-data    4096 Jun 29 18:01 block-2\\
\\
\\
\\
\\
\\
}19507
\hypertarget{linux_bash_-_quidsup_+_others_ideas}{\section {Linux Bash - Quidsup + others ideas}}
\textbf{CONSTANTS    readonly}\\
      -a        refer to indexed array \hyperlink{variables}{variables}\\
      -A        refer to associative array \hyperlink{variables}{variables}\\
      -f        refer to shell functions\\
      -p        display a list of all readonly \hyperlink{variables}{variables} or functions,\\
                depending on whether or not the -f option is given\\
\\
\textbf{\\
VARIABLE     declare}\\
   \\
      -a        to make NAMEs indexed arrays\\
      -A        to make NAMEs associative arrays \\
\\
example \\
\\
	declare -a foo\_array\\
\\
	declare -A foo\_bar\\
	foo\_bar[''cloudfront.net'']=true\\
	foo\_bar[''googleusercontent.com'']=true\\
	foo\_bar[''googlevideo.com'']=true\\
\\
\\
      -i        to make NAMEs have the `integer' attribute\\
      -l        to convert NAMEs to lower case on assignment\\
      -n        make NAME a reference to the variable named by its value\\
      -r        to make NAMEs readonly\\
      -t        to make NAMEs have the `trace' attribute\\
      -u        to convert NAMEs to upper case on assignment\\
      -x        to make NAMEs export\\
    \\
\textbf{LOCAL VARIABLE}\textbf{  local}\\
Only can do inside a function: restricts scope to that function and its children.\\
Identical to declare; takes almost all the same options\\
\\
Example\\
\\
function check\_logage() \{\\
  local log\_time=''''\\
  local foo\_bar=0\\
  .\\
  .\\
  log\_time=\$(mysql -sN --user=......\\
\\
\textbf{Set a 'Main' with options using 'getopt'}\\
\\
Example\\
\\
\#--------------------------------------------------------------------\\
\#Main\\
if [ ''\$1'' ]; then                                \#Have any arguments been given\\
  if ! options=''\$(getopt -o achv -l age,copy,delete-access,delete-live,help,version -- ''\$@'')''; then\\
    \# something went wrong, getopt will put out an error message for us\\
    exit 6\\
  fi\\
\\
  set -- \$options\\
\\
  while [ \$\# -gt 0 ]\\
  do\\
    case \$1 in\\
      -a|--age)\\
        check\_logage\\
        show\_logage \$?\\
        exit 0\\
      ;;\\
      -c|--copy)\\
        copy\_table\\
        exit 0\\
      ;;\\
      --delete-lighty)\\
        delete\_lighty\\
        exit 0\\
      ;;\\
      --delete-live)\\
        delete\_live\\
        exit 0\\
      ;;\\
      -h|--help)\\
        show\_help\\
        exit 0\\
      ;;\\
      -v|--version) \\
        show\_version\\
        exit 0\\
      ;;\\
      (--) \\
        shift\\
        break\\
      ;;\\
      (-*)         \\
        echo ''\$0: error - unrecognized option \$1''\\
        exit 6\\
      ;;\\
      (*) \\
        break\\
      ;;\\
    esac\\
    shift\\
  done\\
fi\\
\\
\\
--------------------------------------------------------\\
\\
\textbf{Create an install script}\textbf{- Examples of what may contain}\\
\\
Set constants for \\
	directory pathways etc\\
	version no.\\
	\\
Set environmental variable's up eg\\
	IP\_ADDRESS=''''\\
\\
declare an Error function\\
\\
Main 'loop' menu() function used - \\
	\textit{while true; do}\\
\\
Put scripts into correct location\\
copy scripts from where they were installed, to a specific directory\\
\\
function to create file\\
\\
function to delete file\\
\\
download  git\\
\\
download with wget\\
\\
install downloaded packages\\
	determine which repo method ie if apt,apt-get,dnf,yum,pacman,apk,abps-intall\\
	then install required dependencies and packages\\
	setup those packages\\
\\
\\
Uninstall Script\\
	Auto delete as many files and folders as possible\\
	Inform user of files that need to be manually deleted\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
3003
\hypertarget{linux_command_line_shortcuts}{\section {Linux Command Line Shortcuts}}
https://linuxhandbook.com/linux-shortcuts/{\large \textbf{HISTORY}}{\large \\
Ctrl + p	Previous command = up key\\
\\
Ctrl + n	Next command = dwn key\\
\\
Ctrl + r    Repeat command; type the search term; Repeat Ctrl + r to loop through results\\
		Search the last remembered search term. Ctrl + r twice\\
\\
Ctrl + j	End the search at current history entry\\
\\
Ctrl + g  	Cancel the search and restore original line\\
\\
\\
\textbf{NAVIGATE}}{\large \\
CTRL + e 	Moves the cursor to the end of the line\\
\\
CTRL + a 	Moves the cursor to the beginning of the line\\
\\
ALT + b 		Skips back to the previous space\\
\\
ALT + f 		Skips forward to the previous space\\
\\
\\
\textbf{CUT N PASTE}}{\large  (‘Kill and yank’)\\
CTRL + w	Cuts the word behind the cursor. \\
\\
Ctrl + u		Erase everything from the current cursor position to the beginning of the line\\
\\
Ctrl + k		Erase everything from the current cursor position to the end of the line\\
\\
Ctrl + y		Paste the erased text that you saw with Ctrl + W, Ctrl + U and Ctrl + K shortcuts\\
\\
\\
ALT + y 		Loop through and paste previously cut text.  (use it after Ctrl + y)    \\
\\
ALT + .    	Loop through and paste the last argument of previous commands\\
\\
\\
\\
Shift + Insert	Pastes text into the terminal\\
\\
ALT + Bkspce 	Cut from cursor to the start of word\\
\\
ALT + d		Cut from cursor to the end of word\\
\\
\\
\\
\textbf{SHELL INTERACTION}}{\large \\
Ctrl + d 		Logs out \hyperlink{ssh___and_sshfs}{SSH   and SSHFS}}{\large  connection,closed a shell; the ‘exit’ command\\
\\
Ctrl + z		Send a running program in the background; use if forgot to use -option flag\\
\\
\\
\textbf{CLEAR}}{\large \\
Ctrl + L		clear the terminal\\
\\
CTRL + s		Suspend Output of shell  (CTRL + Q to resume)\\
\\
\textbf{SHORTEN PROMPT in bash shell}}{\large \\
\$ PS1='\\W\\\$ '\\
}\\
see https://bit.ly/2oPcYDq1639
\hypertarget{linux_permissions}{\section {Linux Permissions}}
https://www.ibm.com/developerworks/library/l-lpic1-104-5/index.htmlhttps://access.redhat.com/documentation/en-US/Red\_Hat\_Enterprise\_Linux/4/html/Step\_by\_Step\_Guide/s1-navigating-ownership.htmlhttps://www.linux.com/learn/understanding-linux-file-permissionshttp://fideloper.com/user-group-permissions-chmod-apache{\large \textbf{USERS}}{\large \\
2 types of users; \textbf{System}}{\large  users and \textbf{Regular}}{\large  users\\
The /etc/passwd}{\large  file contains all users on a system\\
\\
\\
\textbf{SUPERUSER}}{\large \\
This is also called the 'root' user - has 'god' rights\\
To assume 'superuser rights' we have 'superuser do' or 'sudo'\\
Normaly don't go login as 'root' but use 'sudo'\\
\\
\\
\textbf{GROUPS}}{\large \\
collection of 0 or more users\\
Users belong to a default and other groups\\
\\
The /etc/group}{\large  file shows all groups and members\\
\\
\\
\textbf{OWNERSHIP \& PERMISSION}}{\large S\\
Each file:\\
access permissions + owned by a single user and group\\
\\
Example\\
\\
tomdom@tomdom-iMac:\~\$ ls -l /etc\\
drwxr-xr-x  	3 	root			root   		4096 		Jan  	5	21:09 	acpi\\
MODE			OWNER		GROUP		FILE SIZE		LAST MODIFIED	FILENAME\\
\\
\\
admin@tomdom-iMac:\~/wp-content/plugins\$ ls -l\\
drwxrwxr-x	4 	www-data	www-data 	4096 		Jun 26 	11:37 	akismet\\
MODE			OWNER		GROUP		FILE SIZE		LAST MODIFIED	FILENAME\\
\\
drwxrwsr-x	5 	admin 		www-data 	4096 		Jun 29 	18:01 	block-2\\
MODE			OWNER		GROUP		FILE SIZE		LAST MODIFIED	FILENAME\\
\\
tomdom@tomdom-iMac:\~\$ ls -l\\
drwxr-xr-x  	2 	tomdom 		tomdom    	4096 		Mar 13 10:03 		Desktop\\
MODE			OWNER		GROUP		FILE SIZE		LAST MODIFIED	FILENAME\\
\\
\\
    			\textbf{MODE}}{\large \\
\\
    		 		User 	Group	Other\\
Examples\\
File type-->	d	rwx		rwx		rwx			\textbf{r}}{\large ead \textbf{w}}{\large rite e\textbf{x}}{\large ecute\\
			-	rw-		rw-		r--\\
			l	rwx		rwx		rwx\\
			d	rwx		---		---\\
			d	rwx		rws		r-x\\
\\
\textbf{File type}}{\large \\
'Normal' (-) or 'Special' (eg d)\\
\\
-	data file, a simple file\\
------------------------------------------\\
d	Directory\\
l	Symbolic link\\
c	Character special device\\
b	Block special device\\
p	FIFO\\
s	Socket\\
\\
\\
\\
\textbf{Permission classes}}{\large \textbf{U}}{\large ser - owner of file in this class\\
\textbf{G}}{\large roup - members of the group in this class\\
\textbf{O}}{\large ther -  anyone else in this class\\
\\
r--  means Read Only\\
rw- means read, write only\\
rwx Read, write and execute\\
\\
rws \\
\\
\\
\textbf{Owner Permissions}}{\large : for a multi-user OS\\
Config services to operate as a distinct user; hence via permissions, can control the service's access\\
We can setup programs/services via a username and perform all operations via that user\\
\\
\textbf{Group Permissions}}{\large \\
Setup 'Group owner'\\
\\
To see what groups a user belongs too \\
\$ groups\\
\\
To see all group  (not group not group'S')\\
\$ cat /etc/group}{\large \\
\\
\\
tomdom@tomdom-iMac:\~\$ \textbf{groups}}{\large \\
tomdom adm cdrom sudo dip plugdev lpadmin sambashare \hyperlink{docker}{docker}}{\large \\
\\
\\
admin@tomdom-iMac:\~/wp-content/plugins\$ \textbf{groups}}{\large \\
admin www-data\\
\\
\\
Octal notation\\
4 = Read\\
2 = Write\\
1 = eXecute\\
\\
\\
\textbf{Chmod - CHange files MOde permissions}}{\large \\
\\
eg\\
\$ chmod 660 filename\\
or\\
\$ chmod +r filename\\
or\\
\$ chmod +rwx filename\\
\\
\$ chmod -R filename    \textbf{R}}{\large ecursively go through the directory and change all file permissions\\
\\
\\
Often need to be MORE SELECTIVE\\
To selectively set the mode:  u for users permissions, g for groups, o for others eg.\\
\$ chmod ug+xw filename\\
\\
and to remove permissions; example\\
\$ chmod o-xrw filename\\
\\
Can set different expressions by commas\\
eg. ug=rwx,o=rx— \\
\\
or octal numerical permissions\\
\\
\\
To identify user \\
\$ whoami\\
\\
To change users\\
\$ su tomdom\\
\\
To see what groups a user belongs too \\
\$ groups\\
\\
To see what groups a different user (eg 'sarah') belongs too \\
\$ groups sarah\\
\\
examples\\
----------------------------------------------------------\\
tomdom@tomdom-iMac:\~\$ whoami\\
tomdom\\
tomdom@tomdom-iMac:\~\$ groups admin\\
admin : admin www-data\\
tomdom@tomdom-iMac:\~\$ \\
----------------------------------------------------------\\
\\
\\
\textbf{Suid (Set user id) \\
}}{\large If program has the suid access modes set, it will run as if  started by the file's owner\\
Have as few suid programs as possible as poor use of suid is a security risk.\\
\textbf{\\
and Sgid (Set group id)}}{\large \\
The program will run as if the initiating user belonged to the file's group rather than to his own group.\\
\\
When a directory has the sgid mode enabled, any files or directories created in it will inherit the group ID of the directory. \\
Useful for a group of people working on the same project. \\
\\
\\
EXAMPLE  http://fideloper.com/user-group-permissions-chmod-apache}{\large \\
Not necessarily correct\\
-------------------------------------------------------------------------------------------------------------------------------\\
\\
Use this knowledge to setup Apache we want for Apache:\\
user www-data\\
group www-data\\
Server web root is /var/www/html}{\large \\
\\
To set the owner/group of the 'web root' (and any directories/files therein ie Recursively)\\
\\
\$ sudo chown -R www-data:www-data /var/www/html}{\large \\
\\
So no-one but the current user (www-data) can access the web-root content\\
\$ chmod go-rwx /var/www/html}{\large \\
\\
allow users of the same group (and 'other') to enter the /var/www/html}{\large  directory\\
\$ chmod go+x /var/www/html}{\large \\
\\
Make sure all directories and files in the 'web root' have the 'www-data' group\\
\$ chgrp -R www-data /var/www/html}{\large \\
\\
Set it so only the user can access web content\\
\$ chmod -R go-rwx /var/www/html}{\large \\
\\
Set it so anyone in the same group can ready/write and execute in the web root\\
\$ chmod -R g+rx /var/www/html}{\large \\
\\
give group write permissions\\
\$ chmod -R g+rwx /var/www/html}{\large \\
\\
\\
--------------------\\
\\
set the setgid bit on each of the directories within the web document root /var/www/html}{\large \\
\\
So all new files created within /var/www/html}{\large   to be given the group of www-data which is the parents group\\
\\
Hence  the web server 'www-data' will still have group ownership\\
\\
\$ }sudo find /var/www/html -type d -exec{\large \textbf{chmod g+s}}{\large  \{\}} \\;{\large \\
\\
give group write access to the wp-content directory so that the web interface can make theme and plugin changes:\\
\\
\$ sudo chmod g+w /var/www/html/wp-content}{\large \\
\\
give the web server write access to all of the content in these two directories:\\
\\
\$ sudo chmod -R g+w /var/www/html/wp-content/themes}{\large \\
\\
\$ sudo chmod -R g+w /var/www/html/wp-content/plugins}{\large \\
--------------------------------------------------------------------------------------------------------------------------------\\
\\
\\
\textbf{The sticky bit (t)}}{\large \\
Only allows the owning user or the superuser (root) to delete or unlink a file. \\
\\
\\
\\
\\
==========================================================\\
\\
\\
}\textbf{{\Large What is the www-data user?}}{\large }https://www.digitalocean.com/community/tutorials/how-to-serve-django-applications-with-uwsgi-and-nginx-on-ubuntu-16-04{\large \\
\\
Since Ubuntu 14.04 /var/www}{\large  has changed to /var/www/html}{\large  \\
An Apache2 install typically creates www-data automatically\\
\\
Web servers often run as \\
User: 			www-data\\
Group: 			www-data; typically no write permissions\\
Owner of files is 	www-data\\
\\
For security, \textbf{web content}}{\large , HTML, JS, etc should \textbf{not }}{\large be \textbf{owned by www-data}}{\large \textbf{Data}}{\large  written out be server \textbf{owned by www-data}}{\large \textbf{Web server }}{\large run as\textbf{ user 'www-data' }}{\large so the entire server can't be compromised\\
\\
\\
The web server has to be run under a specific user\\
That user must exist\\
\\
\\
\\
}\textbf{{\Large How to avoid using sudo when working in /var/www/html?}}{\large }https://askubuntu.com/questions/46331/how-to-avoid-using-sudo-when-working-in-var-www{\large \textbf{Method 1}}{\large \\
Add your username to the www-data group\\
Set the setgid bit on /var/www/html}{\large  directory so that all newly created files inherit this group as well\\
\\
\$ sudo gpasswd -a ''\$USER'' www-data\\
\\
Correct previously created files (assuming you to be the only user of /var/www/html}{\large  )\\
\\
\$ sudo chown -R ''\$USER'':www-data /var/www}{\large \\
\$ find /var/www}{\large  -type f -exec chmod 0660 \{\} \\;\\
\$ sudo find /var/www}{\large  -type d -exec chmod 2770 \{\} \\;\\
\\
chmod 0660    =   -rw-rw----\\
\\
chmod 2770    =  drwxrws---\\
\\
}https://chmodcommand.com/chmod-2770/{\large \textbf{Method 2}}{\large \\
\\
Create a symlink for each project to your home directory\\
If project is at \~/projects/foo}{\large  to located it at /var/www/html/foo}{\large  \\
\\
\$ sudo ln -sT \~/projects/foo}{\large /var/www/html/foo}{\large       [ s softlink   T  no target; treat 'foo' as a normal file]\\
\\
\\
Change the \textbf{group of 'projects' to 'www-data'}}{\large  setting e\textbf{x}}{\large ecute only\\
Do the same for the \~/projects}{\large  folder as it may contain other projects than www.}{\large  \\
(You don't need sudo if you have previously added your user to the www-data group.)\\
\\
\$ sudo chgrp www-data \~ \~/projects}{\large \\
\$ chmod 710 \~ \~/projects}{\large \\
\\
Set the group to www-data on \~/projects/foo}{\large  and allow the webserver to read and write to files and files+directories and descend into directories:\\
\\
\$ sudo chgrp www-data \~/projects/foo}{\large \\
\$ find \~/projects/foo}{\large  -type f -exec chmod 660 \{\} \\;\\
\$ find \~/projects/foo}{\large  -type d -exec chmod 2770 \{\} \\;\\
\\
\\
You can now access your site at http://localhost/foo}{\large  and edit your project files in \~/projects/foo.}{\large }\textbf{{\Large Solving the web file permissions problem once and for all}}{\large }http://blog.netgusto.com/solving-web-file-permissions-problem-once-and-for-all/{\large \\
\\
Both the web server and the developpers require file permissions on the same files to operate properly, but they might need different permissions on the same files.\\
\\
With bindfs, developers access applications via dedicated filesystem mountpoints (placed in their home dir), acting as file-permission filters, presenting files like they're owned by themselves, whereas the files are really owned by the web server user (like www-data).\\
\\
\\
\\
\\
\textbf{{\Large Create-guten-block and\\
Fixing npm EACCES errors }}}{\large {\large \\
\\
\\
The problem I had with setting up the create-guten-block npm app is that it produced EACCES errors.\\
\\
The problem is that I had the web server in var/www/html but the user I had difficulties getting permissions correct.\\
\\
\\
Tried the following; this looks unsafe and just didn't work\\
\\
\$ sudo npx create-guten-block --unsafe-perm=true --allow-root myblock\\
\$ sudo npx create-guten-block myblock --unsafe-perm=true --allow-root\\
\\
\\
We have two users 'tomdom' and 'www-data'\\
\\
switching to 'www-data' user\\
\$ sudo su www-data\\
\\
\\
\\
If we check the groups for www-data, tomdom and admin\\
\\
\$ groups tomdom www-data\\
tomdom : tomdom adm cdrom sudo dip plugdev lpadmin sambashare \hyperlink{docker}{docker}}{\large \\
www-data : www-data\\
\\
So tomdom is NOT a member of the www-data 'web root' group\\
'www-data' user is a member of the 'www-data' group\\
\\
Checking the status of the passwords for these users\\
\$ sudo passwd --status tomdom\\
tomdom P 03/07/2018 0 99999 7 -1\\
\\
\$ sudo passwd --status www-data\\
www-data L 01/05/2018 0 99999 7 -1\\
\\
Fields 1 to 7 mean:\\
1) User's login name\\
2) If user has a locked password (L), no password (NP), usable password (P)\\
3 to 7) Date of the last password change, min age ,max age, warning period, inactivity period\\
\\
We see that the \textbf{www-data user}}{\large  p\textbf{assword is locked down}}{\large  for security reasons.\\
\\
\\
We could unlock it OR create a new user that has a password enabled and is assigned permissions to the 'www-data' group\\
\\
Lets add/create a new user called 'admin' and assign it permissions to the 'www-data' web server group\\
\$ sudo useradd -d /var/www/html}{\large  -G www-data admin\\
\$ sudo passwd admin\\
\$ sudo usermod -d /var/www/html}{\large  admin\\
\\
Checking the status of the passwords for admin\\
\$ sudo passwd --status admin\\
admin P 06/29/2018 0 99999 7 -1\\
\\
Now set permissions for all users recursively in the www-data group; so this will include 'admin'\\
\$ sudo chgrp -R www-data /var/www/html}{\large \\
\\
\$ sudo chmod -R g+w /var/www/html}{\large \\
\$ sudo chmod g+s /var/www/html}{\large \\
\\
Setgid bit is set so any files created in /var/www/html}{\large  will inherit 'www-data' group id\\
OR could have done [safer]\\
\$ chmod -R 2775 /var/www/html}{\large \\
\\
OR - which is the same as doing\\
\$ sudo chmod -R a+rwx,o-w,ug+s,+t,u-s,-t  /var/www/html}{\large \\
\\
\\
Checking  'admin' and 'www-data' users are members of the 'www-data' group\\
\$ groups admin www-data\\
admin : admin www-data\\
www-data : www-data\\
\\
[(d)   user   group   other]\\
\$ ls -al /var/www/html}{\large \\
drwxrwsr-x  7   www-data    www-data    4096 Jun 29 17:36 html\\
\\
So 'html' web root project directory is 'user', and 'group' is www-data. \\
The 'www-data' group has read, write and execute permissions, \\
\\
\\
\\
and the 'plugin' and 'gutenburg' directories have user and group permissions of 'www-data'\\
\$ ls -al /var/www/html/wp-content/plugins}{\large \\
drwxrwsr-x 5    www-data    www-data  .\\
drwxrwxr-x 7    www-data    www-data   gutenberg\\
\\
\\
\\
Lets create a symbolic soft link inside our 'wordpress' project folder that points to the 'web root' directory\\
\$ ln -s /var/www/html}{\large  '/home/tomdom/Temp stuff/WP\_Using hosts MySQL db/wp\_test/wordpress'\\
\\
\\
\\
Check follow symbolic links in apache2 config\\
-------------\\
<Directory /var/www/html/>}{\large \\
        Options Indexes FollowSymLinks\\
        AllowOverride All\\
        Require all granted\\
</Directory>\\
-------------\\
\$ cd /etc/apache2/}{\large \\
\$ nano apache2.conf \\
\\
\\
Switch to the 'admin' user\\
\$ su admin\\
\\
now as 'admin' is a member of www-data group we can create a guten-block with npm\\
\\
\$ sudo npx create-guten-block\\
\$ sudo npx create-guten-block testblock\\
\\
\\
And if we check the newly created guten-block 'block-2' we see \\
its user and group permissions are 'admin' and 'ww-data' as required\\
\\
\$ ls -al /var/www/html/wp-content/plugins}{\large \\
drwxrwsr-x 5    admin       www-data    4096 Jun 29 18:01 block-2\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
}6764
\hypertarget{linux_pipes_and_re-directs}{\section {Linux Pipes and Re-directs}}
\textbf{{\Large 0 STD IN     1 STD OUT    3 STD ERR}}{\Large }{\large }{\Large \$ wc -l barry.txt > myoputput\\
\\
( word count 'barry' and put result in file 'myoutput' ) \\
\\
\\
	>> to append to output file\\
\\
\\
	\$ wc -l < myoutput \\
\\
( put file content of 'myoutput' int the word count command tool )\\
\\
\\
	\$ ls -l video.mp4 foo.bar  2> errors.txt \\
\\
( list long the following and put any errors into a file called 'errors.txt' )\\
\\
\\
	\$ ls -l video.mp4 foo.bar > myoutput 2>\&1\\
\\
\\
( save both normal output and error messages into same file, redirecting STDOUT and STDERR to the same file.\\
\\
We redirect to a file then an error stream.\\
\\
We place and \& in fronb tof the stream number.\\
\\
Hence 2>\&1   means redirect STDOUT into STDIN)\\
\\
\\
\\
\textbf{PIPING}}{\Large \\
\\
To send data from one command to another\\
\\
example 1) 	\$ ls | head -3 | tail -i\\
\\
\\
example 2) 	\$ ls -l /etc | tail -n +2 | sort\\
\\
\\
\\
Tip: build and test pipes up incrementally !\\
\\
\\
Combine pipe with redirection eg.\\
\\
	\$ ls | head -3 | tail -i > myoutput\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
}962
\hypertarget{making_a_'here'_document}{\section {Making a 'here' document}}
{\Large \$ cat bananas << BANANAS\\
>well I never\\
>I've had no BANANAS\\
>so I'll put on a separate line BANANAS\\
BANANAS\\
\\
the case end 'BANANAS' can appear anywhere in the input, only when it appears on its own in a line with no spaces will it terminate the output\\
\\
However typically EOF (end of file/field) is used so:\\
\\
\$ cat << EOF\\
>foo\\
>bar\\
>lemon\\
EOF\\
\\
\\
}0
\hypertarget{new_note_template}{\section {New Note Template}}
19
\hypertarget{new_note_template}{\section {New Note Template}}
19
\hypertarget{note_from_2018-12-13_11:05:49.936}{\section {Note from 2018-12-13 11:05:49.936}}
http://www.oecd.org/fr/dev/developing-countries-and-the-renewable-energy-revolution.htm\\
\\
\\
Put in China, USA and EU in 'highlighted countries' search and you will see \_*China is now the lowest for air and climate changing gas emissions*\_ the emit far less the USA https://data.oecd.org/air/air-and-ghg-emissions.htm\\
\\
\\
\\
Also put in China, USA and EU in 'highlighted countries' OECD search for \_*renewable energy : China*\_ is by far the leader https://data.oecd.org/energy/renewable-energy.htm1090
\hypertarget{remove__.mp4.mov.mov_extensions}{\section {Remove  .mp4.mov.mov extensions}}
\textbf{{\large for f in * ; do mv ''\$f'' ''\$(echo ''\$f'' | cut -f 1 -d '.')''; done\\
\\
for f in * ; do mv ''\$f'' ''\$f.mov''; done}}\\
\\
\\
-----------------------\\
\\
\\
\textbf{\\
for f in * ; do mv ''\$f'' ''\$(echo ''\$f'' | cut -f 1 -d '.')''; done \&\& for f in * ; do mv ''\$f'' ''\$f.mov''; done}98
\hypertarget{setting_bash_aliases}{\section {Setting bash aliases}}
{\large To update everything\\
\$ sudo apt update \&\& sudo apt dist-upgrade \&\& sudo apt autoremove --purge \&\& sudo snap refresh \&\& flatpak update\\
\\
To list aliases\\
\$ alias\\
\\
------------------------------------------------------\\
To create an 'update everything' alias\\
\$ alias updateme='sudo apt update \&\& sudo apt upgrade \&\& sudo apt dist-upgrade \&\& sudo apt autoremove --purge \&\& sudo snap refresh \&\& flatpak update'\\
\\
[Note: to remove this it's just \$ unalias updateme ]\\
BUT only valid for current session!\\
\\
If you look at the .bashrc file\\
\$ less .bashrc\\
\\
then '/alias' to highlite the alias text\\
\\
also find thescript\\
\\
--------\\
\# Alias definitions.\\
\# You may want to put all your additions into a separate file like\\
\# \~/.bash\_aliases,}{\large  instead of adding them here directly.\\
\# See /usr/share/doc/bash-doc/examples}{\large  in the bash-doc package.\\
\\
if [ -f \~/.bash\_aliases}{\large  ]; then\\
    . \~/.bash\_aliases}{\large \\
fi\\
--------\\
\\
\\
}\textbf{{\Large Make alias permanent between sessions}}{\large \\
----------------------------------------------------------------------------\\
\\
\textbf{CHECK .bashrc\_alaises exists}}{\large \\
1) backup your bashrc file first\\
go to home directory\\
\$ cd \~\\
\\
2) Copy your [hidden] bashrc file\\
\$ cp .bashrc .bashrc.backup\\
\\
3) list the .bashrc file\\
\$ less \~/.bashrc}{\large \\
\\
4) Check to see if a .bashrc\_aliases file exists\\
\$ ls -al | grep .bash\_aliases\\
\\
Also do \\
\$ \$ ls -al | grep .bashrc\\
just to see if other files exist ok\\
\\
If no file exists, create one\\
5) touch .bash\_aliases\\
\\
\\
\\
\textbf{METHOD 1}}{\large \\
Open up .bash\_aliases in a text editor\\
1) \$ nano .bash\_alaiases\\
\\
and add\\
------------\\
alias updateme='sudo apt update \&\& sudo apt upgrade \&\& sudo apt dist-upgrade \&\& sudo apt autoremove --purge \&\& sudo snap refresh \&\& flatpak update'\\
------------\\
\\
2) Reload your terminal window\\
Close and reopen it \\
OR \\
restart via terminal\\
\$ bash\\
OR\\
just run the .bashrc file\\
\$ . \~/.bashrc}{\large \textbf{METHOD 2}}{\large  - echo\\
1) as above create a .bash\_aliases file if one doesn't already exist\\
\\
2) echo the alias command and redirect and append it to the .bashrc\_aliases file !\\
\$ echo ''alias updateme='sudo apt update \&\& sudo apt upgrade \&\& sudo apt dist-upgrade \&\& sudo apt autoremove --purge \&\& sudo snap refresh \&\& flatpak update''' >> \~./bashrc\_aliases\\
\\
3) restart terminal\\
\$ bash\\
\\
\textbf{METHOD 3}}{\large  - cat\\
1) as above create a .bash\_aliases file if one doesn't already exist\\
\\
2) cat the alias command and redirect and append it to the .bash\_aliases\\
\\
-----\\
\$ cat >> .bash\_aliases\\
''alias updateme='sudo apt update \&\& sudo apt upgrade \&\& sudo apt autoremove --purge \&\& sudo snap refresh \&\& flatpak update''' \\
-----\\
\\
\textbf{\textit{DON'T FORGET its DOUBLE for append   >> }}}{\large {\large \\
\\
=======================================}\textbf{{\Large \\
Summary}}{\large \\
\\
\$cp .bashrc .bashrc.backup\\
\\
\$ touch .bash\_aliases\\
\\
\$ nano .bash\_aliases\\
     ---> alias updateme='sudo apt upda....\&\& flatpak update'\\
     ---> save and exit\\
\\
\$ bash\\
\\
\$ updateme}{\large ======================================\\
\\
}2356
\hypertarget{shell_and_sub-shell_behaviour}{\section {Shell and Sub-shell behaviour}}
{\Large \\
\\
Good for when you have a group of commands that take a long time to execute. Allows you to run stuff in the background.\\
\\
\\
}{\large \#!/bin/sh\\
\# Demonstrates variable behaviour in a sub-shell environment\\
VAR=10\\
echo ''VAR is'' \$VAR\\
(\\
echo ''In the subshell, VAR is still'' \$VAR\\
VAR=\$((\$VAR+5))\\
echo ''The new value of VAR in the subshell is'' \$VAR\\
)\\
echo ''Outside of the subshell, VAR is'' \$VAR\\
\\
when run as \$ ./example\_sub\_shell.sh  \\
\\
output is: ---->\\
}{\Large }{\large VAR is 10\\
In the subshell, VAR is still 10\\
The new value of VAR in the subshell is 15\\
Outside of the subshell, VAR is 10}{\Large }151
\hypertarget{shredding_old_spinning_hd}{\section {Shredding old spinning HD}}
\textbf{{\Large }}{\large Create one large partition, typically this is /dev/sda}{\large }\textbf{{\Large \$ sudo shred -v -n8 -z /dev/sda}}{\large \\
\\
-v   verbose\\
-z   final overwrite with zeros\\
-n8 repeat 9 (n+1) times\\
\\
}\textbf{{\Large \\
\$ sudo dd if=/dev/urandom of=/dev/sda bs=1M count=2}}{\large \\
\\
\$ sudo dd if=/dev/zero of=/dev/sda bs=512 count=3}290
\hypertarget{ssh___and_sshfs}{\section {SSH   and SSHFS}}
user@server1.cyberciti.biz\\
\\
OR just copy the public key in remote server as authorized\_keys in \~/.ssh/ directory:\\
\\
scp \$HOME/.ssh/id\_rsa.pub user@server1.cyberciti.biz:\~/.ssh/authorized\_keys\\
\\
\\
\\
    3 Add yourself to sudo admin account\\
\\
\\
\\
\\
\\
    4 Disable the password login for root account\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
====================================================\\
\\
\\
\\
\\
\\
\\
\\
{\large \\
\\
The ssh CLIENT comes standard with Ubuntu\\
BUT - the ssh 'SERVER' need to install on the machine you want to connect to\\
\\
Hence on the machine you want to log into\\
\\
				\$sudo apt install openssh-server\\
\\
\\
Also on both machines allow port 22 for ssh\\
\\
\$sudo ufw allow ssh\\
\$sudo ufw status numbered\\
\\
So ssh is on port 22: not totally happy with  this but for now ok.\\
\\
And to connect to this machine from another local machine eg as root on a local machine labled 'iMac'\\
\\
\$ ssh root@iMac\\
\\
	where were connecting as 'root' in this example\\
\\
OR we can find the i.p. address\\
\\
\\
Identify local i.p\\
\$ hostname -I\\
--->  192.168.1.99 172.17.0.1\\
\\
OR\\
\\
install net-tools\\
	\$ sudo apt install net-tools\\
\\
	\$ifconfig \\
 	--> inet 172.17.0.1   [ for example ]\\
\\
\\
Then\\
\\
\$ ssh root@192.168.1.99}{\large    [sometimes this way is less reliable - not sure why ? ]\\
\\
\\
\\
Should get\\
 --->\\
The authenticity of host 'imac (192.168.1.99)' can't be established.\\
ECDSA key fingerprint is SHA256:xxxxxxxxx...etc etc\\
Are you sure you want to continue connecting?\\
\\
\$ yes\\
\\
--->\\
Warning: Perminantly added 'imac, 192.168.1.99' (ECDSA) to the list of known hosts.\\
Connection closed by 192.168.1.99 port 22\\
\\
\\
NOW AGAIN DO\\
\\
\$ ssh tomdom@iMac\\
-->\\
tomdom@iMac password:  \\
\\
\\
On machine that is serving ssh\\
sudo nano /etc/ssh/sshd\_config}{\large \\
------------\\
\#Port 22\\
Can change from Port 22, but as local i.p. not much point.\\
\\
If going via the internet then 'Port froward 22' to a port number between 1024 and 31,000 through your router\\
\\
\#PermitRootLogin prohibit-password\\
[ change to]\\
PermitRootLogin prohibit-password \\
[ this means only public-key, hostbased and GSSAPI authentication allowed ]\\
\\
[ OR] \\
PermitRootLogin no      \\
[wont disable on Ubuntu though as it doesn't have root by default !! ]\\
\\
[at the bottom of sshd\_config set specific user and i.p. address only allowed ssh access]\\
AllowUsers tomdom@192.168.1.66}{\large \\
\\
[ also may need to check GitHub etc is working ok, try something like\\
AllowUsers tomdom@192.168.1.66}{\large foobar@x.x.x.x}{\large  git tomdom\\
\\
AllowGroups ssh-user ]\\
--------\\
\\
restart the ssh server\\
\\
\$ sudo service ssh restart\\
\\
\\
*** To give Hosts an i.p. label for an i.p. address  ****\\
To list the hosts\\
\\
\$ sudo nano /etc/hosts}{\large \\
\\
--->\\
\\
	127.0.0.1       localhost\\
	127.0.1.1       iMac\\
\\
	\# The following lines are desirable for IPv6 capable hosts\\
	::1     ip6-localhost ip6-loopback\\
	fe00::0 ip6-localnet\\
	ff00::0 ip6-mcastprefix\\
	ff02::1 ip6-allnodes\\
	ff02::2 ip6-allrouters\\
\\
\\
\\
\\
Use scp To copy from your local computer to the remote, type, in the local computer:\\
\\
scp /tmp/file}{\large user@example.com:/home/name/dir}{\large \\
\\
(where /tmp/file}{\large  can be replaced with any local file and /home/name/dir}{\large  with any remote directory)\\
\\
To copy from the remote computer to the local one, type, in the local computer:\\
\\
scp user@example.com:/home/name/dir/file}{\large  /tmp\\
\\
Use sshfs This is a little more advanced but much, much nicer (when the internet connection of both computers is good. If not, stick to scp)\\
\\
You can ''link'' a directory from the remote computer to an (empty) directory of the local computer. Say you ''link'' the /some/remote/dir}{\large  from the remote computer to /home/youruser/remotecomp}{\large  in your computer. If there is a file /some/remote/dir/file}{\large  in the remote computer, you can see it on /home/youruser/remotecomp/file.}{\large  You can copy and mv as usual, and you can even alter remote files and dirs.\\
\\
Note however, that when the connection ends, /home/youruser/remotecomp}{\large  becomes an empty dir again, and you only keep in the local computer the files you copied to other directories\\
\\
To achieve this:\\
\\
1) install sshfs:\\
\\
sudo apt-get install sshfs\\
\\
2) create a empty dir\\
\\
mkdir /home/youruser/remotecomp}{\large \\
\\
3) ''link'' the two directories (the right term is mount)\\
\\
sshfs user@server.com:/some/remote/dir}{\large /home/youruser/remotecomp}{\large \\
\\
4) Enjoy\\
\\
5) ''unlink'' the dirs\\
\\
fusermount -u /home/youruser/remotecomp}{\large }592
\hypertarget{thursday}{\section {Thursday}}
\sout{{\large }}{\large My own site/Social media - make a plan\\
\\
Timescales - Milestone deadlines\\
\\
\\
\\
CSS animation + JavaScript - Make notes from various YouTube 'courses'\\
\\
My site - Sketch out what I'm going to do. Jobs to be done. qualify, quantify\\
\\
JavaScript Udemy course - create questions based on code so far\\
\\
JS Udemy - ajax API stuff (fetch)\\
\\
Run\\
\\
LinkedIn - 'fix'\\
\\
My site 'fix typo'\\
\\
-------------------------------------------------------\\
\\
}{\Large Gym - check\\
\\
BE 'DOMINIC' - NOT TOM -}{\Large  ACT!! - ADOPT A PERSONAL!!\\
\\
RELEVANCE - DO PEOPLE NEED TO KNOW !!}{\Large \\
\\
FISH ! - \\
GO FAST! - }GET PRODUCT INTO HANDS OF PROSPECTIVE HANDS AS QUICKLY AS POSSIBLE{\Large \\
GO HARD!! - }PUSH PUSH{\Large \\
GO CHEAP!! - }PRESERVE CAPTITAL - MVP  - GOOD ENOUGH\\
{\Large \\
focus on half chances - \\
FOCUS ON THE PROCESS NOT THE GOAL !!!\\
\\
PROGRESS NOT PERFECTION !!!}301
\hypertarget{to_make_script_work_from_the_bash_prompt}{\section {To make script work from the bash prompt}}
 To make script work from the bash prompt\\
 \\
https://www.taniarascia.com/how-to-create-and-use-bash-scripts/\\
   \\
    1) \$ cd \~\\
    2) \$ mkdir -p bin\\
    3) \$ touch .bash\_profile\\
    Create a PATH in  .bash\_profile [note: >> as append \\
    \\
    4) \$ cd\~\\
    5) \$ cat .bash\_profile   -->  typically its got stuff in it!!  \\
    Don't delete it !; use nano if not sure \\
    6) \$ echo ''export PATH=\$PATH:/home/tomdom/bin'' >> .bash\_profile\\
    Put the script in the bin directory\\
    7) \$ mv myScript.sh \~/bin/myScript     [no extension !]\\
    8) \$ chmod u+x \~/bin/myScript571
\hypertarget{today_+_stratergy}{\section {TODAY + STRATERGY}}
{\large }{\Large \\
Every day become A WEB \textbf{DEVELOPER}}{\Large  - BE IT }
\begin{itemize}
\item {\Large fake it till you make it !}
\item {\Large focus on the process (Daily/weekly) not the goal}
\end{itemize}
{\large \textbf{Exercise\\
       Code  [PHP (server side)   JavaScript(client/side)]\\
       Market myself}}{\large  (here is something I'm making, or an idea. Find a good place to show of work, youtube?, linkedIn, medium??)\\
}{\large \\
Micro-HABITTS (45min) 7:15 am - 8am\\
	Everyday memorise one or a bit of JavaScript Cardio programmes (20 min)\\
	Everyday go over a JS question (10 min)\\
	Every day memorise some CSS/ HTML5 (10 min)\\
	Press up/ sit up 10 min\\
\\
----------------------------------------------------\\
TIMESCALES - (weeks)\\
\\
\\
----------------------------------------------------\\
}\textbf{{\Large \\
TO-DO's}}{\large \textbf{Gym cancel\\
Car - insurance\\
Open Post}}{\large \textbf{Shopping\\
RUN}}{\large {\large \\
Sort times in timetable and pick dates for when doing Parkrun again\\
\\
Check email working on Toastmaster website\\
Make up 4 Games for Toastmasters\\
\\
Tax - Checkout HMRC feedback}{\large Labour Website - WordPress feedback / }{\large \\
Finish Website report\\
\textbf{Ask at council for about Mayor website or other - charities?}}{\large {\large {\large \\
\\
\\
Ring Giles  Warburton / Sarah at Shortlist recruitment for update  01244 360206\\
--------------------------------------------------------------------------\\
\\
STRATERGY\\
	MARKETING Strategy - \\
	CODING Strategy - \\
\\
My 'brand' my customers /audience - what the different strands are for?\\
Make a video about each stage!\\
Jobs to be done- pains and gains\\
How to market myself\\
Create a new website for myself specifically to customer types!!\\
\\
Demos:\\
My own site - The brand name!!, Jobs to be done, UX design/branding, front-end-coding Bootstrap 4, Sass n mixins, SEO, LAMP stack, WordPress, blog integration,  a little PHP to serve up a 'game' with peoples name and scores or something else perhaps..\\
\\
\\
Stack overflow - presence\\
GitHub - presence\\
\\
Junior job coding skills - have them in my social media write ups\\
\\
My own 'dummy' business site selling 'spectacle wipes', Arabic cakes n  coffee\\
Sites I've done for clients eg Fiverr (if possible)\\
\\
Free Code Camp - finish off the front-end-certificate (so I can say I've got  a certificate! - add to LikedIn and Fiverr)\\
\\
Simon/OXO game - front end coding + PHP for game score on back-end\\
Shopping site - expand on from Iceland\\
\\
Charity Sites - any local ones?\\
FixMyStreet contributions? - teamwork\\
\\
finish off Travis's Javascript course on Udemy\\
Checkout how buttons added in loop with array approach\\
Overview 'The Gaurdian' SCSS and learn about there mixins, vars etc \\
\\
Speaking Festival - Figure out what I'm doing - To promote me!!\\
Contact that 'cake refugee'\\
Speaking Game - to practice speaking for quality speeches\\
Speaking games/ business ideas? (eg speech  - Tom's 'women leaders')\\
Omar Ahmad - cake dream - contact\\
Tony's nephew - advice on setting up a festival\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
}369
\hypertarget{todo_july_2018}{\section {Todo July 2018}}
{\large \\
Forward facing for Job\\
\\
LinkedIn\\
	Re-do page, tidy up per James's suggestions\\
	\\
\\
My own website\\
	Do initial UI design\\
	Decide on WP \\
\\
Look for mini-contract work\\
	Fivver\\
	other ?\\
\\
\\
Build skills and \\
Labour EP\&N website\\
	Sort out\\
	Media (Interviews/ podcasts etc)\\
	Resources\\
	Proper email\\
\\
\\
Car ready\\
	Pay insurance on car\\
	Book MoT\\
\\
\\
Labour Party (skills)\\
	\\
\\
\\
\\
-----------------\\
Also I got another call from an agency for a job in Northwich near where I used to live when I was a lad. Again I had to fluff around the 'what have you been doing' ie do you have experience question. I just said self employed, but they interpreted as freelance web dev. So again I'm fluffing my way in. I've got a bad feeling I'm just not ready...  I'll send my CV to someone I know in Liverpool to see if I can get a couple of months as a junior at his company\\
1 interest gained\\
2 interest retained \\
\\
3 Needs appreciated \\
4 knowledge \\
5 Suitability \\
\\
6 Desire ( to buy)\\
7 Cost - ( how much) \\
8 Value - (It's worth it) \\
\\
\\
}113
\hypertarget{vagrant}{\section {VAGRANT}}
https://box.scotch.io/docs/https://wpdistillery.org/\\
\\
Install vagrant\\
Install virtualbox\\
\\
\textbf{Create a ' vagrantfile '}  \\
project root directory, describes machine and setup\\
\\
lets call the vagrantfile 'fooBar'\\
\\
\$ mkdir vfooBar\\
\$ cd fooBar\\
\\
\\
\\
{\Large INSTALL AND UPGRADE\\
}\\
============================================\\
============================================\\
\\
1\\
\$ vagrant init\textit{Commit the vagrantfile ie 'fooBar' to git version control}\textbf{Vagrant boxes}https://app.vagrantup.com/boxes/search\\
base image to quickly clone a virtual machine\\
\\
example\\
\$ vagrant box add hashicorp/precise64\\
\\
2\\
\$ vagrant box add scotch/box\\
\\
add scotch-box v 3.5 (March 2018)\\
adding files in one guest machine will have no effect on the other machine.\\
\\
\\
\textbf{Using a Box}\\
to configure a box to use it as a base, edit the Vagrantfile \\
eg\\
Can specify box URL; also version number\\
\\
3\\
-------\\
Vagrant.configure(''2'') do |config|\\
  config.vm.box = ''scotch/box''\\
  config.vm.box\_url = ''https://vagrantcloud.com/scotch/boxes/box/versions/3.5/providers/virtualbox.box''\\
end\\
\\
-------\\
\\
\textbf{Up And }\hyperlink{ssh___and_sshfs}{SSH   and SSHFS}\\
\\
start up\\
\\
4\\
\$ vagrant up\\
\\
THIS GIVES\\
-----\\
/vagrant => /home/tomdom/Temp stuff/WordPress\_VAGRANT/Tom1\\
------\\
\\
and to check things are o.k.\\
5\\
\$ vagrant \hyperlink{ssh___and_sshfs}{SSH   and SSHFS}\\
\\
----------------------\\
For help, please visit box.scotch.io or scotch.io. Follow us on Twitter @scotch\_io and @whatnicktweets.\\
\\
Last login: Wed May 31 01:25:33 2017 from 10.0.2.2\\
vagrant@scotchbox:\~\$\\
\\
----------------------------------------------------------------\\
vagrant@scotchbox:\~\$ pwd/home/vagrant\\
\\
vagrant@scotchbox:\~\$ uname -a\\
Linux scotchbox 4.4.0-75-generic \#96-Ubuntu SMP Thu Apr 20 09:56:33 UTC 2017 x86\_64 x86\_64 x86\_64 GNU/Linux\\
\\
vagrant@scotchbox:\~\$ npm --version\\
3.10.10\\
\\
vagrant@scotchbox:\~\$ node --version\\
v6.10.3\\
\\
vagrant@scotchbox:\~\$ git --version\\
git version 2.7.4\\
\\
vagrant@scotchbox:\~\$ nvm --version\\
0.33.2\\
\\
---------------------------------------------------------------------\\
WHAT I DID NEXT IN vagrant@scotchbox shell\\
6\\
\$sudo spt-get update\\
\$ sudo apt-get upgrade\\
\\
GRUB\\
continued without installing grub YES\\
PHP\\
Keep the local version currently installed\\
\\
ADD GIT PPA\\
7\\
\$ sudo add-apt-repository ppa:git-core/ppa\$sudo spt-get update\\
\$ sudo apt-get upgrade\\
\\
8\\
IF WON'T UPGRADE (force dependencies)\\
\$ sudo apt-get --with-new-pkgs upgrade\$ npm install -g npm\\
\\
[updated npm to 6.1.0]\\
\\
\\
-----------------------\\
\$ nvm ls   \\
to see what's installed\\
\\
\$ nvm ls-remote\\
to see what is available\\
----------------\\
\\
9\\
\$ nvm install 10.5.0\\
\\
[Now using node v10.5.0 (npm v6.1.0)]\\
\\
\\
\\
to check server\\
httpd -v\\
\\
\\
can now use bash in the vagrant machine  \textbf{ home/vagrant} \\
\\
10\\
CTRL+D to close \hyperlink{ssh___and_sshfs}{SSH   and SSHFS} session\\
\\
============================================\\
============================================\\
\\
\\
\\
\\
\textbf{{\large Synced folders}}{\large  (no \hyperlink{ssh___and_sshfs}{SSH   and SSHFS}}{\large )}\\
To sync your files from vagrants' \textbf{synced /vagrant} to and from \textbf{/vagrant} directory in guest.\\
\\
Note: The Vagrantfile inside the virtual machine is the same Vagrantfile on your actual host machine\\
With synced folders, you can continue to use your own editor on your host machine and have the files sync into the guest machine.\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\textbf{Automated provisioning}\\
\\
Example Apache server setup\\
\\
\\
https://www.vagrantup.com/docs/provisioning/shell.html\\
Shell provisioning is ideal for users new to Vagrant who want to get up and running quickly\\
\\
\textbf{Provisioning via an External Script }\\
Where 'script.sh' is the script bash file\\
\\
add\_apache.sh   bash script\\
-------------------\\
\#!/usr/bin/env bash\\
\\
apt-get update\\
apt-get install -y apache2\\
if ! [ -L /var/www ]; then\\
  rm -rf /var/www\\
  ln -fs /vagrant /var/www\\
fi\\
\\
-------------------\\
\\
and to get this script to run on 'up'\\
\\
-------------------\\
Vagrant.configure(''2'') do |config|\\
  config.vm.box = ''hashicorp/precise64''\\
  config.vm.provision :shell, path: ''add\_apache.sh''\\
end\\
-------------------\\
\\
\\
If guest machine is already running, then\\
\\
\$ vagrant reload --provision\\
\\
to re-start the VM and\\
\\
\$ vagrant \hyperlink{ssh___and_sshfs}{SSH   and SSHFS}\\
...\\
vagrant@precise64:\~\$\\
\\
and to see apache up and running\\
vagrant@precise64:\~\$ wget -qO- 127.0.0.1\\
\\
[- q quiet  -O  Output file ]\\
\\
also\\
localhost:80\\
gets apache server [unclear why]\\
\\
\\
\textbf{Networking}\\
\\
Port forwarding (eg Apache server)\\
Set ports on the guest machine to share via a port on host\\
\\
change Vagrantfile\\
------------------------\\
Vagrant.configure(''2'') do |config|\\
  config.vm.box = ''hashicorp/precise64''\\
  config.vm.provision :shell, path: ''bootstrap.sh''\\
  config.vm.network :forwarded\_port, guest: 80, host: 4567\\
end\\
------------------------\\
\\
\\
\$ vagrant reload  /  \$ vagrant up\\
\\
and http://127.0.0.1:4567 in your browser\\
\\
\\
can also \\
assign a static IP address to guest \\
bridge the guest machine onto an existing network\\
\\
\\
\\
\textbf{Share}\\
\\
To share your Vagrant environment around the world via a URL\\
\\
----------------\\
\$ vagrant share\\
...\\
==> default: Creating Vagrant Share session...\\
==> default: HTTP URL: http://b1fb1f3f.ngrok.io\\
...\\
----------------\\
\\
\\
\textbf{Suspend --> save state\\
}\$ vagrant suspend\textbf{\\
\\
Halt --> clean shutdown, low memory, extra startup time\\
}\$ vagrant halt\textbf{\\
\\
Destroy --> remove from guest, VM still exists}\\
\$ vagrant destroy    \\
\\
\$ vagrant box remove       --->  gets rid of box\\
\\
\\
\textbf{Plugins}\\
INSTALL\\
\# Installing a plugin from a known gem source\\
\$ vagrant plugin install my-plugin\\
\\
\# Installing a plugin from a local file source\\
\$ vagrant plugin install /path/to/my-plugin.gem\\
\\
UPDATE\\
\$ vagrant plugin update NAME\\
\\
UNINSTALL\\
\$ vagrant plugin uninstall my-plugin\\
\\
LIST\\
\$ vagrant plugin list\\
\\
\\
\textbf{Pushing}\\
Can deploy or ''push'' code in the same directory as your Vagrantfile to a remote such as an \hyperlink{ftp}{FTP} server.\\
\\
\\
===========================================================\\
===========================================================\\
\\
\\
Scotch box MySQL database settings\\
\\
Key 						Value\\
Database Name 			scotchbox\\
Database User 			root\\
Database Password 		root\\
Database Host 			localhost\\
\\
\\
\\
Website http://192.168.33.10/\\
\\
\\
\\
\\
==================================================================\\
==================================================================\\
\\
\\
\textbf{{\Large WordPress distillery}}\\
\\
\$ mkdir Wordpress\_Vagrant\\
\\
then git clone into new directory called 'fooBar-project'\\
\$ git clone https://github.com/flurinduerst/WPDistillery.git fooBarr-project\\
\\
\$ cd fooBar-project\\
\\
\$ cd wpdistillery/\\
\\
\$ kwrite config.yml\\
\\
EDIT ADMIN SETTINGS / PLUGINS ETC !!!\\
In    config.yml\\
\\
\$ cd ..\\
\\
\$ kwrite Vagrantfile\\
\\
Change the config hostname to same as in config.yml i.e\\
\\
\\
Vagrantfile\\
-------------\\
..\\
 {\small    config.\hyperlink{ssh___and_sshfs}{SSH   and SSHFS}}{\small .password = ''vagrant''\\
    config.vm.box = ''scotch/box''\\
    config.vm.network ''private\_network'', ip: ''192.168.33.10''} config.vm.hostname = ''tomswebsite.vm''\\
..\\
------------\\
should be same as in\\
config.yml\\
------------\\
....\\
\# SETTINGS\\
\#\#\#\#\#\#\#\#\#\#\#\\
\\
wpsettings:\\
  url: tomswebsite.vm\\
 ...\\
------------\\
\\
\\
\$ pwd\\
\\
this should be '/fooBar-project' or whatever the created WP directory was initially\\
\\
\$ vagrant up\\
\\
when prompted enter the host machines standard user password\\
ie the same password when booting up your Mac or whatever\\
\\
\\
When finished try\\
\\
http://192.168.33.10/\\
\\
or\\
\\
tomswebsite.vm\\
\\
\\
Now update the VM\\
\\
\$ vagrant \hyperlink{ssh___and_sshfs}{SSH   and SSHFS}\\
\\
\$ sudo chown -R vagrant:\$(id -gn vagrant) /home/vagrant/.config \\
\\
\\
\#\# Update\\
\\
\$ sudo nano /etc/apt/source.list\\
--------------\\
add this\\
\\
	deb http://mirror.bytemark.co.uk/ubuntu/ xenial main \\
	deb-src http://mirror.bytemark.co.uk/ubuntu/ xenial main \\
---------------\\
\\
sudo apt-get update\\
sudo add-apt-repository ppa:git-core/ppa -y\\
sudo apt-get update\\
\\
sudo apt-get update --fix-missing\\
\\
sudo apt-get --with-new-pkgs upgrade\\
sudo npm install -g npm\\
nvm install stable\\
\\
\\
\$ cd /var/www/public/wp-content/plugins\# Install Gutenburg plugin \\
wget https://downloads.wordpress.org/plugin/gutenberg.3.1.0.zip\\
unzip gutenberg.3.1.0.zip\\
rm gutenberg.3.1.0.zip\\
\\
\# Install Create-guten-block\\
sudo npm install -g create-guten-block\\
create-guten-block --version \&\& echo 'create-guten-block installed'\\
\\
\# To get out of the vagrant \hyperlink{ssh___and_sshfs}{SSH   and SSHFS}\\
CTRL+D\\
\\
NOW back in host project directory 'fooBar'\\
fooBar\$ \\
\\
\#\#\$ cd /public/wp-content/plugins\\
\#\# cd /var/www/public/wp-content/plugins\\
\\
\# Create guten block for the project 'fooBar'\\
\\
\$ pwd\\
fooBar/public/wp-content/plugins/\\
\\
\$ create-guten-block myfoobarblock\\
\\
\$ cd myfoobarblock\\
\\
NOW Split the terminal\\
CTRL+SHIFT+(\\
\\
In original terminal\\
\\
myfoobarblock\$ npm start\\
\\
\\
\\
\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\\
SITE\\
http://192.168.33.10/\\
\\
WP-ADMIN\\
http://192.168.33.10/\\
\\
\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\\
DATABASE (Mysql)\\
\$mysql -u root -p\\
mysql> show databases;\\
[see https://www.digitalocean.com/community/tutorials/how-to-install-wordpress-with-lamp-on-ubuntu-16-04]\\
\\
\# MySQL database default settings\\
\\
\# Key                       Value\\
\# Database Name             scotchbox\\
\# Database User             root\\
\# Database Password         root\\
\# Database Host             localhost\\
\\
\\
\# https://box.scotch.io/docs/8144
\hypertarget{variables}{\section {VARIABLES}}
11
\hypertarget{vim}{\section {Vim}}
{\large To exit vi\\
\\
colon ' : '\\
\\
then   ' q! '}43
\hypertarget{while_read_line_loop_in_bash}{\section {While Read Line Loop in Bash}}
{\large https://www.shellhacks.com/bash-read-file-line-by-line-while-read-line-loop/}{\large \\
\\
while read LINE\\
    do COMMAND\\
done < FILE\\
\\
Example\\
------------\\
\\
suppose we create a 'users.txt'\\
\\
cat << \_EOF\_ > users.txt\\
Eric\\
Kyle\\
Stan\\
Kenny\\
\_EOF\_\\
----------------------------------------------------------------------------------------\\
\\
\$ while read USER\\
	do echo ''Hello \$USER!''\\
	done < users.txt\\
Hello Eric!\\
Hello Kyle!\\
Hello Stan!\\
Hello Kenny!}{\large \\
==================================================\\
\\
Standard array\\
\\
ARRAY[0]='hello'\\
ARRAY[1]=' '\\
ARRAY[2]='world'\\
\\
}\textbf{{\Large To 'push' onto an array stack}}{\large \textit{''In the context where an assignment statement is assigning a value to a shell variable or array index (see Arrays), the ‘+=’ operator can be used to append to or add to the variable’s previous value. This includes arguments to builtin commands such as declare that accept assignment statements (declaration commands).''}}{\large https://www.gnu.org/software/bash/manual/bashref.html\#Shell-Parameters}{\large \\
\\
ARRAY=()\\
ARRAY+=('hello')\\
ARRAY+=(' ')\\
ARRAY+=('world')\\
\\
eg\\
\\
\$ myarray=()\\
\$ myarray+=('hello')\\
\$ myarray+=('world')\\
\$ myarray+=('!')\\
\$ echo ''\$\{myarray[*]\}''\\
hello  world !\\
\\
\\
\\
}107
\hypertarget{wp_rest_api}{\section {WP REST api}}
{\Large }{\large * Routes/Endpoints\\
* Requests   WP\_REST\_Request\\
* Responses   WP\_REST\_Responce\\
 * Schema\\
 * Controller Classes\\
\\
\\
Posts			/wp/v2/posts}{\large \\
Post Revisions 	/wp/v2/revisions}{\large \\
Categories 		/wp/v2/categories}{\large \\
Tags 			/wp/v2/tags}{\large \\
Pages 			/wp/v2/pages}{\large \\
Comments 		/wp/v2/comments}{\large \\
Taxonomies 		/wp/v2/taxonomies}{\large \\
Media 			/wp/v2/media}{\large \\
Users 			/wp/v2/users}{\large \\
Post Types 		/wp/v2/types}{\large \\
Post Statuses 		/wp/v2/statuses}{\large \\
Settings 			/wp/v2/settings}{\large \\
\\
\\
WordPress REST API\\
we have a discovery process that allows interacting with sites without prior contact.\\
\\
\\
Using REST api\\
Global Parameters: learn about the global REST API query parameters that apply to every endpoint\\
\\
Pagination: \\
work with large collections of resources \& control how many records you receive from the REST API\\
\\
Linking \& Embedding: \\
understand how to read and modify connections between different objects, and embed related resources such as author and media data in the REST API’s responses\\
\\
Discovery: \\
determine what REST API resources a site supports, and where they are located\\
\\
Authentication: \\
authorise your REST API requests so that you can create, update and delete your data\\
\\
\\
\\
\\
\\
\\
\\
\\
}1151
\hypertarget{yt}{\section {yt}}
https://www.youtube.com/playlist?list=PLhxITUni9OWerafeQSih8Vw7sZv0ifmFo\\
\\
Richard Wolff Economics\\
youtube-dl https://www.youtube.com/playlist?list=PLhxITUni9OWfL7UoYK7pOnJkm6JNZFuFS\\
\\
\\
youtube-dl https://youtu.be/TkDLagTs1eg\\
\\
\\
\\
\\
\\
Silent Witness\\
\\
\\
\\
\\
youtube-dl https://www.bbc.co.uk/iplayer/episode/b05234gh/silent-witness-one-of-our-own-part-1 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b052357k/silent-witness-one-of-our-own-part-2 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b06vr2j7/silent-witness-after-the-fall-part-1 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b06vr4cl/silent-witness-after-the-fall-part-2 \\
\\
\\
\\
\\
\\
\\
\\
Bleak House\\
\\
\\
youtube-dl https://www.bbc.co.uk/iplayer/episode/b0074s1f/bleak-house-episode-1 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b0074s1h/bleak-house-episode-3 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b0074s1g/bleak-house-episode-2 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b0074s1j/bleak-house-episode-4 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b0074s1k/bleak-house-episode-5 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b0074s1q/bleak-house-episode-6 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b0074s1r/bleak-house-episode-7 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b0074s1s/bleak-house-episode-8 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b0074s1t/bleak-house-episode-9 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b0074s1v/bleak-house-episode-10 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b0074s1w/bleak-house-episode-11 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b0074s1x/bleak-house-episode-12 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b0074s1y/bleak-house-episode-13 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b0074s1z/bleak-house-episode-14 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b0074s20/bleak-house-episode-15\\
\\
\\
\\
\\
\\
\\
\\
\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\\
DONE\\
\\
\\
Sense \& Sensibility\\
youtube-dl https://www.bbc.co.uk/iplayer/episode/b008lzfl/sense-and-sensibility-episode-1 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b008p8y2/sense-and-sensibility-episode-2 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b008ptbs/sense-and-sensibility-episode-3\\
\\
\\
Silent Witness\\
youtube-dl https://www.bbc.co.uk/iplayer/episode/b08d292b/silent-witness-awakening-1-part-one \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b08c7d8z/silent-witness-covenant-2-part-two \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b08c78vt/silent-witness-covenant-1-part-one \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b09m8w6q/silent-witness-series-21-1-moment-of-surrender-part-one \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b09m8ym6/silent-witness-series-21-2-moment-of-surrender-part-two \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b09p67rq/silent-witness-series-21-3-duty-of-candour-part-one \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b09p68yk/silent-witness-series-21-4-duty-of-candour-part-two\\
\\
 youtube-dl https://www.bbc.co.uk/iplayer/episode/b09pkv9n/silent-witness-series-21-5-a-special-relationship-part-one \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b09pkv9q/silent-witness-series-21-6-a-special-relationship-part-two \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b09qmy54/silent-witness-series-21-7-one-day-part-one \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b09qn03l/silent-witness-series-21-8-one-day-part-two \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b09rfh1p/silent-witness-series-21-9-family-part-one \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b09rfjr8/silent-witness-series-21-10-family-part-two \\
\\
\\
youtube-dl https://www.bbc.co.uk/iplayer/episode/b03nktgy/silent-witness-commodity-part-1 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b03nkwnq/silent-witness-commodity-part-2 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b03pjf78/silent-witness-coup-de-grace-part-1  \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b03pmkgh/silent-witness-coup-de-grace-part-2 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b03qggv6/silent-witness-in-a-lonely-place-part-1 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b03qgk91/silent-witness-in-a-lonely-place-part-2 \\
\\
\\
youtube-dl https://www.bbc.co.uk/iplayer/episode/b03s6z5x/silent-witness-undertone-part-1 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b03s7178/silent-witness-undertone-part-2 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b03t36gt/silent-witness-fraternity-part-1 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b03t37c0/silent-witness-fraternity-part-2 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b04xwrfp/silent-witness-snipers-nest-part-1 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b04xws0x/silent-witness-snipers-nest-part-2 \\
\\
youtube-dl https://www.bbc.co.uk/iplayer/episode/b04ylr65/silent-witness-falling-angels-part-1 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b04ylrk4/silent-witness-falling-angels-part-2 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b050m0jj/silent-witness-protection-part-1 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b050m1sz/silent-witness-protection-part-2 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b051cmhg/silent-witness-squaring-the-circle-part-2 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b051clcj/silent-witness-squaring-the-circle-part-1\\
\\
youtube-dl https://www.bbc.co.uk/iplayer/episode/b06wjd0f/silent-witness-flight-part-1 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b06wjfcx/silent-witness-flight-part-2 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b06ykmc0/silent-witness-life-licence-part-1 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b06yknm4/silent-witness-life-licence-part-2 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b06zc64g/silent-witness-in-plain-sight-part-1 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/b06zc95v/silent-witness-in-plain-sight-part-2\\
\\
\\
\\
watership down\\
youtube-dl https://www.bbc.co.uk/iplayer/episode/p06t63xn/watership-down-series-1-episode-1-chapter-1 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/p06t8wmk/watership-down-series-1-episode-2-chapter-1 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/p06t8vnw/watership-down-series-1-episode-1-chapter-2 \&\& youtube-dl https://www.bbc.co.uk/iplayer/episode/p06t8xwm/watership-down-series-1-episode-2-chapter-25468
\end{document}
